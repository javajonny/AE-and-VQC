{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import stats\n",
    "from matplotlib import rcParams\n",
    "import itertools\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# Define the font \n",
    "plt.rcParams['font.family'] = 'Computer Modern'  # Replace 'serif' with the name of the desired font\n",
    "# Define colorblind-friendly palette\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_csv_with_loss(folder_path, csv_file):\n",
    "    '''\n",
    "    Plots the validation loss for a specific CSV file.\n",
    "\n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                csv_file (string): Name of the CSV file\n",
    "    '''\n",
    "    # Read the CSV file\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract the epochs and validation loss as numpy arrays\n",
    "    epochs = data['Epoch'].values\n",
    "    validation_loss = data['Validation_Loss'].values\n",
    "    seed = data[\"SEED\"][0]\n",
    "    learning_rate = data[\"AE_LEARNING_RATE\"][0]\n",
    "    batch_size = data[\"AE_BATCH_SIZE\"][0]\n",
    "    test_loss = data[\"Test_Loss\"][0]\n",
    "    \n",
    "    # Plot the graph\n",
    "    plt.plot(epochs, validation_loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title(f'Validation Loss - {seed} - {learning_rate} - {batch_size}')\n",
    "    plt.suptitle(f'Test Loss: {test_loss}')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_csv_with_accuracy(folder_path, csv_file):\n",
    "    '''\n",
    "    Plots the validation acc for a specific CSV file.\n",
    "\n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                csv_file (string): Name of the CSV file\n",
    "    '''\n",
    "    # Read the CSV file\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract the epochs and validation loss as numpy arrays\n",
    "    epochs = data['Epoch'].values\n",
    "    validation_loss = data['Validation_Loss'].values\n",
    "    validation_accuracy = data['Validation_Accuracy'].values\n",
    "    seed = data[\"SEED\"][0]\n",
    "    learning_rate = data[\"AE_LEARNING_RATE\"][0]\n",
    "    batch_size = data[\"AE_BATCH_SIZE\"][0]\n",
    "    test_acc = data[\"Test_Accuracy\"][0]\n",
    "    \n",
    "    # Plot the graph\n",
    "    plt.plot(epochs, validation_accuracy)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Acc')\n",
    "    plt.title(f'Validation Acc - {seed} - {learning_rate} - {batch_size}')\n",
    "    plt.suptitle(f'Test Acc: {test_acc}')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_accuracy(folder_path, model):\n",
    "    '''\n",
    "    Plots the average validation accuracy for a specific model.\n",
    "    \n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                model (string): Name of the model\n",
    "    '''\n",
    "\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    val_accuracy_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path)\n",
    "        # check if file is the model we are looking for\n",
    "        model_list_name = data[\"List Name\"][0]\n",
    "        if model_list_name == model:\n",
    "            model_learning_rate = data[\"LEARNING_RATE\"][0]            \n",
    "            model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "            model_dataset_name = data[\"Dataset\"][0]\n",
    "            model_seed = data[\"SEED\"][0]\n",
    "            model_validation_accuracy = data[\"Validation_Accuracy\"].values\n",
    "            model_validation_loss = data[\"Validation_Loss\"].values\n",
    "            \n",
    "            # model_validation_accuracy = model_validation_accuracy[:50]\n",
    "            # model_validation_loss = model_validation_loss[:50]\n",
    "\n",
    "            val_accuracy_list.append((model_seed, model_validation_accuracy))\n",
    "            val_loss_list.append((model_seed, model_validation_loss))\n",
    "\n",
    "    val_accuracy_list = sorted(val_accuracy_list, key=lambda x:x[0])\n",
    "    val_loss_list = sorted(val_loss_list, key=lambda x:x[0])\n",
    "\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Average over all seeds\n",
    "    # Extract the array from the tuple\n",
    "    array_data_accuracy = [arr for _, arr in val_accuracy_list]\n",
    "    # Calculate the average for each corresponding element in the arrays\n",
    "    acc_averages = np.mean(array_data_accuracy, axis=0)\n",
    "    ax.plot(acc_averages, label=f\"Average Accuracy\")\n",
    "\n",
    "    array_data_loss = [arr for _, arr in val_loss_list]\n",
    "    # Calculate the average for each corresponding element in the arrays\n",
    "    loss_averages = np.mean(array_data_loss, axis=0)\n",
    "    # ax.plot(loss_averages, label=f\"Average Loss\")\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss and Accuracy')\n",
    "    ax.set_title(f'{model_dataset_name} - {model}')\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"text.usetex\"] = True\n",
    "rc(\"font\", **{\"family\": \"serif\", \"serif\": [\"Computer Modern\"]})\n",
    "rc(\"text\", usetex=True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.set(style=\"whitegrid\", font=\"Computer Modern\", font_scale=2)\n",
    "\n",
    "\n",
    "# Define the color palette for the models\n",
    "model_color_palette = sns.color_palette(\"colorblind\")\n",
    "relevant_model_names = [\"dressed_classical_list\", \"dressed_quantum_list\", \"sequent_classical_list\", \"sequent_quantum_list\"]\n",
    "\n",
    "# Create a custom color dictionary to map each model name to its corresponding color\n",
    "model_colors = {\n",
    "    'dressed_quantum_list': (0.00784313725490196, 0.6196078431372549, 0.45098039215686275), \n",
    "    'sequent_quantum_list': (0.8352941176470589, 0.3686274509803922, 0.0), \n",
    "    'dressed_classical_list': (0.984313725490196, 0.6862745098039216, 0.8941176470588236), \n",
    "    'sequent_classical_list': (0.5803921568627451, 0.5803921568627451, 0.5803921568627451)\n",
    "    }\n",
    "\n",
    "def plot_validation_accuracy_and_loss_all_models_Transfer_Learning(folder_path, dataset_name):\n",
    "    '''\n",
    "    Plots the validation accuracy and validation loss with error bands for specific models.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (string): Path to the folder containing the CSV files\n",
    "        dataset_name (string): Name of the dataset for which to show the legend\n",
    "    '''\n",
    "\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    val_acc_data = []\n",
    "    val_loss_data = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path)\n",
    "        # Check if the file is for a relevant model\n",
    "        model_list_name = data[\"List Name\"][0]\n",
    "\n",
    "        if model_list_name in relevant_model_names:\n",
    "            model_seed = data[\"SEED\"][0]\n",
    "            model_validation_accuracy = data[\"Validation_Accuracy\"].values\n",
    "            model_validation_loss = data[\"Validation_Loss\"].values\n",
    "\n",
    "            for epoch, (accuracy, loss) in enumerate(zip(model_validation_accuracy, model_validation_loss)):\n",
    "                val_acc_data.append({\n",
    "                    'Seed': model_seed,\n",
    "                    'Validation Accuracy': accuracy,\n",
    "                    'Validation Loss': loss,\n",
    "                    'Epoch': epoch,\n",
    "                    'Model': model_list_name\n",
    "                })    \n",
    "    \n",
    "    # Create DataFrame from the list\n",
    "    df = pd.DataFrame(val_acc_data)\n",
    "\n",
    "    # Combine classical and quantum models and add 100 to the epoch for quantum models\n",
    "    val_acc_data_combined = []\n",
    "    for data in val_acc_data:\n",
    "        if \"classical\" in data[\"Model\"]:\n",
    "            val_acc_data_combined.append(data)\n",
    "        elif \"quantum\" in data[\"Model\"]:\n",
    "            data_quantum = data.copy()\n",
    "            if dataset_name == \"MNIST\" or dataset_name == \"Audio MNIST\" :\n",
    "                data_quantum[\"Epoch\"] += 49\n",
    "            else:\n",
    "                data_quantum[\"Epoch\"] += 99\n",
    "            val_acc_data_combined.append(data_quantum)\n",
    "\n",
    "    # Create DataFrame from the combined data\n",
    "    df_combined = pd.DataFrame(val_acc_data_combined)\n",
    "\n",
    "    # Create a line plot for validation accuracy\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "    '''\n",
    "    sns.lineplot(data=df_combined, x='Epoch', y='Validation Accuracy', hue='Model', err_style='band', linewidth=1.5,\n",
    "                 palette=model_colors, hue_order=relevant_model_names)\n",
    "    '''\n",
    "\n",
    "\n",
    "    alpha =0.6\n",
    "    df_combined['Smoothed Accuracy'] = df_combined.groupby('Model')['Validation Accuracy'].transform(lambda x: x.ewm(alpha = alpha).mean())\n",
    "    df_combined['Smoothed Loss'] = df_combined.groupby('Model')['Validation Loss'].transform(lambda x: x.ewm(alpha =alpha).mean())\n",
    "\n",
    "\n",
    "    # Create a line plot with error bands representing the standard deviation for validation accuracy\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "    '''\n",
    "    sns.lineplot(data=df, x='Epoch', y='Validation Accuracy', hue='Model', errorbar='sd', linewidth=1.5,\n",
    "                 palette=model_colors, hue_order=relevant_model_names)\n",
    "    '''\n",
    "    sns.lineplot(x='Epoch', y='Smoothed Accuracy', hue='Model', data=df_combined, errorbar='sd', linewidth=1.5, palette=model_colors, hue_order=relevant_model_names)\n",
    "\n",
    "\n",
    "    # print(df_combined)\n",
    "    # Add labels and title for validation accuracy plot\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    # plt.title(f'Validation Accuracy for {dataset_name}')\n",
    "\n",
    "    # Show the legend only for the banknote dataset\n",
    "    \"\"\"\n",
    "    if dataset_name == \"Banknote\":\n",
    "        mylabels = [\"DQC (classical)\", \"DQC (quantum)\", \"SEQUENT (classical)\", \"SEQUENT (quantum)\"]\n",
    "        handles, previous_labels = plt.gca().get_legend_handles_labels()\n",
    "        plt.legend(handles=handles, labels=mylabels, fontsize=10, loc='lower right')\n",
    "    elif dataset_name == \"Audio MNIST\":\n",
    "        mylabels = [\"DQC (classical)\", \"DQC (quantum)\", \"SEQUENT (classical)\", \"SEQUENT (quantum)\"]\n",
    "        handles, previous_labels = plt.gca().get_legend_handles_labels()\n",
    "        plt.legend(handles=handles, labels=mylabels, fontsize=10, loc='lower right')\n",
    "    \"\"\"\n",
    "    mylabels = [\"DQC (classical)\", \"DQC (quantum)\", \"SEQUENT (classical)\", \"SEQUENT (quantum)\"]\n",
    "    handles, previous_labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles=handles, labels=mylabels, fontsize=10, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        # plt.legend('',frameon=False)\n",
    "    '''   \n",
    "    if dataset_name == \"Banknote\":\n",
    "        mylabels = [\"DQC (classical)\", \"DQC (quantum)\", \"SEQUENT (classical)\", \"SEQUENT (quantum)\"]\n",
    "        handles, previous_labels = plt.gca().get_legend_handles_labels()\n",
    "        plt.legend(handles=handles, labels=mylabels, fontsize=10, loc='lower right')\n",
    "    elif dataset_name == \"Audio MNIST\":\n",
    "        mylabels = [\"DQC (classical)\", \"DQC (quantum)\", \"SEQUENT (classical)\", \"SEQUENT (quantum)\"]\n",
    "        handles, previous_labels = plt.gca().get_legend_handles_labels()\n",
    "        plt.legend(handles=handles, labels=mylabels, fontsize=10, loc='lower right')\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Set x-axis limits to start at 0 and end at the maximum epoch\n",
    "    max_epoch = df_combined['Epoch'].max()\n",
    "    plt.xlim(left=0)\n",
    "    plt.xlim(right=max_epoch+2)\n",
    "\n",
    "\n",
    "    # Display the validation accuracy graph\n",
    "    plt.show()\n",
    "\n",
    "    # Create a line plot for validation loss\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "    '''\n",
    "    sns.lineplot(data=df_combined, x='Epoch', y='Validation Loss', hue='Model', errorbar='sd', linewidth=1.5,\n",
    "                 palette=model_colors, hue_order=relevant_model_names)\n",
    "    '''\n",
    "    sns.lineplot(x='Epoch', y='Smoothed Loss', hue='Model', data=df_combined, errorbar='sd', linewidth=1.5, palette=model_colors, hue_order=relevant_model_names)\n",
    "\n",
    "    # Add labels and title for validation loss plot\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    # plt.title(f'Validation Loss for {dataset_name}')\n",
    "\n",
    "    # Show the legend for validation loss plot\n",
    "    mylabels = [\"DQC (classical)\", \"DQC (quantum)\", \"SEQUENT (classical)\", \"SEQUENT (quantum)\"]\n",
    "    handles, previous_labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles=handles, labels=mylabels, fontsize=10, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "\n",
    "    # Set x-axis limits to start at 0 and end at the maximum epoch\n",
    "    plt.xlim(left=0)#, right=max_epoch)\n",
    "    plt.xlim(right=max_epoch+2)\n",
    "\n",
    "    # Display the validation loss graph\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Define the folder paths for each dataset\n",
    "folder_path_BanknoteAuthentication = os.path.join(os.getcwd(), \"..\", \"Results\", \"Banknote\")\n",
    "folder_path_BreastCancer = os.path.join(os.getcwd(), \"..\", \"Results\", \"Breast_Cancer\")\n",
    "folder_path_MNIST = os.path.join(os.getcwd(), \"..\", \"Results\", \"MNIST\")\n",
    "folder_path_Audio = os.path.join(os.getcwd(), \"..\", \"Results\", \"Audio_MNIST\")\n",
    "\n",
    "\n",
    "# Plot validation accuracy and validation loss for each dataset\n",
    "plot_validation_accuracy_and_loss_all_models_Transfer_Learning(folder_path_BanknoteAuthentication, \"Banknote\")\n",
    "plot_validation_accuracy_and_loss_all_models_Transfer_Learning(folder_path_BreastCancer, \"Breast Cancer\")\n",
    "plot_validation_accuracy_and_loss_all_models_Transfer_Learning(folder_path_MNIST, \"MNIST\")\n",
    "plot_validation_accuracy_and_loss_all_models_Transfer_Learning(folder_path_Audio, \"Audio MNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_accuracy_all_models_with_errorband_wo_custom_legend(folder_path):\n",
    "    '''\n",
    "    Plots the validation accuracy with error bands for specific models.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (string): Path to the folder containing the CSV files\n",
    "    '''\n",
    "\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    val_acc_data = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path)\n",
    "        # Check if the file is for a relevant model\n",
    "        model_list_name = data[\"List Name\"][0]\n",
    "\n",
    "        relevant_model_names = [\"VQC_angle_list\", \"VQC_amplitude_list\", \"dressed_quantum_list\", \"sequent_quantum_list\", \"NN_with_compressed_input_list\",  \"NN_with_original_input_list\"]\n",
    "        if model_list_name in relevant_model_names:\n",
    "            model_seed = data[\"SEED\"][0]\n",
    "            model_validation_accuracy = data[\"Validation_Accuracy\"].values\n",
    "\n",
    "            for epoch, accuracy in enumerate(model_validation_accuracy):\n",
    "                val_acc_data.append({\n",
    "                    'Seed': model_seed,\n",
    "                    'Validation Accuracy': accuracy,\n",
    "                    'Epoch': epoch,\n",
    "                    'Model': model_list_name\n",
    "                })\n",
    "\n",
    "    # Create DataFrame from the list\n",
    "    df = pd.DataFrame(val_acc_data)\n",
    "\n",
    "    # Set the plot style and font size\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Create a line plot with error bands representing the standard deviation\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "    sns.lineplot(data=df, x='Epoch', y='Validation Accuracy', hue='Model', errorbar='sd', linewidth=1.5,\n",
    "                 palette=model_color_palette, hue_order=relevant_model_names)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title(f'Model Validation Accuracy for {os.path.basename(folder_path)}')\n",
    "\n",
    "    # Show the legend\n",
    "    # mylabels = [\"VQC with angle encoding\", \"VQC with amplitude encoding\", \"Dressed Quantum NN\", \"Sequent Quantum NN\", \"NN with compressed input\", \"NN with original input\"]\n",
    "\n",
    "    plt.legend(fontsize=10)\n",
    "\n",
    "    # Display the graph\n",
    "    plt.show()\n",
    "\n",
    "# Define the folder paths for each dataset\n",
    "folder_path_Audio = os.path.join(os.getcwd(), \"..\", \"Results\", \"Audio_MNIST\")\n",
    "folder_path_BanknoteAuthentication = os.path.join(os.getcwd(), \"..\", \"Results\", \"Banknote\")\n",
    "folder_path_BreastCancer = os.path.join(os.getcwd(), \"..\", \"Results\", \"Breast_Cancer\")\n",
    "folder_path_MNIST = os.path.join(os.getcwd(), \"..\",  \"Results\", \"MNIST\")\n",
    "\n",
    "# Plot validation accuracy for each dataset\n",
    "plot_validation_accuracy_all_models_with_errorband_wo_custom_legend(folder_path_BanknoteAuthentication)\n",
    "plot_validation_accuracy_all_models_with_errorband_wo_custom_legend(folder_path_BreastCancer)\n",
    "plot_validation_accuracy_all_models_with_errorband_wo_custom_legend(folder_path_MNIST)\n",
    "plot_validation_accuracy_all_models_with_errorband_wo_custom_legend(folder_path_Audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_confidence_interval(folder_path, model):\n",
    "    '''\n",
    "    Calculates the mean test accuracy and the 95% confidence interval for a given model.\n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                model (string): Name of the model\n",
    "    '''\n",
    "    \n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    test_accuracy_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path)\n",
    "        # check if file is the model we are looking for\n",
    "        model_list_name = data[\"List Name\"][0]\n",
    "        if model_list_name == model:\n",
    "            model_seed = data[\"SEED\"][0]\n",
    "            model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "            test_accuracy_list.append((model_seed, model_test_accuracy))\n",
    "\n",
    "    test_accuracy_list = sorted(test_accuracy_list, key=lambda x: x[0])\n",
    "    # Extract the array from the tuple\n",
    "    array_data_accuracy = np.array([acc for _, acc in test_accuracy_list])\n",
    "\n",
    "    # Calculate mean test accuracy and standard error (SE) of the mean\n",
    "    mean_test_accuracy = np.mean(array_data_accuracy)\n",
    "    se_test_accuracy = stats.sem(array_data_accuracy)\n",
    "\n",
    "    # Calculate the 95% confidence interval for test accuracy\n",
    "    confidence_interval = stats.t.interval(0.95, len(array_data_accuracy) - 1, loc=mean_test_accuracy, scale=se_test_accuracy)\n",
    "\n",
    "    print(abs(mean_test_accuracy-confidence_interval[0]))\n",
    "    print(abs(mean_test_accuracy-confidence_interval[1]))\n",
    "    # Print the Results\n",
    "    print(\"Model:\", model)\n",
    "    print(\"Mean Test Accuracy:\", mean_test_accuracy)\n",
    "    print(\"95% Confidence Interval for Test Accuracy:\", confidence_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_list_for_all_datasets(folder_paths, model_list, output_csv, round_numbers):\n",
    "    '''\n",
    "    Calculates the mean test accuracy and the 95% confidence interval for all models in the model list for all datasets.\n",
    "    The results are stored in the output CSV file. The accuracies for each model and dataset over all seeds are also stored in the CSV file as a list. \n",
    "        Parameters:\n",
    "                folder_paths (dict): Dictionary containing the folder paths for each dataset\n",
    "                model_list (list): List of models for which to calculate the confidence interval\n",
    "                output_csv (string): Name of the output CSV file\n",
    "                round_numbers (bool): Whether to round the numbers to 3 decimal places\n",
    "    '''\n",
    "    \n",
    "    all_Results = []\n",
    "\n",
    "    for dataset, folder_path in folder_paths.items():\n",
    "        for model in model_list:\n",
    "            # Get all the files in the folder\n",
    "            files = os.listdir(folder_path)\n",
    "            # Filter out the CSV files\n",
    "            csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "            test_accuracy_list = []\n",
    "\n",
    "            for file in csv_files:\n",
    "                # Read the CSV file\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                data = pd.read_csv(file_path)\n",
    "                # check if file is the model we are looking for\n",
    "                model_list_name = data[\"List Name\"][0]\n",
    "                if model_list_name == model:\n",
    "                    model_seed = data[\"SEED\"][0]\n",
    "                    model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "                    test_accuracy_list.append((model_seed, model_test_accuracy))\n",
    "\n",
    "            # Sort the list by the seed\n",
    "            test_accuracy_list = sorted(test_accuracy_list, key=lambda x: x[0])\n",
    "            # Extract the array from the tuple\n",
    "            array_data_accuracy = np.array([acc for _, acc in test_accuracy_list])\n",
    "\n",
    "\n",
    "            # Calculate mean test accuracy and standard error (SE) of the mean\n",
    "            mean_test_accuracy = np.mean(array_data_accuracy)\n",
    "            se_test_accuracy = stats.sem(array_data_accuracy)\n",
    "\n",
    "            # Calculate the 95% confidence interval for test accuracy\n",
    "            confidence_interval_acc = stats.t.interval(0.95, len(array_data_accuracy) - 1, loc=mean_test_accuracy, scale=se_test_accuracy)\n",
    "            conf_interval_half_acc = abs(confidence_interval_acc[1] - confidence_interval_acc[0]) / 2\n",
    "\n",
    "\n",
    "            if round_numbers:\n",
    "                # round to 3 decimal places\n",
    "                mean_test_accuracy = round(mean_test_accuracy, 3)\n",
    "                conf_interval_half_acc = round(conf_interval_half_acc, 3)\n",
    "\n",
    "\n",
    "            all_Results.append({\"Model\": model,\n",
    "                                \"Dataset\": dataset,\n",
    "                                \"Accuracies\": array_data_accuracy,\n",
    "                                \"Mean test acc\": mean_test_accuracy,\n",
    "                                \"Confidence interval acc\": confidence_interval_acc,\n",
    "                                \"Confidence interval / 2 acc\": conf_interval_half_acc})\n",
    "    # Create a DataFrame from the Results for all datasets\n",
    "    df_all_Results = pd.DataFrame(all_Results)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_all_Results.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all files are in the folder\n",
    "folder_path_BanknoteAuthentication= os.path.join(os.getcwd(), \"..\", \"Results\", \"Banknote\")\n",
    "folder_path_BreastCancer = os.path.join(os.getcwd(), \"..\", \"Results\", \"Breast_Cancer\")\n",
    "folder_path_MNIST = os.path.join(os.getcwd(), \"..\", \"Results\", \"MNIST\")\n",
    "folder_path_Audio = os.path.join(os.getcwd(), \"..\", \"Results\", \"Audio_MNIST\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "folder_paths = {\n",
    "    \"BanknoteAuthentication\": folder_path_BanknoteAuthentication,\n",
    "    \"BreastCancer\": folder_path_BreastCancer,\n",
    "    \"MNIST\": folder_path_MNIST,\n",
    "    \"Audio\": folder_path_Audio\n",
    "}\n",
    "model_list = [\n",
    "    \"VQC_angle_testing_list\",\n",
    "    \"VQC_amplitude_testing_list\",\n",
    "    \"dressed_quantum_testing_list\",\n",
    "    \"sequent_quantum_testing_list\",\n",
    "    \"NN_with_compressed_input_testing_list\",\n",
    "    \"NN_with_original_input_testing_list\"\n",
    "]\n",
    "\n",
    "output_csv = os.path.join(os.getcwd(), \"..\", \"Results\", \"accuracy_list_all_models_datasets.csv\")\n",
    "\n",
    "calculate_accuracy_list_for_all_datasets(folder_paths, model_list, output_csv, round_numbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_loss_confidence_interval_for_all_datasets(folder_paths, model_list, output_csv, round_numbers):\n",
    "    '''\n",
    "    Calculates the mean test accuracy and test loss and the 95% confidence interval for all models in the model list for all datasets.\n",
    "    The results are stored in the output CSV file.\n",
    "    \n",
    "        Parameters:\n",
    "            folder_paths (dict): Dictionary containing the folder paths for each dataset\n",
    "            model_list (list): List of models for which to calculate the confidence interval\n",
    "            output_csv (string): Name of the output CSV file\n",
    "            round_numbers (bool): Whether to round the numbers to 3 decimal places\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    all_Results = []\n",
    "\n",
    "    for dataset, folder_path in folder_paths.items():\n",
    "        for model in model_list:\n",
    "            # Get all the files in the folder\n",
    "            files = os.listdir(folder_path)\n",
    "            # Filter out the CSV files\n",
    "            csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "            test_accuracy_list = []\n",
    "            test_loss_list = []\n",
    "\n",
    "            for file in csv_files:\n",
    "                # Read the CSV file\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                data = pd.read_csv(file_path)\n",
    "                # check if file is the model we are looking for\n",
    "                model_list_name = data[\"List Name\"][0]\n",
    "                if model_list_name == model:\n",
    "                    model_seed = data[\"SEED\"][0]\n",
    "                    model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "                    test_accuracy_list.append((model_seed, model_test_accuracy))\n",
    "                    model_test_loss = data[\"Test_Loss\"][0]\n",
    "                    test_loss_list.append((model_seed, model_test_loss))\n",
    "\n",
    "            test_accuracy_list = sorted(test_accuracy_list, key=lambda x: x[0])\n",
    "            # Extract the array from the tuple\n",
    "            array_data_accuracy = np.array([acc for _, acc in test_accuracy_list])\n",
    "\n",
    "            # Calculate mean test accuracy and standard error (SE) of the mean\n",
    "            mean_test_accuracy = np.mean(array_data_accuracy)\n",
    "            se_test_accuracy = stats.sem(array_data_accuracy)\n",
    "\n",
    "            # Calculate the 95% confidence interval for test accuracy\n",
    "            confidence_interval_acc = stats.t.interval(0.95, len(array_data_accuracy) - 1, loc=mean_test_accuracy, scale=se_test_accuracy)\n",
    "            conf_interval_half_acc = abs(confidence_interval_acc[1] - confidence_interval_acc[0]) / 2\n",
    "\n",
    "\n",
    "            test_loss_list = sorted(test_loss_list, key=lambda x: x[0])\n",
    "            # Extract the array from the tuple\n",
    "            array_data_loss = np.array([loss for _, loss in test_loss_list])\n",
    "\n",
    "            # Calculate mean test loss and standard error (SE) of the mean\n",
    "            mean_test_loss = np.mean(array_data_loss)\n",
    "            se_test_loss = stats.sem(array_data_loss)\n",
    "\n",
    "            # Calculate the 95% confidence interval for test loss\n",
    "            confidence_interval_loss = stats.t.interval(0.95, len(array_data_loss) - 1, loc=mean_test_loss, scale=se_test_loss)\n",
    "            conf_interval_half_loss = abs(confidence_interval_loss[1] - confidence_interval_loss[0]) / 2\n",
    "\n",
    "\n",
    "            if round_numbers:\n",
    "                # round to 3 decimal places\n",
    "                mean_test_accuracy = round(mean_test_accuracy, 3)\n",
    "                conf_interval_half_acc = round(conf_interval_half_acc, 3)\n",
    "                mean_test_loss = round(mean_test_loss, 3)\n",
    "                conf_interval_half_loss = round(conf_interval_half_loss, 3)\n",
    "\n",
    "\n",
    "            all_Results.append({\"Model\": model,\n",
    "                                \"Dataset\": dataset,\n",
    "                                \"Mean test acc\": mean_test_accuracy,\n",
    "                                \"Confidence interval acc\": confidence_interval_acc,\n",
    "                                \"Confidence interval / 2 acc\": conf_interval_half_acc,\n",
    "                                \"Mean test loss\": mean_test_loss,\n",
    "                                \"Confidence interval loss\": confidence_interval_loss,\n",
    "                                \"Confidence interval / 2 loss\": conf_interval_half_loss})\n",
    "    # Create a DataFrame from the Results for all datasets\n",
    "    df_all_Results = pd.DataFrame(all_Results)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_all_Results.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_paths = {\n",
    "    \"BanknoteAuthentication\": folder_path_BanknoteAuthentication,\n",
    "    \"BreastCancer\": folder_path_BreastCancer,\n",
    "    \"MNIST\": folder_path_MNIST,\n",
    "    \"Audio\": folder_path_Audio\n",
    "}\n",
    "model_list = [\n",
    "    \"VQC_angle_testing_list\",\n",
    "    \"VQC_amplitude_testing_list\",\n",
    "    \"dressed_quantum_testing_list\",\n",
    "    \"sequent_quantum_testing_list\",\n",
    "    \"NN_with_compressed_input_testing_list\",\n",
    "    \"NN_with_original_input_testing_list\"\n",
    "]\n",
    "\n",
    "output_csv = os.path.join(os.getcwd(), \"..\", \"Results\", \"all_models_test_acc_confidence_interval.csv\")\n",
    "\n",
    "calculate_accuracy_loss_confidence_interval_for_all_datasets(folder_paths, model_list, output_csv, round_numbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_test_acc(csv_file, round_numbers):\n",
    "    '''\n",
    "    Calculates the mean test accuracy and the 95% confidence interval over all models in the model list for all datasets.\n",
    "    I.e. the average test accuracy over all models for each dataset.\n",
    "    The results are stored in a new CSV file.\n",
    "\n",
    "        Parameters:\n",
    "                csv_file (string): Name of the input CSV file\n",
    "                round_numbers (bool): Whether to round the numbers to 3 decimal places\n",
    "    '''\n",
    "\n",
    "    all_Results = []\n",
    "    data = pd.read_csv(csv_file)\n",
    "    models = data[\"Model\"]\n",
    "    datasets = data[\"Dataset\"]\n",
    "    mean_test_accuracies = data[\"Mean test acc\"]\n",
    "\n",
    "    acc_VQC_angle = []\n",
    "    acc_VQC_amplitude = []\n",
    "    acc_dressed = []\n",
    "    acc_sequent = []\n",
    "    acc_nn_compressed = []\n",
    "    acc_nn_original = []\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        if(models[i] == \"VQC_angle_testing_list\"):\n",
    "            acc_VQC_angle.append(mean_test_accuracies[i])\n",
    "        elif(models[i] == \"VQC_amplitude_testing_list\"):\n",
    "            acc_VQC_amplitude.append(mean_test_accuracies[i])\n",
    "        elif(models[i] == \"dressed_quantum_testing_list\"):\n",
    "            acc_dressed.append(mean_test_accuracies[i])\n",
    "        elif(models[i] == \"sequent_quantum_testing_list\"):\n",
    "            acc_sequent.append(mean_test_accuracies[i])\n",
    "        elif(models[i] == \"NN_with_compressed_input_testing_list\"):\n",
    "            acc_nn_compressed.append(mean_test_accuracies[i])\n",
    "        elif(models[i] == \"NN_with_original_input_testing_list\"):\n",
    "            acc_nn_original.append(mean_test_accuracies[i])\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate mean test accuracy and standard error (SE) of the mean\n",
    "    mean_VQC_angle = np.mean(acc_VQC_angle)\n",
    "    mean_VQC_amplitude = np.mean(acc_VQC_amplitude)\n",
    "    mean_dressed = np.mean(acc_dressed)\n",
    "    mean_sequent = np.mean(acc_sequent)\n",
    "    mean_nn_compressed = np.mean(acc_nn_compressed)\n",
    "    mean_nn_original = np.mean(acc_nn_original)\n",
    "\n",
    "    se_VQC_angle = stats.sem(acc_VQC_angle)\n",
    "    se_VQC_amplitude = stats.sem(acc_VQC_amplitude)\n",
    "    se_dressed = stats.sem(acc_dressed)\n",
    "    se_sequent = stats.sem(acc_sequent)\n",
    "    se_nn_compressed = stats.sem(acc_nn_compressed)\n",
    "    se_nn_original = stats.sem(acc_nn_original)\n",
    "\n",
    "\n",
    "    # Calculate the 95% confidence interval for test accuracy\n",
    "    CI_VQC_angle = stats.t.interval(0.95, len(acc_VQC_angle) - 1, loc=mean_VQC_angle, scale=se_VQC_angle)\n",
    "    CI_VQC_amplitude = stats.t.interval(0.95, len(acc_VQC_amplitude) - 1, loc=mean_VQC_amplitude, scale=se_VQC_amplitude)\n",
    "    CI_dressed = stats.t.interval(0.95, len(acc_dressed) - 1, loc=mean_dressed, scale=se_dressed)\n",
    "    CI_sequent = stats.t.interval(0.95, len(acc_sequent) - 1, loc=mean_sequent, scale=se_sequent)\n",
    "    CI_nn_compressed = stats.t.interval(0.95, len(acc_nn_compressed) - 1, loc=mean_nn_compressed, scale=se_nn_compressed)\n",
    "    CI_nn_original = stats.t.interval(0.95, len(acc_nn_original) - 1, loc=mean_nn_original, scale=se_nn_original)\n",
    "\n",
    "    # Calculate the confidence interval half\n",
    "    conf_interval_half_VQC_angle = abs(CI_VQC_angle[1] - CI_VQC_angle[0]) / 2\n",
    "    conf_interval_half_VQC_amplitude = abs(CI_VQC_amplitude[1] - CI_VQC_amplitude[0]) / 2\n",
    "    conf_interval_half_dressed = abs(CI_dressed[1] - CI_dressed[0]) / 2\n",
    "    conf_interval_half_sequent = abs(CI_sequent[1] - CI_sequent[0]) / 2\n",
    "    conf_interval_half_nn_compressed = abs(CI_nn_compressed[1] - CI_nn_compressed[0]) / 2\n",
    "    conf_interval_half_nn_original = abs(CI_nn_original[1] - CI_nn_original[0]) / 2\n",
    "\n",
    "\n",
    "    if round_numbers:\n",
    "        # round to 3 decimal places\n",
    "        mean_VQC_angle = round(mean_VQC_angle, 3)\n",
    "        mean_VQC_amplitude = round(mean_VQC_amplitude, 3)\n",
    "        mean_dressed = round(mean_dressed, 3)\n",
    "        mean_sequent = round(mean_sequent, 3)\n",
    "        mean_nn_compressed = round(mean_nn_compressed, 3)\n",
    "        mean_nn_original = round(mean_nn_original, 3)\n",
    "\n",
    "        conf_interval_half_VQC_angle = round(conf_interval_half_VQC_angle, 3)\n",
    "        conf_interval_half_VQC_amplitude = round(conf_interval_half_VQC_amplitude, 3)\n",
    "        conf_interval_half_dressed = round(conf_interval_half_dressed, 3)\n",
    "        conf_interval_half_sequent = round(conf_interval_half_sequent, 3)\n",
    "        conf_interval_half_nn_compressed = round(conf_interval_half_nn_compressed, 3)\n",
    "        conf_interval_half_nn_original = round(conf_interval_half_nn_original, 3)\n",
    "\n",
    "\n",
    "    # store as csv\n",
    "    all_Results.append({\"Model\": \"VQC_angle\",\n",
    "                    \"Mean test acc\": mean_VQC_angle,\n",
    "                    \"Confidence interval acc\": CI_VQC_angle,\n",
    "                    \"Confidence interval / 2 acc\": conf_interval_half_VQC_angle})\n",
    "    all_Results.append({\"Model\": \"VQC_amplitude\",\n",
    "                    \"Mean test acc\": mean_VQC_amplitude,\n",
    "                    \"Confidence interval acc\": CI_VQC_amplitude,\n",
    "                    \"Confidence interval / 2 acc\": conf_interval_half_VQC_amplitude})\n",
    "    all_Results.append({\"Model\": \"Dressed\",\n",
    "                    \"Mean test acc\": mean_dressed,\n",
    "                    \"Confidence interval acc\": CI_dressed,\n",
    "                    \"Confidence interval / 2 acc\": conf_interval_half_dressed})\n",
    "    all_Results.append({\"Model\": \"Sequent\",\n",
    "                    \"Mean test acc\": mean_sequent,\n",
    "                    \"Confidence interval acc\": CI_sequent,\n",
    "                    \"Confidence interval / 2 acc\": conf_interval_half_sequent})\n",
    "    all_Results.append({\"Model\": \"NN_compressed\",\n",
    "                    \"Mean test acc\": mean_nn_compressed,\n",
    "                    \"Confidence interval acc\": CI_nn_compressed,\n",
    "                    \"Confidence interval / 2 acc\": conf_interval_half_nn_compressed})\n",
    "    all_Results.append({\"Model\": \"NN_original\",\n",
    "                    \"Mean test acc\": mean_nn_original,\n",
    "                    \"Confidence interval acc\": CI_nn_original,\n",
    "                    \"Confidence interval / 2 acc\": conf_interval_half_nn_original})\n",
    "\n",
    "     # Create a DataFrame from the Results for all datasets\n",
    "    df_all_Results = pd.DataFrame(all_Results)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output = os.path.join(os.getcwd(), \"..\", \"Results\", \"all_models_test_acc_confidence_interval_summary.csv\")\n",
    "    \n",
    "\n",
    "    df_all_Results.to_csv(output, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_test_acc(output_csv, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
