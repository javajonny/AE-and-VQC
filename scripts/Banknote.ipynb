{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Banknote Authentication\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "PennyLane version = 0.27.0\n",
      "Pytorch version = 1.9.0+cpu\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Reproducibility:\n",
      "Seed: 0\n",
      "\n",
      "AE:\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 128\n",
      "- Epochs: 500\n",
      "- Encoder Activation Function: Sigmoid()\n",
      "- Decoder Activation Function: Sigmoid()\n",
      "\n",
      "VQC with Angle Embedding:\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 5\n",
      "- Epochs: 10\n",
      "- Layers: 6\n",
      "\n",
      "VQC with Amplitude Embedding:\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 5\n",
      "- Epochs: 10\n",
      "- Layers: 6\n",
      "\n",
      "NN on Original Input:\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 5\n",
      "- Epochs: 10\n",
      "\n",
      "NN on Compressed Input (with AE before):\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 5\n",
      "- Epochs: 10\n",
      "\n",
      "Sequent:\n",
      "- Preprocessing Activation Function: Sigmoid()\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 5\n",
      "- Epochs: 10\n",
      "- Layers: 6\n",
      "\n",
      "Dressed Quantum Circuit:\n",
      "- Preprocessing Activation Function: Sigmoid()\n",
      "- Learning Rate: 0.001\n",
      "- Batch Size: 5\n",
      "- Epochs: 10\n",
      "- Layers: 6\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random \n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "print(\"+\"*50)\n",
    "print(\"Banknote Authentication\")\n",
    "print(\"+\"*50)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"PennyLane version = {qml.version()}\")\n",
    "print(f\"Pytorch version = {torch. __version__ }\")\n",
    "\n",
    "setgrad = lambda g, *ms: [setattr(p,'requires_grad', g) for m in ms for p in m.parameters() ]\n",
    "\n",
    "\n",
    "SYS_SEED =0\n",
    "SYS_BATCH_SIZE = 5\n",
    "SYS_LEARNING_RATE = 0.001\n",
    "SYS_LAYERS = 6\n",
    "\n",
    "EPOCHS_SETTING = 10\n",
    "\n",
    "# REPRODUCIBILITY \n",
    "SEED = SYS_SEED   # Seed for random initial weights\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# AE\n",
    "LEARNING_RATE_AE = 0.1\n",
    "BATCH_SIZE_AE = 128\n",
    "EPOCHS_AE = 500\n",
    "ENCODER_ACTIVATION_FN = nn.Sigmoid()\n",
    "DECODER_ACTIVATION_FN = nn.Sigmoid()\n",
    "\n",
    "# VQC with Angle Embedding\n",
    "LEARNING_RATE_VQC = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_VQC =  SYS_BATCH_SIZE\n",
    "EPOCHS_VQC = EPOCHS_SETTING\n",
    "LAYERS_ANGLE_EMBEDDING = SYS_LAYERS\n",
    "\n",
    "# VQC with Amplitude Embedding\n",
    "LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING =  SYS_BATCH_SIZE\n",
    "EPOCHS_VQC_AMPLITUDE_EMBEDDING = EPOCHS_SETTING\n",
    "LAYERS_AMPLITUDE_EMBEDDING = SYS_LAYERS\n",
    "\n",
    "# NN on original Input\n",
    "LEARNING_RATE_ONLY_NN = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_ONLY_NN = SYS_BATCH_SIZE\n",
    "EPOCHS_ONLY_NN = EPOCHS_SETTING\n",
    "\n",
    "# NN on compressed Input (with AE before) \n",
    "LEARNING_RATE_AE_NN = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_AE_NN = SYS_BATCH_SIZE\n",
    "EPOCHS_AE_NN = EPOCHS_SETTING\n",
    "\n",
    "# SEQUENT\n",
    "PREPROCESSING_SEQUENT_ACTICATION_FN = nn.Sigmoid()\n",
    "LEARNING_RATE_SEQUENT = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_SEQUENT = SYS_BATCH_SIZE\n",
    "EPOCHS_SEQUENT = EPOCHS_SETTING\n",
    "LAYERS_SEQUENT = SYS_LAYERS\n",
    "\n",
    "# DRESSED\n",
    "PREPROCESSING_DRESSED_ACTICATION_FN = nn.Sigmoid()\n",
    "LEARNING_RATE_DRESSED =  SYS_LEARNING_RATE\n",
    "BATCH_SIZE_DRESSED = SYS_BATCH_SIZE\n",
    "EPOCHS_DRESSED = EPOCHS_SETTING\n",
    "LAYERS_DRESSED = SYS_LAYERS\n",
    "\n",
    "\n",
    "print('-' * 50)\n",
    "print('-' * 50)\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the information\n",
    "print(\"Reproducibility:\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(\"\\nAE:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_AE}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_AE}\")\n",
    "print(f\"- Epochs: {EPOCHS_AE}\")\n",
    "print(f\"- Encoder Activation Function: {ENCODER_ACTIVATION_FN}\")\n",
    "print(f\"- Decoder Activation Function: {DECODER_ACTIVATION_FN}\")\n",
    "print(\"\\nVQC with Angle Embedding:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_VQC}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_VQC}\")\n",
    "print(f\"- Epochs: {EPOCHS_VQC}\")\n",
    "print(f\"- Layers: {LAYERS_ANGLE_EMBEDDING}\")\n",
    "print(\"\\nVQC with Amplitude Embedding:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING}\")\n",
    "print(f\"- Epochs: {EPOCHS_VQC_AMPLITUDE_EMBEDDING}\")\n",
    "print(f\"- Layers: {LAYERS_AMPLITUDE_EMBEDDING}\")\n",
    "print(\"\\nNN on Original Input:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_ONLY_NN}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_ONLY_NN}\")\n",
    "print(f\"- Epochs: {EPOCHS_ONLY_NN}\")\n",
    "print(\"\\nNN on Compressed Input (with AE before):\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_AE_NN}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_AE_NN}\")\n",
    "print(f\"- Epochs: {EPOCHS_AE_NN}\")\n",
    "print(\"\\nSequent:\")\n",
    "print(f\"- Preprocessing Activation Function: {PREPROCESSING_SEQUENT_ACTICATION_FN}\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_SEQUENT}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_SEQUENT}\")\n",
    "print(f\"- Epochs: {EPOCHS_SEQUENT}\")\n",
    "print(f\"- Layers: {LAYERS_SEQUENT}\")\n",
    "print(\"\\nDressed Quantum Circuit:\")\n",
    "print(f\"- Preprocessing Activation Function: {PREPROCESSING_DRESSED_ACTICATION_FN}\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_DRESSED}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_DRESSED}\")\n",
    "print(f\"- Epochs: {EPOCHS_DRESSED}\")\n",
    "print(f\"- Layers: {LAYERS_DRESSED}\")\n",
    "\n",
    "\n",
    "print('-' * 50)\n",
    "print('-' * 50)\n",
    "print('-' * 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankNoteDataset(Dataset):\n",
    "    def __init__(self, file_path, train=False, validation=False, test=False, seed=SEED):\n",
    "        # load data into dataframe\n",
    "        self.dataframe = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop rows with missing values\n",
    "        self.dataframe = self.dataframe.dropna()\n",
    "\n",
    "        # Convert the dataset to numpy arrays\n",
    "        data = self.dataframe.to_numpy()\n",
    "\n",
    "        # Split the dataset into X and y\n",
    "        X = data[:, :-1]\n",
    "        y = data[:, -1]\n",
    "\n",
    "        # Store the input dimension of X\n",
    "        self.input_dimension = X.shape[1]\n",
    "\n",
    "        # Store the feature names\n",
    "        self.feature_names = self.dataframe.columns[:4].tolist()\n",
    "\n",
    "        # Store the label name\n",
    "        self.label_names = self.dataframe.columns[-1]\n",
    "\n",
    "        # Convert y to integer labels\n",
    "        y = y.astype(int)\n",
    "\n",
    "        # Apply one-hot encoding to y\n",
    "        self.num_classes = len(np.unique(y))\n",
    "        y = np.eye(self.num_classes)[y]\n",
    "\n",
    "        # Apply Scaling\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        # Split: 80%, 10%, 10%\n",
    "        # here it makes no difference if we split the train-set into training & validation or the test-set because it comes from the same dataset \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=seed, shuffle=True)\n",
    "\n",
    "        if train:\n",
    "            self.X = torch.tensor(X_train, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_train, dtype=torch.float32)\n",
    "        elif validation:\n",
    "            self.X = torch.tensor(X_val, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_val, dtype=torch.float32)     \n",
    "        elif test:\n",
    "            self.X = torch.tensor(X_test, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_test, dtype=torch.float32)     \n",
    "\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return X, y \n",
    "\n",
    "    def visualize_output_distribution(self):\n",
    "        # Count the occurrences of each class\n",
    "        class_counts = self.y.sum(dim=0)\n",
    "\n",
    "        # Get the class labels\n",
    "        class_labels = [str(i) for i in range(self.num_classes)]\n",
    "\n",
    "        # Plot the output distribution\n",
    "        plt.bar(class_labels, class_counts)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Output Distribution')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), '..', 'data', 'BankNote_Authentication.csv')\n",
    "\n",
    "banknote_train = BankNoteDataset(file_path, train=True)\n",
    "banknote_validation = BankNoteDataset(file_path, validation=True)\n",
    "banknote_test = BankNoteDataset(file_path, test=True)\n",
    "\n",
    "\n",
    "num_classes = banknote_train.num_classes\n",
    "input_dimension = banknote_train.input_dimension\n",
    "\n",
    "\n",
    "# angle embedding: Encodes N features into the rotation angles of n qubits, where Nâ‰¤n\n",
    "VQC_width = num_classes\n",
    "# amplitude embedding: Encodes 2^n features into the amplitude vector of n qubits.\n",
    "wires_amplitude = max(math.ceil(math.log(input_dimension, 2)), num_classes) #at least as many qubits as output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 137, 138)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(banknote_train), len(banknote_validation), len(banknote_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of X_train: 1.0\n",
      "Minimum of X_train: 0.0\n",
      "Maximum of X_test: 0.9877678751945496\n",
      "Minimum of X_test: 0.004258233122527599\n"
     ]
    }
   ],
   "source": [
    "X_train_max = torch.max(banknote_train.X)\n",
    "X_train_min = torch.min(banknote_train.X)\n",
    "X_test_max = torch.max(banknote_test.X)\n",
    "X_test_min = torch.min(banknote_test.X)\n",
    "\n",
    "\n",
    "print(f\"Maximum of X_train: {X_train_max}\")\n",
    "print(f\"Minimum of X_train: {X_train_min}\")\n",
    "print(f\"Maximum of X_test: {X_test_max}\")\n",
    "print(f\"Minimum of X_test: {X_test_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "banknote_train.visualize_output_distribution()\n",
    "banknote_validation.visualize_output_distribution()\n",
    "banknote_test.visualize_output_distribution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, encoder_last_layer_activation=ENCODER_ACTIVATION_FN, decoder_last_layer_activation=DECODER_ACTIVATION_FN):\n",
    "        super().__init__()\n",
    "\n",
    "        # calculate the number of neurons for each layer\n",
    "        neuron_list = []\n",
    "        running_size = input_size\n",
    "        while(running_size > hidden_size):\n",
    "            neuron_list.append(running_size)\n",
    "            running_size = running_size // 2\n",
    "        neuron_list.append(hidden_size)\n",
    "\n",
    "        # Encoder layers\n",
    "        encoder_layers = []\n",
    "        length = len(neuron_list)\n",
    "        for i in range(length-1):\n",
    "            encoder_layers.append(nn.Linear(neuron_list[i], neuron_list[i+1]))\n",
    "            if(i != length-2):\n",
    "                encoder_layers.append(nn.ReLU())\n",
    "            else:\n",
    "                encoder_layers.append(encoder_last_layer_activation)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers) # asterisk (*) operator to unpack the list into separate arguments\n",
    "\n",
    "\n",
    "        # Decoder layers\n",
    "        decoder_layers = []\n",
    "        for i in range(length - 1, 0, -1):\n",
    "            decoder_layers.append(nn.Linear(neuron_list[i], neuron_list[i-1]))\n",
    "            if(i != 1):\n",
    "                decoder_layers.append(nn.ReLU())\n",
    "            else:\n",
    "                decoder_layers.append(decoder_last_layer_activation)\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "# Sigmoid activation function to get values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Layer of single-qubit Hadamard gates. \"\"\"\n",
    "def Hadamard(nqubits):\n",
    "    return [qml.Hadamard(wires=idx) for idx in range(nqubits)]\n",
    "        \n",
    "\"\"\"Layer of parametrized qubit rotations around the y axis.\"\"\"\n",
    "def Rotation(w):\n",
    "    return [qml.RY(element, wires=idx) for idx, element in enumerate(w)]\n",
    "\n",
    "\"\"\"Layer of shifted CNots.\"\"\"\n",
    "def CNot(start, nqubits):\n",
    "    return [qml.CNOT(wires=[i, i + 1]) for i in range(start, nqubits - 1, 2)] \n",
    "\n",
    "\"\"\"Layer of CNOTs followed by another shifted layer of CNOTs and a Rotation Layer\"\"\"   \n",
    "def Entangle(weights): \n",
    "    return [[*CNot(0, len(w)), *CNot(1, len(w)), *Rotation(w)] for w in weights]\n",
    "\n",
    "\"\"\"Expectation values in the Z basis.\"\"\"\n",
    "def Measure(wires):\n",
    "    return [qml.expval(qml.PauliZ(position)) for position in wires]  \n",
    "\n",
    "\n",
    "\n",
    "dev_angle_embedding = qml.device('lightning.qubit', wires=VQC_width)\n",
    "dev_amplitude_embedding = qml.device('lightning.qubit', wires=wires_amplitude)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_angle_embedding, interface=\"torch\", diff_method='adjoint')\n",
    "def variational_circuit_angle_embedding(input, weights, out):\n",
    "    weights =  2.0 * torch.arctan(2 * weights) # weight remapping\n",
    "\n",
    "    # rewrite weights to have the same shape but just containing pi \n",
    "    # weights = torch.ones(weights.shape) * math.pi\n",
    "    # weights.requires_grad_() # to be able to differentiate\n",
    "\n",
    "    width = weights.shape[1]    \n",
    "    assert input.shape[0] == width, f\"Expected input of len {width}\"\n",
    "    input = input * np.pi - np.pi / 2.0   # Rescale [0, 1] to [-pi/2, pi/2]\n",
    "    Hadamard(width)               # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    Rotation(input)               # Embed features in the quantum node\n",
    "\n",
    "    Entangle(weights)             # Sequence of trainable variational layers\n",
    "    return Measure(range(out))    # Expectation values in the Z basis\n",
    "\n",
    "\n",
    "\n",
    "@qml.qnode(dev_amplitude_embedding, interface=\"torch\", diff_method='adjoint')\n",
    "def variational_circuit_amplitude_embedding(input, weights, out):\n",
    "    torch_pi = torch.tensor(math.pi)\n",
    "    weights =  torch_pi * torch.tanh(weights) # weight remapping\n",
    "    width = weights.shape[1]    \n",
    "    input = input.tolist()\n",
    "    qml.AmplitudeEmbedding(features=input, wires=range(width), normalize=True, pad_with=0.)  # Embed features in the quantum node\n",
    "    Entangle(weights)             # Sequence of trainable variational layers\n",
    "    return Measure(range(out))    # Expectation values in the Z basis\n",
    "\n",
    "\n",
    "\n",
    "class Circuit(nn.Module):\n",
    "    def __init__(self, width, depth, out, amplitude_embedding):\n",
    "        super().__init__()\n",
    "        self.out = out\n",
    "        self.params = torch.nn.Parameter(torch.randn(depth, width))\n",
    "        self.amplitude_embedding = amplitude_embedding\n",
    "\n",
    "    def forward(self, input):\n",
    "        if len(input.shape) > 1: return torch.cat([self(i).float().unsqueeze(0) for i in input])\n",
    "        if self.amplitude_embedding:\n",
    "            return variational_circuit_amplitude_embedding(input, self.params, self.out).float()\n",
    "        else:\n",
    "            return variational_circuit_angle_embedding(input, self.params, self.out).float()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit with Angle Embedding\n",
      "0: â”€â”€Hâ”€â”€RY(4.38)â”€â”€â•­â—â”€â”€RY(1.77)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(-2.26)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(1.94)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—\n",
      "1: â”€â”€Hâ”€â”€RY(8.20)â”€â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.50)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.32)â”€â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-2.61)â”€â•°X\n",
      "2: â”€â”€Hâ”€â”€RY(-3.01)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.64)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-0.36)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-0.40)â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€RY(-2.24)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(1.29)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(0.15)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(-0.76)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—\n",
      "â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-1.12)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.29)â”€â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.05)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-0.46)â”€â•°X\n",
      "â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(0.91)â”€â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-2.32)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.32)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-2.06)â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€RY(-2.46)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(-1.91)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(1.31)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(1.65)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—\n",
      "â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.55)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.12)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.71)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(0.31)â”€â•°X\n",
      "â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(0.66)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(0.61)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.21)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.21)â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€RY(-1.57)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(-1.08)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(1.89)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(0.90)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—\n",
      "â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.98)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-0.72)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-1.12)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-2.45)â”€â•°X\n",
      "â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.78)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.63)â”€â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-2.27)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-1.68)â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€RY(1.64)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(0.66)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(2.23)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€RY(1.33)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—\n",
      "â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.37)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(2.10)â”€â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-0.30)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.74)â”€â•°X\n",
      "â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.34)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-1.04)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-2.28)â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.85)â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€RY(-2.36)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  <Z>\n",
      "â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(1.76)â”€â”€â”¤  <Z>\n",
      "â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RY(-1.66)â”€â”¤     \n",
      "\n",
      "Circuit with Amplitude Embedding\n",
      "0: â”€â•­AmplitudeEmbedding(M0)â”€â•­â—â”€â”€RY(1.30)â”€â”€â•­â—â”€â”€RY(2.74)â”€â”€â•­â—â”€â”€RY(-1.58)â”€â•­â—â”€â”€RY(-2.85)â”€â•­â—â”€â”€RY(0.61)â”€â”€â•­â—\n",
      "1: â”€â•°AmplitudeEmbedding(M0)â”€â•°Xâ”€â”€RY(-0.03)â”€â•°Xâ”€â”€RY(-0.86)â”€â•°Xâ”€â”€RY(-3.12)â”€â•°Xâ”€â”€RY(2.42)â”€â”€â•°Xâ”€â”€RY(-1.97)â”€â•°X\n",
      "\n",
      "â”€â”€â”€RY(2.94)â”€â•­â—â”€â”€RY(2.35)â”€â•­â—â”€â”€RY(-0.16)â”€â•­â—â”€â”€RY(-1.80)â”€â•­â—â”€â”€RY(-2.34)â”€â•­â—â”€â”€RY(0.23)â”€â•­â—â”€â”€RY(1.53)â”€â•­â—\n",
      "â”€â”€â”€RY(1.05)â”€â•°Xâ”€â”€RY(2.81)â”€â•°Xâ”€â”€RY(-1.75)â”€â•°Xâ”€â”€RY(2.95)â”€â”€â•°Xâ”€â”€RY(-1.77)â”€â•°Xâ”€â”€RY(1.60)â”€â•°Xâ”€â”€RY(2.65)â”€â•°X\n",
      "\n",
      "â”€â”€â”€RY(-0.12)â”€â•­â—â”€â”€RY(-1.44)â”€â•­â—â”€â”€RY(1.65)â”€â”€â•­â—â”€â”€RY(-0.45)â”€â•­â—â”€â”€RY(-0.27)â”€â•­â—â”€â”€RY(1.68)â”€â”€â•­â—â”€â”€RY(-1.10)â”€â•­â—\n",
      "â”€â”€â”€RY(-2.09)â”€â•°Xâ”€â”€RY(-1.09)â”€â•°Xâ”€â”€RY(-2.58)â”€â•°Xâ”€â”€RY(-0.60)â”€â•°Xâ”€â”€RY(2.78)â”€â”€â•°Xâ”€â”€RY(-1.41)â”€â•°Xâ”€â”€RY(-2.73)â”€â•°X\n",
      "\n",
      "â”€â”€â”€RY(2.94)â”€â”¤  <Z>\n",
      "â”€â”€â”€RY(3.04)â”€â”¤  <Z>\n"
     ]
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput,params = torch.randn(VQC_width), torch.nn.Parameter(torch.randn(LAYERS_ANGLE_EMBEDDING, VQC_width))\\nprint(\"Circuit with Angle Embedding\")\\nprint(qml.draw(variational_circuit_angle_embedding)(input, params, num_classes))\\nprint(\"\\nCircuit with Amplitude Embedding\")\\ninput,params = torch.randn(input_dimension), torch.nn.Parameter(torch.randn(LAYERS_AMPLITUDE_EMBEDDING, wires_amplitude))\\nprint(qml.draw(variational_circuit_amplitude_embedding)(input, params, num_classes))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 8ef5d6a885ab34c067ab9fe8d09f7dcbf8eb112f
    }
   ],
   "source": [
    "VQC_width = 3\n",
    "LAYERS_ANGLE_EMBEDDING = 2\n",
    "input,params = torch.randn(VQC_width), torch.nn.Parameter(torch.randn(LAYERS_ANGLE_EMBEDDING, VQC_width))\n",
    "print(\"Circuit with Angle Embedding\")\n",
    "print(qml.draw(variational_circuit_angle_embedding)(input, params, num_classes))\n",
    "print(\"\\nCircuit with Amplitude Embedding\")\n",
    "input,params = torch.randn(input_dimension), torch.nn.Parameter(torch.randn(LAYERS_AMPLITUDE_EMBEDDING, wires_amplitude))\n",
    "print(qml.draw(variational_circuit_amplitude_embedding)(input, params, num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumCircuit(torch.nn.Module):\n",
    "  def __init__(self, width, depth, i=input_dimension, o=num_classes):\n",
    "    \"\"\" :param i,o: Input, Output dimension, :params width, depth: Internal net width (i.e. n_qubits) and depth (number of variational layers)\"\"\"\n",
    "    super().__init__()\n",
    "    self.pre_processing  = torch.nn.Sequential(torch.nn.Linear(i, width), PREPROCESSING_DRESSED_ACTICATION_FN) \n",
    "    self.circuit = Circuit(width, depth, width, amplitude_embedding=False)\n",
    "    self.post_processing = torch.nn.Linear(width, o)\n",
    "  \n",
    "  def train(self, mode): \n",
    "    if mode == 'classical': setgrad(True, self.pre_processing, self.post_processing); setgrad(False, self.circuit)\n",
    "    if mode == 'quantum': setgrad(True, self.circuit); setgrad(False, self.pre_processing, self.post_processing)\n",
    "    if mode == 'hybrid': setgrad(True, self.pre_processing, self.circuit, self.post_processing)\n",
    "\n",
    "  def forward(self, input): return self.post_processing(self.circuit(self.pre_processing(input.float())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEQUENT(torch.nn.Module):\n",
    "  \"\"\" Sequential Quantum Enhanced Training (SEQUENT) \"\"\"\n",
    "  def __init__(self, width, depth, i=input_dimension, o=num_classes):\n",
    "    \"\"\" :params i,o: Input, Output dimension, :params width, depth: Internal net width (i.e. n_qubits) and depth (number of variational layers)\"\"\"\n",
    "    super().__init__()\n",
    "    self.compression  = torch.nn.Sequential(torch.nn.Linear(i, width),PREPROCESSING_SEQUENT_ACTICATION_FN) \n",
    "    self.surrogate = torch.nn.Sequential(torch.nn.Linear(width, o))\n",
    "    self.circuit = Circuit(width, depth, o, amplitude_embedding=False)\n",
    "\n",
    "  def train(self, mode): \n",
    "    if mode == 'classical': self.classification = self.surrogate; setgrad(False, self.circuit); setgrad(True, self.compression, self.surrogate)\n",
    "    if mode == 'quantum': self.classification = self.circuit; setgrad(True, self.circuit); setgrad(False, self.compression, self.surrogate)\n",
    "    if mode == 'hybrid': self.classification = self.circuit; setgrad(True, self.compression, self.circuit); setgrad(False, self.surrogate)\n",
    "\n",
    "  def forward(self, input): return self.classification(self.compression(input.float()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder(model, dataset_test, batch_size):\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for original_images_val, _ in dataloader_test:\n",
    "            recon_images_val = model(original_images_val)\n",
    "            loss = criterion(recon_images_val, original_images_val)\n",
    "            test_loss += loss.item() * original_images_val.shape[0] \n",
    "\n",
    "    # Compute average test loss for the epoch\n",
    "    test_loss /= len(dataloader_test.dataset)\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataset_test, batch_size):\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "    model.eval()\n",
    "    results_list = []\n",
    "    test_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in dataloader_test:\n",
    "            test_predictions = model(batch_inputs)\n",
    "            y_probs = torch.softmax(test_predictions, dim=1)\n",
    "            y_preds = torch.argmax(y_probs, dim=1)\n",
    "            print(y_preds)\n",
    "            y_trues = torch.argmax(batch_labels, dim=1)\n",
    "            \n",
    "            for i in range(len(batch_inputs)):\n",
    "                sample_result = (y_trues[i].item(), y_preds[i].item(), y_probs[i].tolist())\n",
    "                results_list.append(sample_result)\n",
    "\n",
    "            # Compute the test loss\n",
    "            loss = criterion(test_predictions, y_trues)\n",
    "            test_loss += loss.item() * batch_inputs.shape[0]\n",
    "\n",
    "            # Compute the test accuracy\n",
    "            total_accuracy += (y_preds == y_trues).sum().item()\n",
    "\n",
    "    # Calculate average test loss and test accuracy\n",
    "    avg_test_loss = test_loss / len(dataset_test)\n",
    "    avg_test_accuracy = total_accuracy / len(dataset_test)\n",
    "\n",
    "\n",
    "    return results_list, avg_test_loss, avg_test_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_autoencoder(model, dataset_train, dataset_validation, batch_size, num_epochs, learning_rate):\n",
    "    # Define the dataloader for efficient batch training\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_values = []\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for original_images, _ in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            recon_image = model(original_images)\n",
    "            loss = criterion(recon_image, original_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * original_images.size(0) # loss.item() * batch_size\n",
    "\n",
    "        # Compute average training loss for the epoch\n",
    "        train_loss /= len(dataloader_train.dataset)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for original_images_val, _ in dataloader_validation:\n",
    "                recon_images_val = model(original_images_val)\n",
    "                loss = criterion(recon_images_val, original_images_val)\n",
    "                val_loss += loss.item() * original_images_val.size(0) \n",
    "\n",
    "        # Compute average validation loss for the epoch\n",
    "        val_loss /= len(dataloader_validation.dataset)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        loss_values.append((epoch+1, train_loss, val_loss, epoch_time))\n",
    "        \n",
    "        # print out\n",
    "        print(f\"Epoch: [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_parameters(model):\n",
    "    for p in model.parameters():\n",
    "        print(p)\n",
    "        print(f\"p.shape: {p.shape}\")\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) \n",
    "    #numel() in order to calculate the total number of elements in a PyTorch tensor or parameter.\n",
    "\n",
    "\n",
    "def train_and_validate_model(model, dataset_train, dataset_validation, batch_size, num_epochs, learning_rate):    \n",
    "    # Define the dataloader for efficient batch training\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    result_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize the total loss and accuracy for this epoch\n",
    "        total_loss = 0.0\n",
    "        total_accuracy = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "\n",
    "        # Loop over the batches\n",
    "        for batch_inputs, batch_labels in dataloader_train:\n",
    "            # Reset the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the predictions\n",
    "            train_predictions = model(batch_inputs)\n",
    "            # Compute the loss\n",
    "            loss = criterion(train_predictions, batch_labels.argmax(dim=1))\n",
    "            # Accumulate the loss and accuracy\n",
    "            total_loss += loss.item() * batch_inputs.shape[0]\n",
    "            total_accuracy += (train_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute the average loss and accuracy for this epoch\n",
    "        avg_train_loss = total_loss / len(dataset_train)\n",
    "        avg_train_accuracy = total_accuracy / len(dataset_train)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        total_validation_loss = 0.0\n",
    "        total_validation_accuracy = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_labels in dataloader_validation:\n",
    "                val_predictions = model(batch_inputs)\n",
    "                val_loss = criterion(val_predictions, batch_labels.argmax(dim=1))\n",
    "                total_validation_loss += val_loss.item() * batch_inputs.shape[0]\n",
    "                total_validation_accuracy += (val_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "        \n",
    "        # Compute the average validation loss and accuracy for this epoch\n",
    "        avg_val_loss = total_validation_loss / len(dataset_validation)\n",
    "        avg_val_accuracy = total_validation_accuracy / len(dataset_validation)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        # Print the progress\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}, Train loss = {avg_train_loss:.4f}, Validation loss = {avg_val_loss:.4f}, Train accuracy = {avg_train_accuracy:.4f},  Validation accuracy = {avg_val_accuracy:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "        \n",
    "        # Add values to list\n",
    "        result_list.append((epoch+1, avg_train_loss, avg_val_loss, avg_train_accuracy, avg_val_accuracy, epoch_time))\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_SEQUENT_DRESSED(model, dataset_train, dataset_validation, dataset_test, stages, num_epochs, batch_size, learning_rate):\n",
    "    print('-' * 50)\n",
    "    print('-' * 50)\n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f\"epochs: {num_epochs}\")\n",
    "    print(f\"batch size: {batch_size}\")\n",
    "    print(f\"learning rate: {learning_rate}\")\n",
    "    print('-' * 50)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    for stage in stages:\n",
    "        print(f\"Training mode: {stage}\")\n",
    "        result_list_stage = []\n",
    "\n",
    "        \n",
    "        if stage == \"quantum\":\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = 0.001\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train(stage) # defines which part should be trained\n",
    "            total_loss = 0.0\n",
    "            total_accuracy = 0.0\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Loop over the batches\n",
    "            for batch_inputs, batch_labels in dataloader_train:\n",
    "                # Reset the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Compute the predictions\n",
    "                train_predictions = model(batch_inputs)\n",
    "                # Compute the loss\n",
    "                loss = criterion(train_predictions, batch_labels.argmax(dim=1))\n",
    "                # Accumulate the loss and accuracy\n",
    "                total_loss += loss.item() * batch_inputs.shape[0]\n",
    "                total_accuracy += (train_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "                # Compute the gradients\n",
    "                # if stage == \"classical\":\n",
    "                loss.backward()\n",
    "                # Update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "            # Compute the average loss and accuracy for this epoch\n",
    "            avg_train_loss = total_loss / len(dataset_train)\n",
    "            avg_train_accuracy = total_accuracy / len(dataset_train)\n",
    " \n",
    "\n",
    "            # Evaluate the model on the validation set\n",
    "            model.eval()\n",
    "            total_validation_loss = 0.0\n",
    "            total_validation_accuracy = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_inputs, batch_labels in dataloader_validation:\n",
    "                    val_predictions = model(batch_inputs)\n",
    "                    val_loss = criterion(val_predictions, batch_labels.argmax(dim=1))\n",
    "                    total_validation_loss += val_loss.item() * batch_inputs.shape[0]\n",
    "                    total_validation_accuracy += (val_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "            \n",
    "            # Compute the average validation loss and accuracy for this epoch\n",
    "            avg_val_loss = total_validation_loss / len(dataset_validation)\n",
    "            avg_val_accuracy = total_validation_accuracy / len(dataset_validation)\n",
    "\n",
    "            end_time = time.time()\n",
    "            epoch_time = end_time - start_time\n",
    "\n",
    "            # Print the progress\n",
    "            print(f\"Model: {model.__class__.__name__}, Stage: {stage} --- Epoch: {epoch + 1}/{num_epochs}, Train loss = {avg_train_loss:.4f}, Validation loss = {avg_val_loss:.4f}, Train accuracy = {avg_train_accuracy:.4f},  Validation accuracy = {avg_val_accuracy:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "            # Add values to list\n",
    "            result_list_stage.append((epoch+1, avg_train_loss, avg_val_loss, avg_train_accuracy, avg_val_accuracy, epoch_time))\n",
    "\n",
    "        # Add testing and validation values to list\n",
    "        result_list.append((stage, result_list_stage))\n",
    "\n",
    "        # Testing\n",
    "        test_list_stage, avg_test_loss, avg_test_accuracy = test_model(model, dataset_test, batch_size)\n",
    "        test_result_list.append((stage, test_list_stage, avg_test_loss, avg_test_accuracy))\n",
    "\n",
    "\n",
    "    return result_list, test_result_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder model \n",
    "autoencoder = Autoencoder(input_size=input_dimension, hidden_size=VQC_width, encoder_last_layer_activation=ENCODER_ACTIVATION_FN, decoder_last_layer_activation=DECODER_ACTIVATION_FN)\n",
    "print(\"\\nAutoencoder results\")\n",
    "# Train and validate the autoencoder model\n",
    "AE_loss_values = train_and_validate_autoencoder(model = autoencoder, dataset_train=banknote_train, dataset_validation=banknote_validation, batch_size=BATCH_SIZE_AE, num_epochs=EPOCHS_AE, learning_rate=LEARNING_RATE_AE)\n",
    "\n",
    "# Testing\n",
    "AE_test_loss = test_autoencoder(autoencoder, dataset_test=banknote_test, batch_size=BATCH_SIZE_AE)\n",
    "print(f\"AE test loss: {AE_test_loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 3, 1, 3, 1, 3, 1, 3, 3, 3, 1, 3, 1, 3,\n",
      "        3, 1, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3,\n",
      "        3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3, 1, 1, 3, 3, 1, 3, 3, 1, 1, 3,\n",
      "        3, 1, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 3, 1, 3, 3, 3,\n",
      "        3, 3, 3, 1, 3, 3, 1, 3])\n",
      "tensor([3, 1, 3, 3, 3, 3, 3, 1, 1, 3])\n",
      "0.07971014492753623\n"
     ]
    }
   ],
   "source": [
    "AE_testing_list, AE_testing_loss, AE_testing_accuracy = test_model(autoencoder, dataset_test=banknote_test, batch_size=BATCH_SIZE_AE)\n",
    "print(AE_testing_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "encoded_input_train.shape = torch.Size([1097, 2])\n",
      "y_train.shape = torch.Size([1097, 2])\n",
      "Minimum of X_train: 0.0\n",
      "Maximum of X_train: 1.0\n",
      "Minimum of encoded_input_train: 0.006891174707561731\n",
      "Maximum of encoded_input_train: 0.9582826495170593\n"
     ]
    }
   ],
   "source": [
    "# get the encoded input for training, validation, and testing\n",
    "encoded_input_train = autoencoder.encoder(banknote_train.X)\n",
    "encoded_input_train = encoded_input_train.detach()\n",
    "\n",
    "encoded_input_validation = autoencoder.encoder(banknote_validation.X)\n",
    "encoded_input_valiation = encoded_input_validation.detach()\n",
    "\n",
    "encoded_input_test = autoencoder.encoder(banknote_test.X)\n",
    "encoded_input_test = encoded_input_test.detach()\n",
    "\n",
    "\n",
    "# Visualize compressed input\n",
    "print(\"\\n\")\n",
    "print(f\"encoded_input_train.shape = {encoded_input_train.shape}\")\n",
    "print(f\"y_train.shape = {banknote_train.y.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Minimum of X_train: {torch.min(banknote_train.X)}\")\n",
    "print(f\"Maximum of X_train: {torch.max(banknote_train.X)}\")\n",
    "print(f\"Minimum of encoded_input_train: {torch.min(encoded_input_train)}\")\n",
    "print(f\"Maximum of encoded_input_train: {torch.max(encoded_input_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "encoded_input_train.shape[1] = 2\n",
      "Number of qubits = 2\n",
      "Number of layers = 6\n",
      "Number of output classes = 2\n",
      "\n",
      "Variational Quantum Circuit (with compressed input) results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Train loss = 0.5443, Validation loss = 0.5634, Train accuracy = 0.7284,  Validation accuracy = 0.7664, Epoch Time: 5.94 seconds\n",
      "Epoch: 2/10, Train loss = 0.5144, Validation loss = 0.5362, Train accuracy = 0.7657,  Validation accuracy = 0.7518, Epoch Time: 5.19 seconds\n",
      "Epoch: 3/10, Train loss = 0.5092, Validation loss = 0.6077, Train accuracy = 0.7639,  Validation accuracy = 0.6496, Epoch Time: 4.73 seconds\n",
      "Epoch: 4/10, Train loss = 0.5110, Validation loss = 0.5398, Train accuracy = 0.7603,  Validation accuracy = 0.7445, Epoch Time: 4.50 seconds\n",
      "Epoch: 5/10, Train loss = 0.5114, Validation loss = 0.5328, Train accuracy = 0.7657,  Validation accuracy = 0.7664, Epoch Time: 4.61 seconds\n",
      "Epoch: 6/10, Train loss = 0.5085, Validation loss = 0.5521, Train accuracy = 0.7657,  Validation accuracy = 0.7518, Epoch Time: 4.44 seconds\n",
      "Epoch: 7/10, Train loss = 0.5054, Validation loss = 0.5631, Train accuracy = 0.7566,  Validation accuracy = 0.7226, Epoch Time: 4.65 seconds\n",
      "Epoch: 8/10, Train loss = 0.5092, Validation loss = 0.5390, Train accuracy = 0.7566,  Validation accuracy = 0.7518, Epoch Time: 4.66 seconds\n",
      "Epoch: 9/10, Train loss = 0.5053, Validation loss = 0.5534, Train accuracy = 0.7548,  Validation accuracy = 0.7080, Epoch Time: 4.74 seconds\n",
      "Epoch: 10/10, Train loss = 0.5032, Validation loss = 0.5423, Train accuracy = 0.7666,  Validation accuracy = 0.7664, Epoch Time: 4.60 seconds\n",
      "VQC (Angle Embedding) | test loss: 0.5392087428034216, test accuracy: 0.6884057971014492\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(f\"encoded_input_train.shape[1] = {encoded_input_train.shape[1]}\")\n",
    "print(f\"Number of qubits = {VQC_width}\")\n",
    "print(f\"Number of layers = {LAYERS_ANGLE_EMBEDDING}\")\n",
    "print(f\"Number of output classes = {num_classes}\")\n",
    "\n",
    "# Create a TensorDataset for the encoded/compressed input\n",
    "compressed_dataset_train = torch.utils.data.TensorDataset(encoded_input_train, banknote_train.y)\n",
    "compressed_dataset_validation = torch.utils.data.TensorDataset(encoded_input_validation, banknote_validation.y)\n",
    "compressed_dataset_test = torch.utils.data.TensorDataset(encoded_input_test, banknote_test.y)\n",
    "\n",
    "# Initialize the quantum circuit module\n",
    "circuit = Circuit(VQC_width, LAYERS_ANGLE_EMBEDDING, num_classes,  amplitude_embedding=False)\n",
    "\n",
    "# Train and validate the VQC\n",
    "VQC_angle_list = []\n",
    "print(\"\\nVariational Quantum Circuit (with compressed input) results\")\n",
    "VQC_angle_list = train_and_validate_model(circuit, compressed_dataset_train, compressed_dataset_validation, BATCH_SIZE_VQC, EPOCHS_VQC, LEARNING_RATE_VQC)    \n",
    "\n",
    "\n",
    "# Testing\n",
    "VQC_angle_testing_list, VQC_angle_testing_loss, VQC_angle_testing_accuracy = test_model(circuit, dataset_test=compressed_dataset_test, batch_size=BATCH_SIZE_VQC)\n",
    "print(f\"VQC (Angle Embedding) | test loss: {VQC_angle_testing_loss}, test accuracy: {VQC_angle_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder + Classical feedforward Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters in the VQC: 12\n",
      "NN input size: 2\n",
      "NN hidden neurons: 2\n",
      "NN output size: 2\n",
      "Trainable parameters in the NN: 12\n",
      "\n",
      "Feedforward NN (with compressed input) results\n",
      "Epoch: 1/10, Train loss = 0.6879, Validation loss = 0.6884, Train accuracy = 0.5579,  Validation accuracy = 0.5620, Epoch Time: 0.20 seconds\n",
      "Epoch: 2/10, Train loss = 0.6869, Validation loss = 0.6712, Train accuracy = 0.5524,  Validation accuracy = 0.5693, Epoch Time: 0.16 seconds\n",
      "Epoch: 3/10, Train loss = 0.6238, Validation loss = 0.5870, Train accuracy = 0.6718,  Validation accuracy = 0.7299, Epoch Time: 0.14 seconds\n",
      "Epoch: 4/10, Train loss = 0.5246, Validation loss = 0.5514, Train accuracy = 0.7566,  Validation accuracy = 0.7299, Epoch Time: 0.14 seconds\n",
      "Epoch: 5/10, Train loss = 0.4987, Validation loss = 0.5354, Train accuracy = 0.7584,  Validation accuracy = 0.7372, Epoch Time: 0.14 seconds\n",
      "Epoch: 6/10, Train loss = 0.4891, Validation loss = 0.5631, Train accuracy = 0.7566,  Validation accuracy = 0.7518, Epoch Time: 0.16 seconds\n",
      "Epoch: 7/10, Train loss = 0.4885, Validation loss = 0.5711, Train accuracy = 0.7438,  Validation accuracy = 0.7372, Epoch Time: 0.15 seconds\n",
      "Epoch: 8/10, Train loss = 0.4903, Validation loss = 0.5452, Train accuracy = 0.7502,  Validation accuracy = 0.7664, Epoch Time: 0.15 seconds\n",
      "Epoch: 9/10, Train loss = 0.4826, Validation loss = 0.5754, Train accuracy = 0.7666,  Validation accuracy = 0.7445, Epoch Time: 0.14 seconds\n",
      "Epoch: 10/10, Train loss = 0.4887, Validation loss = 0.5615, Train accuracy = 0.7530,  Validation accuracy = 0.7445, Epoch Time: 0.16 seconds\n",
      "NN (with compressed input) | test loss: 0.5583732253399448, test accuracy: 0.7463768115942029\n"
     ]
    }
   ],
   "source": [
    "num_VQC_params = count_trainable_parameters(circuit)\n",
    "input_size = VQC_width\n",
    "output_size = num_classes\n",
    "\n",
    "# The formula for the total number N of parameters of a network with one hidden layer is:\n",
    "# N = (input_size * hidden_size) + hidden_size + (hidden_size * output_size) + output_size\n",
    "# Rearranging leads to:\n",
    "# N = hidden_size * (input_size + output_size + 1) + output_size\n",
    "# This leads to:\n",
    "# hidden_size = (N - output) / (input_size + output_size + 1)\n",
    "\n",
    "# Since I don't want to make the number of trainable parameters less than the total number in the VQC for fairness reasons, I round up.\n",
    "hidden_neurons = max(1, math.ceil((num_VQC_params - output_size) / (input_size + output_size + 1)))\n",
    "\n",
    "neural_network = ClassicalNeuralNetwork(input_size, hidden_neurons, output_size)\n",
    "\n",
    "\n",
    "num_network_parameters = count_trainable_parameters(neural_network)\n",
    "\n",
    "print(f\"\\nTrainable parameters in the VQC: {num_VQC_params}\")\n",
    "print(f\"NN input size: {input_size}\")\n",
    "print(f\"NN hidden neurons: {hidden_neurons}\")\n",
    "print(f\"NN output size: {output_size}\")\n",
    "print(f\"Trainable parameters in the NN: {num_network_parameters}\")\n",
    "\n",
    "assert num_network_parameters >= num_VQC_params, \"Number of trainable parameters in the network is less than number_VQC_params.\"\n",
    "    \n",
    "\n",
    "# Train and validate the NN on the compressed input\n",
    "NN_with_compressed_input_list = []\n",
    "print(\"\\nFeedforward NN (with compressed input) results\")\n",
    "NN_with_compressed_input_list =  train_and_validate_model(neural_network, compressed_dataset_train, compressed_dataset_validation, BATCH_SIZE_AE_NN, EPOCHS_AE_NN, LEARNING_RATE_AE_NN)   \n",
    "\n",
    "# Testing\n",
    "NN_with_compressed_input_testing_list, NN_with_compressed_input_testing_loss, NN_with_compressed_input_testing_accuracy = test_model(neural_network, dataset_test=compressed_dataset_test, batch_size=BATCH_SIZE_AE_NN)\n",
    "print(f\"NN (with compressed input) | test loss: {NN_with_compressed_input_testing_loss}, test accuracy: {NN_with_compressed_input_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical feedforward Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters in the AE+VQC combined: 34\n",
      "NN input size: 4\n",
      "NN hidden neurons: 5\n",
      "NN output size: 2\n",
      "Trainable parameters in the NN: 37\n",
      "\n",
      "Feedforward NN (with original input) results\n",
      "Epoch: 1/10, Train loss = 0.5560, Validation loss = 0.4530, Train accuracy = 0.7329,  Validation accuracy = 0.8175, Epoch Time: 0.14 seconds\n",
      "Epoch: 2/10, Train loss = 0.2979, Validation loss = 0.2629, Train accuracy = 0.9015,  Validation accuracy = 0.9270, Epoch Time: 0.12 seconds\n",
      "Epoch: 3/10, Train loss = 0.1804, Validation loss = 0.1527, Train accuracy = 0.9444,  Validation accuracy = 0.9416, Epoch Time: 0.10 seconds\n",
      "Epoch: 4/10, Train loss = 0.1171, Validation loss = 0.1037, Train accuracy = 0.9626,  Validation accuracy = 0.9708, Epoch Time: 0.08 seconds\n",
      "Epoch: 5/10, Train loss = 0.0920, Validation loss = 0.0679, Train accuracy = 0.9717,  Validation accuracy = 0.9781, Epoch Time: 0.11 seconds\n",
      "Epoch: 6/10, Train loss = 0.0825, Validation loss = 0.0499, Train accuracy = 0.9717,  Validation accuracy = 0.9854, Epoch Time: 0.09 seconds\n",
      "Epoch: 7/10, Train loss = 0.0701, Validation loss = 0.0542, Train accuracy = 0.9754,  Validation accuracy = 0.9854, Epoch Time: 0.09 seconds\n",
      "Epoch: 8/10, Train loss = 0.0651, Validation loss = 0.0588, Train accuracy = 0.9809,  Validation accuracy = 0.9854, Epoch Time: 0.13 seconds\n",
      "Epoch: 9/10, Train loss = 0.0555, Validation loss = 0.0461, Train accuracy = 0.9818,  Validation accuracy = 0.9854, Epoch Time: 0.14 seconds\n",
      "Epoch: 10/10, Train loss = 0.0538, Validation loss = 0.0316, Train accuracy = 0.9818,  Validation accuracy = 0.9854, Epoch Time: 0.14 seconds\n",
      "NN (with original input) | test loss: 0.07649019064273739, test accuracy: 0.9710144927536232\n"
     ]
    }
   ],
   "source": [
    "num_AE_params = count_trainable_parameters(autoencoder)\n",
    "num_VQC_params = count_trainable_parameters(circuit)\n",
    "num_trainable_params_combined = num_AE_params + num_VQC_params\n",
    "input_size_just_NN = banknote_train.input_dimension\n",
    "output_size_just_NN = banknote_train.num_classes\n",
    "# For the formula for the hidden neurons, see above:\n",
    "hidden_neurons_just_NN = max(1, math.ceil((num_trainable_params_combined - output_size_just_NN) / (input_size_just_NN + output_size_just_NN + 1)))\n",
    "\n",
    "neural_network_just_NN = ClassicalNeuralNetwork(input_size_just_NN, hidden_neurons_just_NN, output_size_just_NN)\n",
    "\n",
    "num_just_NN_parameters = count_trainable_parameters(neural_network_just_NN)\n",
    "\n",
    "print(f\"\\nTrainable parameters in the AE+VQC combined: {num_trainable_params_combined}\")\n",
    "print(f\"NN input size: {input_size_just_NN}\")\n",
    "print(f\"NN hidden neurons: {hidden_neurons_just_NN}\")\n",
    "print(f\"NN output size: {output_size_just_NN}\")\n",
    "print(f\"Trainable parameters in the NN: {num_just_NN_parameters}\")\n",
    "\n",
    "assert num_just_NN_parameters >= num_trainable_params_combined, \"Number of trainable parameters in the network is less than the number in AE + VQC combined.\"\n",
    "\n",
    "# Train and validate the NN on the original input\n",
    "NN_with_original_input_list = []\n",
    "print(\"\\nFeedforward NN (with original input) results\")\n",
    "NN_with_original_input_list =  train_and_validate_model(neural_network_just_NN, banknote_train, banknote_validation, BATCH_SIZE_ONLY_NN, EPOCHS_ONLY_NN, LEARNING_RATE_ONLY_NN)    \n",
    "\n",
    "\n",
    "# Testing\n",
    "NN_with_original_input_testing_list, NN_with_original_input_testing_loss, NN_with_original_input_testing_accuracy = test_model(neural_network_just_NN, dataset_test=banknote_test, batch_size=BATCH_SIZE_ONLY_NN)\n",
    "print(f\"NN (with original input) | test loss: {NN_with_original_input_testing_loss}, test accuracy: {NN_with_original_input_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQC with Amplitude Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the quantum circuit module\n",
    "circuit_amplitude = Circuit(wires_amplitude, LAYERS_AMPLITUDE_EMBEDDING, num_classes, amplitude_embedding=True)\n",
    "\n",
    "# Train and validate the VQC (amplitude embedding)\n",
    "VQC_amplitude_list = []\n",
    "print(\"\\nVariational Quantum Circuit (with original input, but with amplitude embedding) results\")\n",
    "VQC_amplitude_list = train_and_validate_model(circuit_amplitude, banknote_train, banknote_validation, BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING, EPOCHS_VQC_AMPLITUDE_EMBEDDING, LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING) \n",
    "\n",
    "\n",
    "# Testing\n",
    "VQC_amplitude_testing_list, VQC_amplitude_testing_loss, VQC_amplitude_testing_accuracy = test_model(circuit_amplitude, dataset_test=banknote_test, batch_size=EPOCHS_VQC_AMPLITUDE_EMBEDDING)\n",
    "print(f\"VQC (Amplitude Embedding) | test loss: {VQC_amplitude_testing_loss}, test accuracy: {VQC_amplitude_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequent and Dressed Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequent and Dressed results\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Model: SEQUENT\n",
      "epochs: 10\n",
      "batch size: 5\n",
      "learning rate: 0.001\n",
      "--------------------------------------------------\n",
      "Training mode: classical\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 1/10, Train loss = 0.6872, Validation loss = 0.6875, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.19 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 2/10, Train loss = 0.6863, Validation loss = 0.6868, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.18 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 3/10, Train loss = 0.6857, Validation loss = 0.6862, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.18 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 4/10, Train loss = 0.6852, Validation loss = 0.6858, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.19 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 5/10, Train loss = 0.6848, Validation loss = 0.6855, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.16 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 6/10, Train loss = 0.6845, Validation loss = 0.6852, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.19 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 7/10, Train loss = 0.6843, Validation loss = 0.6851, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.18 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 8/10, Train loss = 0.6842, Validation loss = 0.6849, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.17 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 9/10, Train loss = 0.6840, Validation loss = 0.6848, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.18 seconds\n",
      "Model: SEQUENT, Stage: classical --- Epoch: 10/10, Train loss = 0.6839, Validation loss = 0.6847, Train accuracy = 0.5597,  Validation accuracy = 0.5620, Epoch Time: 0.20 seconds\n",
      "Training mode: quantum\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 1/10, Train loss = 0.8449, Validation loss = 0.7685, Train accuracy = 0.4403,  Validation accuracy = 0.4380, Epoch Time: 5.86 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 2/10, Train loss = 0.7429, Validation loss = 0.7164, Train accuracy = 0.4321,  Validation accuracy = 0.4015, Epoch Time: 5.93 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 3/10, Train loss = 0.7155, Validation loss = 0.7020, Train accuracy = 0.3610,  Validation accuracy = 0.4891, Epoch Time: 7.45 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 4/10, Train loss = 0.7078, Validation loss = 0.6979, Train accuracy = 0.4695,  Validation accuracy = 0.4964, Epoch Time: 8.03 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 5/10, Train loss = 0.7053, Validation loss = 0.6959, Train accuracy = 0.5068,  Validation accuracy = 0.5255, Epoch Time: 8.52 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 6/10, Train loss = 0.7041, Validation loss = 0.6951, Train accuracy = 0.5077,  Validation accuracy = 0.5693, Epoch Time: 8.87 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 7/10, Train loss = 0.7035, Validation loss = 0.6946, Train accuracy = 0.5059,  Validation accuracy = 0.5620, Epoch Time: 8.64 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 8/10, Train loss = 0.7030, Validation loss = 0.6942, Train accuracy = 0.5096,  Validation accuracy = 0.5620, Epoch Time: 9.23 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 9/10, Train loss = 0.7027, Validation loss = 0.6940, Train accuracy = 0.5278,  Validation accuracy = 0.5693, Epoch Time: 9.65 seconds\n",
      "Model: SEQUENT, Stage: quantum --- Epoch: 10/10, Train loss = 0.7023, Validation loss = 0.6938, Train accuracy = 0.5169,  Validation accuracy = 0.5693, Epoch Time: 8.74 seconds\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Model: DressedQuantumCircuit\n",
      "epochs: 10\n",
      "batch size: 5\n",
      "learning rate: 0.001\n",
      "--------------------------------------------------\n",
      "Training mode: classical\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 1/10, Train loss = 0.6516, Validation loss = 0.6570, Train accuracy = 0.6664,  Validation accuracy = 0.7080, Epoch Time: 9.54 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 2/10, Train loss = 0.6408, Validation loss = 0.6490, Train accuracy = 0.7265,  Validation accuracy = 0.7226, Epoch Time: 8.46 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 3/10, Train loss = 0.6336, Validation loss = 0.6436, Train accuracy = 0.7384,  Validation accuracy = 0.6788, Epoch Time: 8.30 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 4/10, Train loss = 0.6285, Validation loss = 0.6397, Train accuracy = 0.7174,  Validation accuracy = 0.6861, Epoch Time: 8.15 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 5/10, Train loss = 0.6243, Validation loss = 0.6365, Train accuracy = 0.7119,  Validation accuracy = 0.6277, Epoch Time: 7.98 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 6/10, Train loss = 0.6208, Validation loss = 0.6338, Train accuracy = 0.6983,  Validation accuracy = 0.6496, Epoch Time: 8.48 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 7/10, Train loss = 0.6176, Validation loss = 0.6312, Train accuracy = 0.7001,  Validation accuracy = 0.6569, Epoch Time: 9.29 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 8/10, Train loss = 0.6146, Validation loss = 0.6288, Train accuracy = 0.6983,  Validation accuracy = 0.6569, Epoch Time: 9.47 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 9/10, Train loss = 0.6117, Validation loss = 0.6264, Train accuracy = 0.6992,  Validation accuracy = 0.6569, Epoch Time: 8.26 seconds\n",
      "Model: DressedQuantumCircuit, Stage: classical --- Epoch: 10/10, Train loss = 0.6087, Validation loss = 0.6240, Train accuracy = 0.6983,  Validation accuracy = 0.6569, Epoch Time: 8.88 seconds\n",
      "Training mode: quantum\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 1/10, Train loss = 0.6072, Validation loss = 0.6233, Train accuracy = 0.6983,  Validation accuracy = 0.6569, Epoch Time: 9.87 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 2/10, Train loss = 0.6065, Validation loss = 0.6230, Train accuracy = 0.6992,  Validation accuracy = 0.6569, Epoch Time: 9.56 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 3/10, Train loss = 0.6057, Validation loss = 0.6226, Train accuracy = 0.7001,  Validation accuracy = 0.6569, Epoch Time: 9.50 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 4/10, Train loss = 0.6051, Validation loss = 0.6221, Train accuracy = 0.7019,  Validation accuracy = 0.6569, Epoch Time: 9.77 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 5/10, Train loss = 0.6047, Validation loss = 0.6222, Train accuracy = 0.7083,  Validation accuracy = 0.6569, Epoch Time: 9.43 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 6/10, Train loss = 0.6042, Validation loss = 0.6221, Train accuracy = 0.7019,  Validation accuracy = 0.6569, Epoch Time: 9.47 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 7/10, Train loss = 0.6040, Validation loss = 0.6215, Train accuracy = 0.6964,  Validation accuracy = 0.6569, Epoch Time: 9.87 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 8/10, Train loss = 0.6038, Validation loss = 0.6210, Train accuracy = 0.7019,  Validation accuracy = 0.6569, Epoch Time: 9.04 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 9/10, Train loss = 0.6033, Validation loss = 0.6207, Train accuracy = 0.7019,  Validation accuracy = 0.6496, Epoch Time: 10.50 seconds\n",
      "Model: DressedQuantumCircuit, Stage: quantum --- Epoch: 10/10, Train loss = 0.6032, Validation loss = 0.6205, Train accuracy = 0.7001,  Validation accuracy = 0.6569, Epoch Time: 9.02 seconds\n",
      "\n",
      "Results for Sequent and Dressed\n",
      "\n",
      "Testing\n",
      "Sequent (Classical) | test loss: 0.6938732948856078, test accuracy: 0.5144927536231884\n",
      "Sequent (Quantum) | test loss: 0.7096039441184722, test accuracy: 0.4855072463768116\n",
      "DQC (Classical) | test loss: 0.6231509822866191, test accuracy: 0.6304347826086957\n",
      "DQC (Quantum) | test loss: 0.6178483654191529, test accuracy: 0.6666666666666666\n",
      "sequent_classical_testing_list: [(1, 0.6871988437560437, 0.6875038012100833, 0.5597082953509571, 0.5620437956204379, 0.19290971755981445), (2, 0.6862755547139247, 0.6867516549834369, 0.5597082953509571, 0.5620437956204379, 0.1831529140472412), (3, 0.6856554250012992, 0.6861969715487348, 0.5597082953509571, 0.5620437956204379, 0.18005633354187012), (4, 0.6851877879857365, 0.6857830964735825, 0.5597082953509571, 0.5620437956204379, 0.187514066696167), (5, 0.6848309859429692, 0.6854684043974772, 0.5597082953509571, 0.5620437956204379, 0.16288042068481445), (6, 0.6845446319175832, 0.6852322346972723, 0.5597082953509571, 0.5620437956204379, 0.1855001449584961), (7, 0.6843406865025176, 0.6850680356478169, 0.5597082953509571, 0.5620437956204379, 0.18056011199951172), (8, 0.6841908042932926, 0.6849289271083191, 0.5597082953509571, 0.5620437956204379, 0.17484068870544434), (9, 0.684049345899302, 0.6848176691653954, 0.5597082953509571, 0.5620437956204379, 0.18277502059936523), (10, 0.683945737487094, 0.6847161898647782, 0.5597082953509571, 0.5620437956204379, 0.19583678245544434)]\n",
      "sequent_quantum_testing_list: [(0, 1, [0.4934808909893036, 0.5065191388130188]), (1, 0, [0.5310483574867249, 0.46895164251327515]), (1, 0, [0.5900177359580994, 0.40998223423957825]), (1, 0, [0.5740499496459961, 0.4259500205516815]), (0, 0, [0.5301186442375183, 0.4698813557624817]), (0, 0, [0.5306962132453918, 0.46930375695228577]), (1, 0, [0.5887099504470825, 0.41129007935523987]), (1, 0, [0.5095762610435486, 0.49042370915412903]), (1, 0, [0.5684657692909241, 0.4315342307090759]), (0, 0, [0.5345845222473145, 0.4654155671596527]), (1, 0, [0.5120030641555786, 0.4879968762397766]), (0, 0, [0.5756919384002686, 0.42430809140205383]), (0, 0, [0.5305899381637573, 0.46941009163856506]), (1, 0, [0.5461212992668152, 0.4538787305355072]), (1, 1, [0.4945925772190094, 0.505407452583313]), (1, 0, [0.5629445910453796, 0.43705540895462036]), (1, 0, [0.5610695481300354, 0.4389304220676422]), (1, 0, [0.5944107174873352, 0.40558934211730957]), (0, 0, [0.535422146320343, 0.46457788348197937]), (1, 0, [0.5304955840110779, 0.4695044159889221]), (0, 0, [0.5749068856239319, 0.4250930845737457]), (0, 0, [0.5549064874649048, 0.4450935125350952]), (0, 0, [0.5563740730285645, 0.44362589716911316]), (1, 1, [0.49550625681877136, 0.504493772983551]), (0, 0, [0.557493269443512, 0.44250673055648804]), (0, 0, [0.5096384286880493, 0.4903615415096283]), (0, 0, [0.560912549495697, 0.439087450504303]), (1, 0, [0.5839555859565735, 0.4160443842411041]), (1, 0, [0.5732085704803467, 0.4267914593219757]), (0, 0, [0.5419514179229736, 0.45804858207702637]), (0, 0, [0.5495877861976624, 0.4504122734069824]), (1, 0, [0.5579555034637451, 0.44204452633857727]), (0, 0, [0.5485185384750366, 0.4514814615249634]), (0, 0, [0.5013869404792786, 0.49861305952072144]), (1, 0, [0.5237372517585754, 0.47626277804374695]), (1, 0, [0.5441681742668152, 0.45583176612854004]), (1, 0, [0.5203104019165039, 0.4796895682811737]), (0, 0, [0.5496183037757874, 0.45038169622421265]), (1, 0, [0.5784412622451782, 0.42155879735946655]), (1, 0, [0.5511494278907776, 0.4488505423069]), (1, 0, [0.5427964925765991, 0.4572034776210785]), (0, 0, [0.5363202691078186, 0.46367979049682617]), (0, 0, [0.551612377166748, 0.44838765263557434]), (0, 0, [0.5465410947799683, 0.4534589648246765]), (0, 0, [0.5609908699989319, 0.4390091300010681]), (1, 0, [0.5426163673400879, 0.45738357305526733]), (1, 0, [0.5588086247444153, 0.44119134545326233]), (0, 0, [0.515960156917572, 0.484039843082428]), (1, 0, [0.528765857219696, 0.4712340831756592]), (0, 0, [0.5646384954452515, 0.4353615641593933]), (0, 0, [0.5407060980796814, 0.4592939019203186]), (0, 1, [0.49826779961586, 0.5017321705818176]), (0, 0, [0.5059760808944702, 0.4940239489078522]), (1, 0, [0.5937063694000244, 0.4062936305999756]), (1, 0, [0.5469492077827454, 0.453050822019577]), (1, 0, [0.5417768955230713, 0.4582230746746063]), (1, 0, [0.548597514629364, 0.45140254497528076]), (0, 0, [0.5686348080635071, 0.4313652217388153]), (1, 0, [0.6096920371055603, 0.3903079330921173]), (1, 0, [0.5583850741386414, 0.44161486625671387]), (0, 1, [0.4981812536716461, 0.5018187761306763]), (0, 0, [0.5400014519691467, 0.45999857783317566]), (1, 0, [0.5120620131492615, 0.48793795704841614]), (0, 1, [0.4950180649757385, 0.5049819350242615]), (0, 0, [0.5806556940078735, 0.41934430599212646]), (1, 0, [0.5147614479064941, 0.48523855209350586]), (0, 0, [0.5709880590438843, 0.4290119707584381]), (1, 0, [0.5465623736381531, 0.4534376561641693]), (1, 0, [0.553800642490387, 0.44619929790496826]), (1, 0, [0.5472135543823242, 0.4527864158153534]), (0, 0, [0.5552113652229309, 0.4447886347770691]), (0, 0, [0.5461198091506958, 0.4538802206516266]), (1, 0, [0.5434359312057495, 0.4565640687942505]), (0, 0, [0.5259844660758972, 0.4740155339241028]), (0, 0, [0.573996901512146, 0.4260031282901764]), (0, 0, [0.5523132681846619, 0.44768673181533813]), (1, 0, [0.5118314027786255, 0.4881685972213745]), (0, 0, [0.5621510744094849, 0.4378489851951599]), (1, 0, [0.5869214534759521, 0.4130784869194031]), (0, 0, [0.5247284770011902, 0.4752715229988098]), (1, 0, [0.5091968774795532, 0.4908030927181244]), (1, 0, [0.5716004371643066, 0.42839959263801575]), (0, 0, [0.5721606016159058, 0.42783939838409424]), (0, 0, [0.5009633898735046, 0.49903663992881775]), (1, 0, [0.5497757792472839, 0.45022422075271606]), (0, 0, [0.5254158973693848, 0.47458416223526]), (0, 0, [0.5663306713104248, 0.4336693584918976]), (0, 0, [0.5709889531135559, 0.4290110766887665]), (0, 0, [0.5644024014472961, 0.43559759855270386]), (0, 0, [0.5697848796844482, 0.43021512031555176]), (1, 0, [0.5617555379867554, 0.43824440240859985]), (1, 0, [0.5323513150215149, 0.4676486551761627]), (1, 0, [0.5863681435585022, 0.4136318564414978]), (1, 0, [0.5550665259361267, 0.4449334442615509]), (1, 0, [0.585883617401123, 0.41411638259887695]), (1, 0, [0.5692049860954285, 0.43079498410224915]), (1, 0, [0.6075153350830078, 0.3924846947193146]), (0, 0, [0.5671500563621521, 0.4328498840332031]), (1, 0, [0.5958613753318787, 0.40413859486579895]), (0, 1, [0.49650534987449646, 0.5034946799278259]), (1, 0, [0.5033497214317322, 0.4966502785682678]), (0, 0, [0.5487293004989624, 0.4512706995010376]), (0, 0, [0.5676386952400208, 0.43236133456230164]), (1, 0, [0.5426886677742004, 0.45731133222579956]), (1, 0, [0.5976613163948059, 0.40233874320983887]), (0, 0, [0.5361767411231995, 0.4638232886791229]), (1, 0, [0.5570052862167358, 0.44299474358558655]), (0, 0, [0.568673849105835, 0.43132615089416504]), (0, 0, [0.5592107772827148, 0.44078922271728516]), (1, 0, [0.5584763884544373, 0.44152358174324036]), (1, 0, [0.6172850728034973, 0.3827148675918579]), (0, 0, [0.5636577010154724, 0.4363422989845276]), (1, 0, [0.5855614542961121, 0.4144385755062103]), (0, 0, [0.5223484039306641, 0.4776516258716583]), (1, 0, [0.5668259263038635, 0.4331740438938141]), (0, 0, [0.5227664113044739, 0.47723355889320374]), (0, 0, [0.5507397651672363, 0.44926026463508606]), (1, 0, [0.574565589427948, 0.4254344403743744]), (1, 0, [0.5969389081001282, 0.4030611515045166]), (0, 0, [0.5627301335334778, 0.4372698664665222]), (1, 0, [0.5381704568862915, 0.46182960271835327]), (0, 0, [0.5240663886070251, 0.4759335517883301]), (0, 0, [0.5591738224029541, 0.4408262073993683]), (0, 0, [0.5854619741439819, 0.41453802585601807]), (0, 0, [0.5295912027359009, 0.47040873765945435]), (0, 0, [0.5339404940605164, 0.46605950593948364]), (1, 0, [0.5058782696723938, 0.4941217601299286]), (0, 0, [0.5323123335838318, 0.46768760681152344]), (0, 1, [0.4917369484901428, 0.508263111114502]), (1, 0, [0.5354207754135132, 0.46457919478416443]), (0, 0, [0.5213360786437988, 0.47866398096084595]), (1, 0, [0.5896224975585938, 0.41037750244140625]), (1, 0, [0.5845359563827515, 0.4154640734195709]), (1, 0, [0.578436553478241, 0.4215635359287262]), (0, 0, [0.560912549495697, 0.439087450504303]), (0, 0, [0.5284040570259094, 0.4715959429740906]), (0, 0, [0.5352876782417297, 0.46471232175827026]), (0, 0, [0.5761454701423645, 0.4238545596599579])]\n",
      "dressed_classical_testing_list: [(1, 0, [0.5141975283622742, 0.48580244183540344]), (0, 0, [0.5574201941490173, 0.4425797164440155]), (0, 0, [0.6135609745979309, 0.38643908500671387]), (1, 0, [0.6284282207489014, 0.371571809053421]), (1, 1, [0.4230893552303314, 0.576910674571991]), (0, 0, [0.6578450202941895, 0.34215500950813293]), (1, 0, [0.6390061378479004, 0.3609938323497772]), (1, 0, [0.5708847045898438, 0.429115355014801]), (0, 0, [0.6909838318824768, 0.3090161979198456]), (0, 0, [0.6007906794548035, 0.39920932054519653]), (1, 0, [0.5738591551780701, 0.42614084482192993]), (1, 0, [0.5746737122535706, 0.4253261983394623]), (1, 1, [0.42223823070526123, 0.5777617692947388]), (1, 0, [0.5483970642089844, 0.45160290598869324]), (1, 0, [0.5455790162086487, 0.4544210135936737]), (0, 0, [0.5536859631538391, 0.44631409645080566]), (0, 0, [0.6127322912216187, 0.38726767897605896]), (1, 0, [0.5619850754737854, 0.4380149245262146]), (0, 0, [0.6195192337036133, 0.3804807960987091]), (1, 0, [0.5981844067573547, 0.40181559324264526]), (0, 0, [0.6615671515464783, 0.33843281865119934]), (1, 0, [0.6185000538825989, 0.3814999461174011]), (0, 0, [0.6060368418693542, 0.39396318793296814]), (0, 0, [0.6371009945869446, 0.3628990352153778]), (1, 0, [0.5510234236717224, 0.4489765167236328]), (1, 1, [0.4593368470668793, 0.5406631231307983]), (0, 0, [0.5331849455833435, 0.4668150842189789]), (1, 0, [0.5428190231323242, 0.45718100666999817]), (0, 0, [0.5899927616119385, 0.4100072681903839]), (0, 0, [0.5589480996131897, 0.4410519003868103]), (1, 0, [0.5582996606826782, 0.4417003393173218]), (0, 0, [0.5120244026184082, 0.4879756569862366]), (1, 0, [0.5557937026023865, 0.4442063271999359]), (0, 0, [0.6165199279785156, 0.38348013162612915]), (1, 0, [0.5289627909660339, 0.47103720903396606]), (0, 0, [0.608444094657898, 0.39155590534210205]), (0, 0, [0.6442755460739136, 0.35572442412376404]), (1, 0, [0.5273101925849915, 0.47268980741500854]), (1, 0, [0.5532210469245911, 0.44677895307540894]), (1, 0, [0.5034463405609131, 0.4965536892414093]), (1, 0, [0.5483978986740112, 0.45160210132598877]), (1, 1, [0.4704149663448334, 0.529585063457489]), (1, 1, [0.3951249122619629, 0.6048750877380371]), (0, 0, [0.5723152160644531, 0.4276847541332245]), (1, 0, [0.5238800048828125, 0.4761199355125427]), (0, 0, [0.5331849455833435, 0.4668150842189789]), (0, 0, [0.6615817546844482, 0.33841824531555176]), (0, 0, [0.6120997667312622, 0.38790029287338257]), (1, 1, [0.4925866425037384, 0.5074133276939392]), (1, 1, [0.46887505054473877, 0.5311249494552612]), (1, 0, [0.5018420815467834, 0.49815791845321655]), (1, 0, [0.5303682684898376, 0.46963170170783997]), (0, 0, [0.6774497032165527, 0.3225502669811249]), (0, 0, [0.5796228051185608, 0.4203771650791168]), (0, 0, [0.5941837430000305, 0.4058162271976471]), (1, 0, [0.524386465549469, 0.4756135642528534]), (1, 0, [0.5403510332107544, 0.4596490263938904]), (0, 0, [0.6554915308952332, 0.34450846910476685]), (1, 0, [0.558958113193512, 0.44104188680648804]), (1, 0, [0.5811699628829956, 0.41883009672164917]), (1, 1, [0.4273067116737366, 0.5726932287216187]), (1, 0, [0.612550675868988, 0.38744938373565674]), (0, 0, [0.6048862338066101, 0.3951137363910675]), (0, 0, [0.5581229329109192, 0.4418770968914032]), (0, 0, [0.5829944014549255, 0.41700559854507446]), (0, 0, [0.599463164806366, 0.4005368649959564]), (0, 0, [0.541571319103241, 0.45842868089675903]), (0, 0, [0.579767644405365, 0.4202323853969574]), (1, 0, [0.5760778188705444, 0.42392224073410034]), (1, 0, [0.5252574682235718, 0.4747425317764282]), (0, 0, [0.616515040397644, 0.38348495960235596]), (0, 0, [0.6140837073326111, 0.3859163522720337]), (0, 0, [0.5157777070999146, 0.4842222332954407]), (1, 1, [0.4656469225883484, 0.5343531370162964]), (0, 0, [0.6139933466911316, 0.3860066533088684]), (0, 0, [0.5222716331481934, 0.47772839665412903]), (0, 0, [0.5821454524993896, 0.41785454750061035]), (0, 0, [0.5961188673973083, 0.40388113260269165]), (0, 0, [0.6141037940979004, 0.3858962059020996]), (1, 0, [0.50959312915802, 0.49040693044662476]), (0, 0, [0.6396622657775879, 0.36033767461776733]), (1, 0, [0.5024915337562561, 0.4975084364414215]), (1, 0, [0.5140435099601746, 0.4859565496444702]), (0, 0, [0.6752416491508484, 0.3247583508491516]), (0, 0, [0.6650503277778625, 0.33494964241981506]), (1, 0, [0.5907542705535889, 0.40924569964408875]), (1, 0, [0.5145148038864136, 0.48548516631126404]), (0, 0, [0.5865465998649597, 0.4134533703327179]), (0, 0, [0.6885327696800232, 0.3114672601222992]), (0, 0, [0.656674325466156, 0.343325674533844]), (0, 0, [0.5592160820960999, 0.44078391790390015]), (1, 0, [0.6281808018684387, 0.3718191683292389]), (1, 0, [0.5032582879066467, 0.49674174189567566]), (0, 0, [0.6435542702674866, 0.3564457595348358]), (0, 0, [0.6218203902244568, 0.3781795799732208]), (0, 0, [0.6287074089050293, 0.3712925612926483]), (1, 1, [0.3823351562023163, 0.6176648139953613]), (0, 0, [0.6102809309959412, 0.38971906900405884]), (0, 0, [0.6847689151763916, 0.3152311444282532]), (1, 0, [0.5102494955062866, 0.489750474691391]), (1, 0, [0.5130676627159119, 0.4869323670864105]), (1, 1, [0.39955219626426697, 0.6004477739334106]), (1, 1, [0.44110968708992004, 0.5588903427124023]), (1, 0, [0.5473814606666565, 0.4526185691356659]), (1, 0, [0.6046154499053955, 0.3953845202922821]), (1, 0, [0.5484073162078857, 0.45159268379211426]), (0, 0, [0.5615641474723816, 0.43843579292297363]), (1, 1, [0.4371687173843384, 0.5628313422203064]), (0, 0, [0.7033019065856934, 0.2966981530189514]), (0, 0, [0.635621964931488, 0.36437806487083435]), (0, 0, [0.5971818566322327, 0.4028181731700897]), (0, 0, [0.6475489735603333, 0.35245099663734436]), (1, 1, [0.41869455575942993, 0.5813053846359253]), (0, 0, [0.5827468037605286, 0.41725313663482666]), (0, 0, [0.6256086230278015, 0.3743913471698761]), (1, 0, [0.5260059237480164, 0.47399410605430603]), (0, 0, [0.6704556941986084, 0.3295443058013916]), (1, 1, [0.39442741870880127, 0.6055725812911987]), (0, 0, [0.6565097570419312, 0.34349024295806885]), (1, 0, [0.5137539505958557, 0.4862460792064667]), (1, 0, [0.585879921913147, 0.414120078086853]), (1, 0, [0.5921040773391724, 0.40789589285850525]), (0, 0, [0.6599512100219727, 0.34004876017570496]), (0, 0, [0.5056809186935425, 0.4943191111087799]), (0, 0, [0.6438499689102173, 0.3561500310897827]), (1, 0, [0.5601387023925781, 0.43986132740974426]), (0, 0, [0.5876359939575195, 0.4123639762401581]), (0, 0, [0.6168065667152405, 0.3831934630870819]), (0, 0, [0.5945004820823669, 0.40549951791763306]), (0, 0, [0.6356043219566345, 0.3643956482410431]), (0, 0, [0.6594012975692749, 0.3405987322330475]), (0, 0, [0.5223507285118103, 0.4776492416858673]), (1, 0, [0.6253235340118408, 0.3746764659881592]), (1, 1, [0.38831058144569397, 0.6116893887519836]), (1, 0, [0.5854349732398987, 0.41456496715545654]), (0, 0, [0.6271077394485474, 0.3728923201560974]), (1, 0, [0.6077854633331299, 0.3922145664691925]), (1, 0, [0.5680051445960999, 0.43199482560157776])]\n",
      "dressed_quantum_testing_list: [(1, 0, [0.502345621585846, 0.49765434861183167]), (1, 0, [0.5424044728279114, 0.4575956165790558]), (0, 0, [0.6107349991798401, 0.3892649710178375]), (1, 0, [0.5867908596992493, 0.4132091999053955]), (1, 0, [0.6172796487808228, 0.38272038102149963]), (0, 0, [0.5510478019714355, 0.44895222783088684]), (0, 0, [0.5494047999382019, 0.4505952000617981]), (0, 0, [0.5138170719146729, 0.48618289828300476]), (0, 0, [0.588934063911438, 0.411065936088562]), (1, 0, [0.552385151386261, 0.4476148784160614]), (0, 0, [0.6140280365943909, 0.3859719932079315]), (0, 0, [0.6045135855674744, 0.395486444234848]), (1, 0, [0.518253743648529, 0.48174625635147095]), (0, 0, [0.5922375321388245, 0.4077624976634979]), (0, 0, [0.5811175107955933, 0.41888248920440674]), (0, 0, [0.5769755840301514, 0.42302441596984863]), (0, 0, [0.5522511005401611, 0.44774892926216125]), (0, 0, [0.5461927652359009, 0.45380714535713196]), (0, 0, [0.6002581119537354, 0.39974191784858704]), (1, 1, [0.4904484450817108, 0.5095515251159668]), (1, 1, [0.40838900208473206, 0.5916109681129456]), (0, 0, [0.659731388092041, 0.340268611907959]), (0, 0, [0.6616908311843872, 0.3383091986179352]), (0, 0, [0.590464174747467, 0.40953585505485535]), (1, 1, [0.44573184847831726, 0.5542681813240051]), (1, 0, [0.6106113195419312, 0.3893886208534241]), (1, 0, [0.6244180202484131, 0.3755819797515869]), (1, 0, [0.6057198643684387, 0.3942801058292389]), (1, 0, [0.6010022759437561, 0.3989977538585663]), (1, 0, [0.5506649017333984, 0.4493350386619568]), (0, 0, [0.5844817161560059, 0.41551825404167175]), (0, 0, [0.6424435377120972, 0.3575564920902252]), (1, 0, [0.5548253655433655, 0.44517460465431213]), (1, 0, [0.5031859874725342, 0.49681398272514343]), (1, 0, [0.5035220384597778, 0.4964779317378998]), (1, 1, [0.3807389438152313, 0.6192610263824463]), (1, 0, [0.6402072906494141, 0.3597927391529083]), (1, 0, [0.5391808748245239, 0.4608190953731537]), (0, 0, [0.5655994415283203, 0.4344005882740021]), (0, 0, [0.6710771322250366, 0.3289228677749634]), (1, 1, [0.4986829161643982, 0.5013170838356018]), (0, 0, [0.7080870866775513, 0.29191291332244873]), (0, 0, [0.6101195216178894, 0.3898804783821106]), (0, 0, [0.6949411034584045, 0.30505892634391785]), (1, 1, [0.4558101296424866, 0.5441899299621582]), (1, 1, [0.42715567350387573, 0.5728443264961243]), (0, 0, [0.5817471742630005, 0.4182528257369995]), (0, 0, [0.5067746639251709, 0.49322524666786194]), (1, 0, [0.5526338219642639, 0.4473661184310913]), (1, 1, [0.4031563103199005, 0.5968436598777771]), (1, 1, [0.4575633108615875, 0.5424366593360901]), (0, 0, [0.6598951816558838, 0.3401048183441162]), (1, 0, [0.5700001120567322, 0.429999977350235]), (0, 0, [0.6063055992126465, 0.39369437098503113]), (0, 0, [0.6448249816894531, 0.3551749885082245]), (0, 0, [0.5769187211990356, 0.42308127880096436]), (1, 0, [0.6289542317390442, 0.3710457980632782]), (1, 1, [0.49078553915023804, 0.509214460849762]), (0, 0, [0.6106588840484619, 0.3893411457538605]), (0, 0, [0.5543556809425354, 0.4456443190574646]), (1, 1, [0.48065894842147827, 0.5193411111831665]), (0, 0, [0.5340481400489807, 0.4659518599510193]), (0, 0, [0.633176326751709, 0.366823673248291]), (0, 0, [0.6422684788703918, 0.35773158073425293]), (0, 0, [0.5123096704483032, 0.48769035935401917]), (0, 0, [0.6114339232444763, 0.3885660767555237]), (0, 0, [0.573634147644043, 0.42636585235595703]), (1, 0, [0.5205057859420776, 0.47949421405792236]), (0, 0, [0.5508583188056946, 0.44914165139198303]), (0, 0, [0.6882525086402893, 0.3117474913597107]), (1, 1, [0.4922369122505188, 0.5077630281448364]), (1, 1, [0.3854030966758728, 0.614596962928772]), (0, 0, [0.5246718525886536, 0.47532811760902405]), (0, 0, [0.6925687193870544, 0.3074312210083008]), (0, 0, [0.5733359456062317, 0.4266640245914459]), (0, 0, [0.6560354828834534, 0.34396451711654663]), (0, 0, [0.6077885627746582, 0.3922114968299866]), (0, 0, [0.6012894511222839, 0.3987105190753937]), (1, 0, [0.579890787601471, 0.42010921239852905]), (0, 0, [0.6158161163330078, 0.3841839134693146]), (1, 1, [0.4124873876571655, 0.5875126719474792]), (1, 0, [0.5614126324653625, 0.43858736753463745]), (0, 0, [0.6098068356513977, 0.3901931941509247]), (1, 0, [0.5683650374412537, 0.4316349923610687]), (1, 1, [0.4071974456310272, 0.5928025841712952]), (1, 0, [0.5170062184333801, 0.48299381136894226]), (0, 0, [0.6183555126190186, 0.38164445757865906]), (0, 0, [0.6409445405006409, 0.35905545949935913]), (1, 0, [0.5749916434288025, 0.4250083863735199]), (1, 0, [0.5675594806671143, 0.43244051933288574]), (0, 0, [0.5945278406143188, 0.40547212958335876]), (1, 0, [0.5804200172424316, 0.41957998275756836]), (1, 0, [0.5448037981987, 0.45519620180130005]), (1, 0, [0.5201634764671326, 0.47983649373054504]), (0, 0, [0.5762574076652527, 0.4237425923347473]), (1, 0, [0.5868582129478455, 0.41314175724983215]), (0, 0, [0.6577905416488647, 0.34220945835113525]), (0, 0, [0.656079113483429, 0.34392082691192627]), (1, 0, [0.5480271577835083, 0.4519729018211365]), (1, 0, [0.5373262166976929, 0.46267375349998474]), (1, 1, [0.36650165915489197, 0.6334983706474304]), (1, 0, [0.5648085474967957, 0.43519148230552673]), (0, 0, [0.5007458925247192, 0.4992540776729584]), (0, 0, [0.6370695233345032, 0.36293041706085205]), (1, 1, [0.42294377088546753, 0.5770562887191772]), (0, 0, [0.661383867263794, 0.33861619234085083]), (0, 0, [0.6128612756729126, 0.3871387243270874]), (0, 0, [0.6250761151313782, 0.37492382526397705]), (0, 1, [0.49479126930236816, 0.5052086710929871]), (1, 0, [0.6267964243888855, 0.37320366501808167]), (1, 1, [0.37278035283088684, 0.6272196769714355]), (1, 0, [0.5144070982933044, 0.48559296131134033]), (1, 1, [0.3800675570964813, 0.6199324727058411]), (0, 0, [0.6548870205879211, 0.34511294960975647]), (1, 0, [0.5144480466842651, 0.485552042722702]), (0, 0, [0.5975083112716675, 0.40249165892601013]), (1, 0, [0.5934510231018066, 0.40654897689819336]), (0, 0, [0.6239082217216492, 0.37609174847602844]), (1, 0, [0.5336604118347168, 0.4663395583629608]), (1, 1, [0.49238693714141846, 0.5076130628585815]), (0, 0, [0.6256095767021179, 0.3743904232978821]), (0, 0, [0.5912072062492371, 0.4087928235530853]), (1, 0, [0.532842218875885, 0.467157781124115]), (0, 0, [0.5246718525886536, 0.47532811760902405]), (1, 0, [0.503303050994873, 0.49669694900512695]), (1, 0, [0.5398802161216736, 0.4601197838783264]), (0, 0, [0.6465521454811096, 0.353447824716568]), (0, 0, [0.6655363440513611, 0.33446359634399414]), (1, 1, [0.49927738308906555, 0.5007225275039673]), (1, 0, [0.5040874481201172, 0.4959125816822052]), (1, 0, [0.5480568408966064, 0.45194321870803833]), (1, 1, [0.45279163122177124, 0.5472083687782288]), (0, 0, [0.6348303556442261, 0.3651696443557739]), (0, 0, [0.6161825656890869, 0.38381752371788025]), (0, 0, [0.6774213910102844, 0.3225786089897156]), (1, 0, [0.542521059513092, 0.45747897028923035]), (1, 0, [0.5154739618301392, 0.48452603816986084]), (0, 0, [0.6789798140525818, 0.3210202157497406])]\n"
     ]
    }
   ],
   "source": [
    "# initialize lists for the results\n",
    "sequent_classical_list = []\n",
    "sequent_quantum_list = []\n",
    "dressed_classical_list = []\n",
    "dressed_quantum_list = []\n",
    "\n",
    "sequent_classical_testing_list = []\n",
    "sequent_quantum_testing_list = []\n",
    "dressed_classical_testing_list = []\n",
    "dressed_quantum_testing_list = []\n",
    "sequent_classical_testing_loss = 0\n",
    "sequent_classical_testing_accuracy = 0\n",
    "sequent_quantum_testing_loss = 0\n",
    "sequent_quantum_testing_accuracy = 0\n",
    "dressed_classical_testing_loss = 0\n",
    "dressed_classical_testing_accuracy = 0\n",
    "dressed_quantum_testing_loss = 0\n",
    "dressed_quantum_testing_accuracy = 0\n",
    "\n",
    "\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    ('SEQUENT', SEQUENT(width=VQC_width, depth=LAYERS_SEQUENT), banknote_train, banknote_validation, banknote_test, ['classical', 'quantum'], EPOCHS_SEQUENT, LEARNING_RATE_SEQUENT),\n",
    "    ('DQC', DressedQuantumCircuit(width=VQC_width, depth=LAYERS_DRESSED), banknote_train, banknote_validation, banknote_test, ['classical', 'quantum'], EPOCHS_DRESSED, LEARNING_RATE_DRESSED)\n",
    "]\n",
    "\n",
    "print(\"\\nSequent and Dressed results\")\n",
    "\n",
    "# Train and test each model\n",
    "for name, model, train_dataset, validation_dataset, test_dataset, stages, epochs, lr in models:\n",
    "    batch_size = BATCH_SIZE_SEQUENT if name == 'SEQUENT' else BATCH_SIZE_DRESSED\n",
    "\n",
    "    # Training\n",
    "    model_results_list, model_test_results_list = train_and_validate_SEQUENT_DRESSED(\n",
    "        model, train_dataset, validation_dataset, test_dataset, stages, num_epochs=epochs, batch_size=batch_size, learning_rate=lr\n",
    "    )\n",
    "\n",
    "    for i in range(len(model_results_list)):\n",
    "        current_stage = model_results_list[i][0]\n",
    "        if name == 'SEQUENT' and current_stage == 'classical':\n",
    "            sequent_classical_list = model_results_list[i][1]\n",
    "        elif name == 'SEQUENT' and current_stage == 'quantum':\n",
    "            sequent_quantum_list = model_results_list[i][1]\n",
    "        elif name == 'DQC' and current_stage == 'classical':\n",
    "            dressed_classical_list = model_results_list[i][1]\n",
    "        elif name == 'DQC' and current_stage == 'quantum':\n",
    "            dressed_quantum_list = model_results_list[i][1]\n",
    "    \n",
    "    # Testing\n",
    "    for i in range(len(model_test_results_list)):\n",
    "        current_stage = model_test_results_list[i][0]\n",
    "        if name == 'SEQUENT' and current_stage == 'classical':\n",
    "            sequent_classical_testing_list = model_test_results_list[i][1]\n",
    "            sequent_classical_testing_loss = model_test_results_list[i][2]\n",
    "            sequent_classical_testing_accuracy = model_test_results_list[i][3]\n",
    "        elif name == 'SEQUENT' and current_stage == 'quantum':\n",
    "            sequent_quantum_testing_list = model_test_results_list[i][1]\n",
    "            sequent_quantum_testing_loss = model_test_results_list[i][2]\n",
    "            sequent_quantum_testing_accuracy = model_test_results_list[i][3]\n",
    "        elif name == 'DQC' and current_stage == 'classical':\n",
    "            dressed_classical_testing_list = model_test_results_list[i][1]\n",
    "            dressed_classical_testing_loss = model_test_results_list[i][2]\n",
    "            dressed_classical_testing_accuracy = model_test_results_list[i][3]\n",
    "        elif name == 'DQC' and current_stage == 'quantum':\n",
    "            dressed_quantum_testing_list = model_test_results_list[i][1]\n",
    "            dressed_quantum_testing_loss = model_test_results_list[i][2]\n",
    "            dressed_quantum_testing_accuracy = model_test_results_list[i][3]\n",
    "\n",
    "print(\"\\nResults for Sequent and Dressed\")\n",
    "print(\"\\nTesting\")\n",
    "print(f\"Sequent (Classical) | test loss: {sequent_classical_testing_loss}, test accuracy: {sequent_classical_testing_accuracy}\")\n",
    "print(f\"Sequent (Quantum) | test loss: {sequent_quantum_testing_loss}, test accuracy: {sequent_quantum_testing_accuracy}\")\n",
    "print(f\"DQC (Classical) | test loss: {dressed_classical_testing_loss}, test accuracy: {dressed_classical_testing_accuracy}\")\n",
    "print(f\"DQC (Quantum) | test loss: {dressed_quantum_testing_loss}, test accuracy: {dressed_quantum_testing_accuracy}\")\n",
    "\n",
    "\n",
    "print(f\"sequent_classical_testing_list: {sequent_classical_list}\")\n",
    "print(f\"sequent_quantum_testing_list: {sequent_quantum_testing_list}\")\n",
    "print(f\"dressed_classical_testing_list: {dressed_classical_testing_list}\")\n",
    "print(f\"dressed_quantum_testing_list: {dressed_quantum_testing_list}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "HYPERPARAMETERS = {\n",
    "    \"AE\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"AE_LEARNING_RATE\": LEARNING_RATE_AE,\n",
    "        \"AE_BATCH_SIZE\": BATCH_SIZE_AE,\n",
    "        \"AE_EPOCHS\": EPOCHS_AE,\n",
    "        \"AE_ENCODER_ACTIVATION_FN\": str(ENCODER_ACTIVATION_FN),\n",
    "        \"AE_DECODER_ACTIVATION_FN\": str(DECODER_ACTIVATION_FN),\n",
    "    },\n",
    "    \"VQC_angle\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_VQC,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_VQC,\n",
    "        \"EPOCHS\": EPOCHS_VQC,\n",
    "        \"LAYERS\": LAYERS_ANGLE_EMBEDDING,\n",
    "    },\n",
    "    \"VQC_amplitude\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING,\n",
    "        \"EPOCHS\": EPOCHS_VQC_AMPLITUDE_EMBEDDING,\n",
    "        \"LAYERS\": LAYERS_AMPLITUDE_EMBEDDING,\n",
    "    },\n",
    "    \"NN_compressedInput\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_AE_NN,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_AE_NN,\n",
    "        \"EPOCHS\": EPOCHS_AE_NN,\n",
    "    },\n",
    "    \"NN_originalInput\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_ONLY_NN,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_ONLY_NN,\n",
    "        \"EPOCHS\": EPOCHS_ONLY_NN,\n",
    "    },\n",
    "    \"SEQUENT\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"PREPROCESSING_ACTIVATION_FN\": str(PREPROCESSING_SEQUENT_ACTICATION_FN),\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_SEQUENT,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_SEQUENT,\n",
    "        \"EPOCHS\": EPOCHS_SEQUENT,\n",
    "        \"LAYERS\": LAYERS_SEQUENT\n",
    "    },\n",
    "    \"DRESSED\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"PREPROCESSING_ACTIVATION_FN\": str(PREPROCESSING_DRESSED_ACTICATION_FN),\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_DRESSED,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_DRESSED,\n",
    "        \"EPOCHS\": EPOCHS_DRESSED,\n",
    "        \"LAYERS\": LAYERS_DRESSED\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def save_list_to_csv(data_list, hyperparameters, list_name, autoencoder, testing, test_loss=None, test_accuracy=None):\n",
    "    dataset_name = \"BankNote_Authentication\"\n",
    "    header_list = []\n",
    "    result_list = []\n",
    "    header_list.append(\"Dataset\")\n",
    "    header_list.append(\"List Name\")\n",
    "    result_list.append(dataset_name)\n",
    "    result_list.append(list_name)\n",
    "\n",
    "\n",
    "    hyperparam_str = \"_\".join([f\"{param}-{value}\" for param, value in hyperparameters.items()])\n",
    "\n",
    "    # Add the hyperparameters for the AE to all csv files\n",
    "    AE_hyperparameters = HYPERPARAMETERS[\"AE\"]\n",
    "    for param, value in AE_hyperparameters.items():\n",
    "        header_list.append(param)\n",
    "        result_list.append(value)\n",
    "\n",
    "    # Add specific hyperparameters \n",
    "    if(not autoencoder):\n",
    "        for param, value in hyperparameters.items():\n",
    "            header_list.append(param)\n",
    "            result_list.append(value)\n",
    "\n",
    "    # Create the file name by combining the list name, hyperparameters, and the \".csv\" extension\n",
    "    file_name = f\"{dataset_name}--{list_name}_results_{hyperparam_str}.csv\"\n",
    "\n",
    "    # Save the list to the CSV file\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the column headers based on the type of result\n",
    "        if autoencoder:\n",
    "            header_list = header_list + [\"Epoch\", \"Train_Loss\", \"Validation_Loss\", \"Time\", \"Test_Loss\"]\n",
    "            writer.writerow(header_list)\n",
    "        elif testing:\n",
    "            header_list = header_list + [\"y_true\", \"y_pred\", \"y_probs\", \"Test_Loss\", \"Test_Accuracy\"]\n",
    "            writer.writerow(header_list)\n",
    "        else:\n",
    "            header_list = header_list + [\"Epoch\", \"Train_Loss\", \"Validation_Loss\", \"Train_Accuracy\", \"Validation_Accuracy\", \"Time\", \"Test_Loss\", \"Test_Accuracy\"]\n",
    "            writer.writerow(header_list)\n",
    "        \n",
    "        result_list = [list(result_list) + list(data) for data in data_list]\n",
    "\n",
    "        # if AE -> add the test loss\n",
    "        if(autoencoder):\n",
    "            result_list = [[*entry, test_loss] for entry in result_list]\n",
    "        else: # add test loss and test accuracy\n",
    "            result_list = [[*entry, test_loss, test_accuracy] for entry in result_list]\n",
    "\n",
    "        # Write the data rows\n",
    "        writer.writerows(result_list)\n",
    " \n",
    "\n",
    "# Training & Validation lists to csv\n",
    "save_list_to_csv(AE_loss_values, HYPERPARAMETERS[\"AE\"], \"AE_loss_values\", autoencoder=True, testing=False, test_loss=AE_test_loss)\n",
    "\n",
    "save_list_to_csv(VQC_angle_list, HYPERPARAMETERS[\"VQC_angle\"], \"VQC_angle_list\", autoencoder=False, testing=False, test_loss=VQC_angle_testing_loss, test_accuracy=VQC_angle_testing_accuracy)\n",
    "save_list_to_csv(NN_with_compressed_input_list, HYPERPARAMETERS[\"NN_compressedInput\"], \"NN_with_compressed_input_list\", autoencoder=False, testing=False, test_loss=NN_with_compressed_input_testing_loss, test_accuracy=NN_with_compressed_input_testing_accuracy)\n",
    "save_list_to_csv(NN_with_original_input_list, HYPERPARAMETERS[\"NN_originalInput\"], \"NN_with_original_input_list\", autoencoder=False, testing=False, test_loss=NN_with_original_input_testing_loss, test_accuracy=NN_with_original_input_testing_accuracy)\n",
    "save_list_to_csv(VQC_amplitude_list, HYPERPARAMETERS[\"VQC_amplitude\"], \"VQC_amplitude_list\", autoencoder=False, testing=False, test_loss=VQC_amplitude_testing_loss, test_accuracy=VQC_amplitude_testing_accuracy)\n",
    "save_list_to_csv(sequent_classical_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_classical_list\", autoencoder=False, testing=False, test_loss=sequent_classical_testing_loss, test_accuracy=sequent_classical_testing_accuracy)\n",
    "save_list_to_csv(sequent_quantum_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_quantum_list\", autoencoder=False, testing=False, test_loss=sequent_quantum_testing_loss, test_accuracy=sequent_quantum_testing_accuracy)\n",
    "save_list_to_csv(dressed_classical_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_classical_list\", autoencoder=False, testing=False, test_loss=dressed_classical_testing_loss, test_accuracy=dressed_classical_testing_accuracy)\n",
    "save_list_to_csv(dressed_quantum_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_quantum_list\", autoencoder=False, testing=False, test_loss=dressed_quantum_testing_loss, test_accuracy=dressed_quantum_testing_accuracy)\n",
    "\n",
    "# Testing lists to csv\n",
    "save_list_to_csv(VQC_angle_testing_list, HYPERPARAMETERS[\"VQC_angle\"], \"VQC_angle_testing_list\", autoencoder=False, testing=True, test_loss=VQC_angle_testing_loss, test_accuracy=VQC_angle_testing_accuracy)\n",
    "save_list_to_csv(NN_with_compressed_input_testing_list, HYPERPARAMETERS[\"NN_compressedInput\"], \"NN_with_compressed_input_testing_list\", autoencoder=False, testing=True, test_loss=NN_with_compressed_input_testing_loss, test_accuracy=NN_with_compressed_input_testing_accuracy)\n",
    "save_list_to_csv(NN_with_original_input_testing_list, HYPERPARAMETERS[\"NN_originalInput\"], \"NN_with_original_input_testing_list\", autoencoder=False, testing=True, test_loss=NN_with_original_input_testing_loss, test_accuracy=NN_with_original_input_testing_accuracy)\n",
    "save_list_to_csv(VQC_amplitude_testing_list, HYPERPARAMETERS[\"VQC_amplitude\"], \"VQC_amplitude_testing_list\", autoencoder=False, testing=True, test_loss=VQC_amplitude_testing_loss, test_accuracy=VQC_amplitude_testing_accuracy)\n",
    "save_list_to_csv(sequent_classical_testing_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_classical_testing_list\", autoencoder=False, testing=True, test_loss=sequent_classical_testing_loss, test_accuracy=sequent_classical_testing_accuracy)\n",
    "save_list_to_csv(sequent_quantum_testing_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_quantum_testing_list\", autoencoder=False, testing=True, test_loss=sequent_quantum_testing_loss, test_accuracy=sequent_quantum_testing_accuracy)\n",
    "save_list_to_csv(dressed_classical_testing_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_classical_testing_list\", autoencoder=False, testing=True, test_loss=dressed_classical_testing_loss, test_accuracy=dressed_classical_testing_accuracy)\n",
    "save_list_to_csv(dressed_quantum_testing_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_quantum_testing_list\", autoencoder=False, testing=True, test_loss=dressed_quantum_testing_loss, test_accuracy=dressed_quantum_testing_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"+\"*50)\n",
    "print(\"+\"*50)\n",
    "print(\"-\"*50)\n",
    "print(\"Results\")\n",
    "print(\"-\"*50)\n",
    "print(\"Training & Validation Results\")\n",
    "print(f\"AE_loss_values: {AE_loss_values}\")\n",
    "print(f\"VQC_angle_list: {VQC_angle_list}\")\n",
    "print(f\"NN_with_compressed_input_list: {NN_with_compressed_input_list}\")\n",
    "print(f\"NN_with_original_input_list: {NN_with_original_input_list}\")\n",
    "print(f\"VQC_amplitude_list: {VQC_amplitude_list}\")\n",
    "print(f\"sequent_classical_list: {sequent_classical_list}\")\n",
    "print(f\"sequent_quantum_list: {sequent_quantum_list}\")\n",
    "print(f\"dressed_classical_list: {dressed_classical_list}\")\n",
    "print(f\"dressed_quantum_list: {dressed_quantum_list}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Results\")\n",
    "print(f\"VQC_angle_testing_list: {VQC_angle_testing_list}\")\n",
    "print(f\"NN_with_compressed_input_testing_list: {NN_with_compressed_input_testing_list}\")\n",
    "print(f\"NN_with_original_input_testing_list: {NN_with_original_input_testing_list}\")\n",
    "print(f\"VQC_amplitude_testing_list: {VQC_amplitude_testing_list}\")\n",
    "print(f\"sequent_classical_testing_list: {sequent_classical_testing_list}\")\n",
    "print(f\"sequent_quantum_testing_list: {sequent_quantum_testing_list}\")\n",
    "print(f\"dressed_classical_testing_list: {dressed_classical_testing_list}\")\n",
    "print(f\"dressed_quantum_testing_list: {dressed_quantum_testing_list}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Test Loss and Accuracy\")\n",
    "print(f\"VQC with Angle Embedding | Test Loss: {VQC_angle_testing_loss}, Test Accuracy: {VQC_angle_testing_accuracy}\")\n",
    "print(f\"NN with compressed Input | Test Loss: {NN_with_compressed_input_testing_loss}, Test Accuracy: {NN_with_compressed_input_testing_accuracy}\")\n",
    "print(f\"NN with original Input | Test Loss: {NN_with_original_input_testing_loss}, Test Accuracy: {NN_with_original_input_testing_accuracy}\")\n",
    "print(f\"VQC with Amplitude Embedding | Test Loss: {VQC_amplitude_testing_loss}, Test Accuracy: {VQC_amplitude_testing_accuracy}\")\n",
    "print(f\"Sequent Classical Mode | Test Loss: {sequent_classical_testing_loss}, Test Accuracy: {sequent_classical_testing_accuracy}\")\n",
    "print(f\"Sequent Quantum Mode | Test Loss: {sequent_quantum_testing_loss}, Test Accuracy: {sequent_quantum_testing_accuracy}\")\n",
    "print(f\"Dressed Classical Mode| Test Loss: {dressed_classical_testing_loss}, Test Accuracy: {dressed_classical_testing_accuracy}\")\n",
    "print(f\"Dressed Quantum Mode | Test Loss: {dressed_quantum_testing_loss}, Test Accuracy: {dressed_quantum_testing_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
