{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Breast Cancer Detection\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "PennyLane version = 0.27.0\n",
      "Pytorch version = 1.9.0+cpu\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Reproducibility:\n",
      "Seed: 0\n",
      "\n",
      "AE:\n",
      "- Learning Rate: 0.0001\n",
      "- Batch Size: 32\n",
      "- Epochs: 500\n",
      "- Encoder Activation Function: Sigmoid()\n",
      "- Decoder Activation Function: Sigmoid()\n",
      "\n",
      "VQC with Angle Embedding:\n",
      "- Learning Rate: 0.5\n",
      "- Batch Size: 16\n",
      "- Epochs: 50\n",
      "- Layers: 2\n",
      "\n",
      "VQC with Amplitude Embedding:\n",
      "- Learning Rate: 0.5\n",
      "- Batch Size: 16\n",
      "- Epochs: 50\n",
      "- Layers: 2\n",
      "\n",
      "NN on Original Input:\n",
      "- Learning Rate: 0.5\n",
      "- Batch Size: 16\n",
      "- Epochs: 50\n",
      "\n",
      "NN on Compressed Input (with AE before):\n",
      "- Learning Rate: 0.5\n",
      "- Batch Size: 16\n",
      "- Epochs: 50\n",
      "\n",
      "Sequent:\n",
      "- Preprocessing Activation Function: Sigmoid()\n",
      "- Learning Rate: 0.5\n",
      "- Batch Size: 16\n",
      "- Epochs: 50\n",
      "- Layers: 2\n",
      "\n",
      "Dressed Quantum Circuit:\n",
      "- Preprocessing Activation Function: Sigmoid()\n",
      "- Learning Rate: 0.5\n",
      "- Batch Size: 16\n",
      "- Epochs: 50\n",
      "- Layers: 2\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random \n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "print(\"+\"*50)\n",
    "print(\"Breast Cancer Detection\")\n",
    "print(\"+\"*50)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"PennyLane version = {qml.version()}\")\n",
    "print(f\"Pytorch version = {torch. __version__ }\")\n",
    "\n",
    "setgrad = lambda g, *ms: [setattr(p,'requires_grad', g) for m in ms for p in m.parameters() ]\n",
    "\n",
    "SYS_SEED = 0\n",
    "SYS_BATCH_SIZE =  16\n",
    "SYS_LEARNING_RATE = 0.5\n",
    "SYS_LAYERS = 2\n",
    "\n",
    "EPOCHS_SETTING = 50\n",
    "\n",
    "# REPRODUCIBILITY \n",
    "SEED = SYS_SEED   # Seed for random initial weights\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# AE\n",
    "LEARNING_RATE_AE = 0.01\n",
    "BATCH_SIZE_AE = 32\n",
    "EPOCHS_AE = 500\n",
    "ENCODER_ACTIVATION_FN = nn.Sigmoid()\n",
    "DECODER_ACTIVATION_FN = nn.Sigmoid()\n",
    "\n",
    "# VQC with Angle Embedding\n",
    "LEARNING_RATE_VQC = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_VQC =  SYS_BATCH_SIZE\n",
    "EPOCHS_VQC = EPOCHS_SETTING\n",
    "LAYERS_ANGLE_EMBEDDING = SYS_LAYERS\n",
    "\n",
    "# VQC with Amplitude Embedding\n",
    "LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING =  SYS_BATCH_SIZE\n",
    "EPOCHS_VQC_AMPLITUDE_EMBEDDING = EPOCHS_SETTING\n",
    "LAYERS_AMPLITUDE_EMBEDDING = SYS_LAYERS\n",
    "\n",
    "# NN on original Input\n",
    "LEARNING_RATE_ONLY_NN = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_ONLY_NN = SYS_BATCH_SIZE\n",
    "EPOCHS_ONLY_NN = EPOCHS_SETTING\n",
    "\n",
    "# NN on compressed Input (with AE before) \n",
    "LEARNING_RATE_AE_NN = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_AE_NN = SYS_BATCH_SIZE\n",
    "EPOCHS_AE_NN = EPOCHS_SETTING\n",
    "\n",
    "# SEQUENT\n",
    "PREPROCESSING_SEQUENT_ACTICATION_FN = nn.Sigmoid()\n",
    "LEARNING_RATE_SEQUENT = SYS_LEARNING_RATE\n",
    "BATCH_SIZE_SEQUENT = SYS_BATCH_SIZE\n",
    "EPOCHS_SEQUENT = EPOCHS_SETTING\n",
    "LAYERS_SEQUENT = SYS_LAYERS\n",
    "\n",
    "# DRESSED\n",
    "PREPROCESSING_DRESSED_ACTICATION_FN = nn.Sigmoid()\n",
    "LEARNING_RATE_DRESSED =  SYS_LEARNING_RATE\n",
    "BATCH_SIZE_DRESSED = SYS_BATCH_SIZE\n",
    "EPOCHS_DRESSED = EPOCHS_SETTING\n",
    "LAYERS_DRESSED = SYS_LAYERS\n",
    "\n",
    "\n",
    "print('-' * 50)\n",
    "print('-' * 50)\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the information\n",
    "print(\"Reproducibility:\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(\"\\nAE:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_AE}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_AE}\")\n",
    "print(f\"- Epochs: {EPOCHS_AE}\")\n",
    "print(f\"- Encoder Activation Function: {ENCODER_ACTIVATION_FN}\")\n",
    "print(f\"- Decoder Activation Function: {DECODER_ACTIVATION_FN}\")\n",
    "print(\"\\nVQC with Angle Embedding:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_VQC}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_VQC}\")\n",
    "print(f\"- Epochs: {EPOCHS_VQC}\")\n",
    "print(f\"- Layers: {LAYERS_ANGLE_EMBEDDING}\")\n",
    "print(\"\\nVQC with Amplitude Embedding:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING}\")\n",
    "print(f\"- Epochs: {EPOCHS_VQC_AMPLITUDE_EMBEDDING}\")\n",
    "print(f\"- Layers: {LAYERS_AMPLITUDE_EMBEDDING}\")\n",
    "print(\"\\nNN on Original Input:\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_ONLY_NN}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_ONLY_NN}\")\n",
    "print(f\"- Epochs: {EPOCHS_ONLY_NN}\")\n",
    "print(\"\\nNN on Compressed Input (with AE before):\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_AE_NN}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_AE_NN}\")\n",
    "print(f\"- Epochs: {EPOCHS_AE_NN}\")\n",
    "print(\"\\nSequent:\")\n",
    "print(f\"- Preprocessing Activation Function: {PREPROCESSING_SEQUENT_ACTICATION_FN}\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_SEQUENT}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_SEQUENT}\")\n",
    "print(f\"- Epochs: {EPOCHS_SEQUENT}\")\n",
    "print(f\"- Layers: {LAYERS_SEQUENT}\")\n",
    "print(\"\\nDressed Quantum Circuit:\")\n",
    "print(f\"- Preprocessing Activation Function: {PREPROCESSING_DRESSED_ACTICATION_FN}\")\n",
    "print(f\"- Learning Rate: {LEARNING_RATE_DRESSED}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE_DRESSED}\")\n",
    "print(f\"- Epochs: {EPOCHS_DRESSED}\")\n",
    "print(f\"- Layers: {LAYERS_DRESSED}\")\n",
    "\n",
    "\n",
    "print('-' * 50)\n",
    "print('-' * 50)\n",
    "print('-' * 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, train=False, validation=False, test=False, seed=SEED):\n",
    "        # load data (no missing values present)\n",
    "        breast_cancer = load_breast_cancer()\n",
    "\n",
    "        # Split the dataset into X and y\n",
    "        X = breast_cancer.data\n",
    "        y = breast_cancer.target\n",
    "\n",
    "        # Store the input dimension of X\n",
    "        self.input_dimension = len(breast_cancer.feature_names)\n",
    "        # Store the output dimension\n",
    "        self.num_classes = len(breast_cancer.target_names)\n",
    "\n",
    "        # Store the feature names\n",
    "        self.feature_names = breast_cancer.feature_names\n",
    "        # Store the label name\n",
    "        self.label_names = breast_cancer.target_names\n",
    "\n",
    "        # Convert y to integer labels (already present)\n",
    "\n",
    "        # Apply one-hot encoding to y \n",
    "        y = np.eye(self.num_classes)[y]\n",
    "\n",
    "        # Apply Scaling\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        # Split: 80%, 10%, 10%\n",
    "        # here it makes no difference if we split the train-set into training & validation or the test-set because it comes from the same dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=seed, shuffle=True)\n",
    "\n",
    "        if train:\n",
    "            self.X = torch.tensor(X_train, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_train, dtype=torch.float32)\n",
    "        elif validation:\n",
    "            self.X = torch.tensor(X_val, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_val, dtype=torch.float32)     \n",
    "        elif test:\n",
    "            self.X = torch.tensor(X_test, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_test, dtype=torch.float32) \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return X, y \n",
    "\n",
    "    def visualize_output_distribution(self):\n",
    "        # Count the occurrences of each class\n",
    "        class_counts = self.y.sum(dim=0)\n",
    "\n",
    "        # Get the class labels\n",
    "        class_labels = self.label_names\n",
    "\n",
    "        # Plot the output distribution\n",
    "        plt.bar(class_labels, class_counts)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Output Distribution')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_train = BreastCancerDataset(train=True)\n",
    "breast_cancer_validation = BreastCancerDataset(validation=True)\n",
    "breast_cancer_test = BreastCancerDataset(test=True)\n",
    "\n",
    "\n",
    "num_classes = breast_cancer_train.num_classes\n",
    "input_dimension = breast_cancer_train.input_dimension\n",
    "\n",
    "# angle embedding: Encodes N features into the rotation angles of n qubits, where Nâ‰¤n\n",
    "VQC_width = num_classes\n",
    "# amplitude embedding: Encodes 2^n features into the amplitude vector of n qubits.\n",
    "wires_amplitude = max(math.ceil(math.log(input_dimension, 2)), num_classes) #at least as many qubits as output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 57, 57)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(breast_cancer_train), len(breast_cancer_validation), len(breast_cancer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of X_train: 1.0\n",
      "Minimum of X_train: 0.0\n",
      "Maximum of X_test: 1.0\n",
      "Minimum of X_test: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_train_max = torch.max(breast_cancer_train.X)\n",
    "X_train_min = torch.min(breast_cancer_train.X)\n",
    "X_test_max = torch.max(breast_cancer_test.X)\n",
    "X_test_min = torch.min(breast_cancer_test.X)\n",
    "\n",
    "\n",
    "print(f\"Maximum of X_train: {X_train_max}\")\n",
    "print(f\"Minimum of X_train: {X_train_min}\")\n",
    "print(f\"Maximum of X_test: {X_test_max}\")\n",
    "print(f\"Minimum of X_test: {X_test_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast_cancer_train.visualize_output_distribution()\n",
    "breast_cancer_validation.visualize_output_distribution()\n",
    "breast_cancer_test.visualize_output_distribution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, encoder_last_layer_activation=ENCODER_ACTIVATION_FN, decoder_last_layer_activation=DECODER_ACTIVATION_FN):\n",
    "        super().__init__()\n",
    "\n",
    "        # calculate the number of neurons for each layer\n",
    "        neuron_list = []\n",
    "        running_size = input_size\n",
    "        while(running_size > hidden_size):\n",
    "            neuron_list.append(running_size)\n",
    "            running_size = running_size // 2\n",
    "        neuron_list.append(hidden_size)\n",
    "\n",
    "        # Encoder layers\n",
    "        encoder_layers = []\n",
    "        length = len(neuron_list)\n",
    "        for i in range(length-1):\n",
    "            encoder_layers.append(nn.Linear(neuron_list[i], neuron_list[i+1]))\n",
    "            if(i != length-2):\n",
    "                encoder_layers.append(nn.ReLU())\n",
    "            else:\n",
    "                encoder_layers.append(encoder_last_layer_activation)\n",
    "        print(encoder_layers)\n",
    "        self.encoder = nn.Sequential(*encoder_layers) # asterisk (*) operator to unpack the list into separate arguments\n",
    "\n",
    "\n",
    "        # Decoder layers\n",
    "        decoder_layers = []\n",
    "        for i in range(length - 1, 0, -1):\n",
    "            decoder_layers.append(nn.Linear(neuron_list[i], neuron_list[i-1]))\n",
    "            if(i != 1):\n",
    "                decoder_layers.append(nn.ReLU())\n",
    "            else:\n",
    "                decoder_layers.append(decoder_last_layer_activation)\n",
    "\n",
    "        print(decoder_layers)\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "# Sigmoid activation function to get values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Layer of single-qubit Hadamard gates. \"\"\"\n",
    "def Hadamard(nqubits):\n",
    "    return [qml.Hadamard(wires=idx) for idx in range(nqubits)]\n",
    "        \n",
    "\"\"\"Layer of parametrized qubit rotations around the y axis.\"\"\"\n",
    "def Rotation(w):\n",
    "    return [qml.RY(element, wires=idx) for idx, element in enumerate(w)]\n",
    "\n",
    "\"\"\"Layer of shifted CNots.\"\"\"\n",
    "def CNot(start, nqubits):\n",
    "    return [qml.CNOT(wires=[i, i + 1]) for i in range(start, nqubits - 1, 2)] \n",
    "\n",
    "\"\"\"Layer of CNOTs followed by another shifted layer of CNOTs and a Rotation Layer\"\"\"   \n",
    "def Entangle(weights): \n",
    "    return [[*CNot(0, len(w)), *CNot(1, len(w)), *Rotation(w)] for w in weights]\n",
    "\n",
    "\"\"\"Expectation values in the Z basis.\"\"\"\n",
    "def Measure(wires):\n",
    "    return [qml.expval(qml.PauliZ(position)) for position in wires]  \n",
    "\n",
    "\n",
    "\n",
    "dev_angle_embedding = qml.device('lightning.qubit', wires=VQC_width)\n",
    "dev_amplitude_embedding = qml.device('lightning.qubit', wires=wires_amplitude)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_angle_embedding, interface=\"torch\", diff_method='adjoint')\n",
    "def variational_circuit_angle_embedding(input, weights, out):\n",
    "    weights =  2.0 * torch.arctan(2 * weights) # weight remapping\n",
    "    width = weights.shape[1]    \n",
    "    assert input.shape[0] == width, f\"Expected input of len {width}\"\n",
    "    input = input * np.pi - np.pi / 2.0   # Rescale [0, 1] to [-pi/2, pi/2]\n",
    "    Hadamard(width)               # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    Rotation(input)               # Embed features in the quantum node \n",
    "    Entangle(weights)             # Sequence of trainable variational layers\n",
    "    return Measure(range(out))    # Expectation values in the Z basis\n",
    "\n",
    "\n",
    "\n",
    "@qml.qnode(dev_amplitude_embedding, interface=\"torch\", diff_method='adjoint')\n",
    "def variational_circuit_amplitude_embedding(input, weights, out):\n",
    "    torch_pi = torch.tensor(math.pi)\n",
    "    weights =  torch_pi * torch.tanh(weights) # weight remapping\n",
    "    width = weights.shape[1]    \n",
    "    input = input.tolist()\n",
    "    qml.AmplitudeEmbedding(features=input, wires=range(width), normalize=True, pad_with=0.)  # Embed features in the quantum node\n",
    "    Entangle(weights)             # Sequence of trainable variational layers\n",
    "    return Measure(range(out))    # Expectation values in the Z basis\n",
    "\n",
    "\n",
    "\n",
    "class Circuit(nn.Module):\n",
    "    def __init__(self, width, depth, out, amplitude_embedding):\n",
    "        super().__init__()\n",
    "        self.out = out\n",
    "        self.params = torch.nn.Parameter(torch.randn(depth, width))\n",
    "        self.amplitude_embedding = amplitude_embedding\n",
    "\n",
    "    def forward(self, input):\n",
    "        if len(input.shape) > 1: return torch.cat([self(i).float().unsqueeze(0) for i in input])\n",
    "        if self.amplitude_embedding:\n",
    "            return variational_circuit_amplitude_embedding(input, self.params, self.out).float()\n",
    "        else:\n",
    "            return variational_circuit_angle_embedding(input, self.params, self.out).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput,params = torch.randn(VQC_width), torch.nn.Parameter(torch.randn(LAYERS_ANGLE_EMBEDDING, VQC_width))\\nprint(\"Circuit with Angle Embedding\")\\nprint(qml.draw(variational_circuit_angle_embedding)(input, params, num_classes))\\nprint(\"\\nCircuit with Amplitude Embedding\")\\ninput,params = torch.randn(input_dimension), torch.nn.Parameter(torch.randn(LAYERS_AMPLITUDE_EMBEDDING, wires_amplitude))\\nprint(qml.draw(variational_circuit_amplitude_embedding)(input, params, num_classes))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input,params = torch.randn(VQC_width), torch.nn.Parameter(torch.randn(LAYERS_ANGLE_EMBEDDING, VQC_width))\n",
    "print(\"Circuit with Angle Embedding\")\n",
    "print(qml.draw(variational_circuit_angle_embedding)(input, params, num_classes))\n",
    "print(\"\\nCircuit with Amplitude Embedding\")\n",
    "input,params = torch.randn(input_dimension), torch.nn.Parameter(torch.randn(LAYERS_AMPLITUDE_EMBEDDING, wires_amplitude))\n",
    "print(qml.draw(variational_circuit_amplitude_embedding)(input, params, num_classes))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumCircuit(torch.nn.Module):\n",
    "  def __init__(self, width, depth, i=input_dimension, o=num_classes):\n",
    "    \"\"\" :param i,o: Input, Output dimension, :params width, depth: Internal net width (i.e. n_qubits) and depth (number of variational layers)\"\"\"\n",
    "    super().__init__()\n",
    "    self.pre_processing  = torch.nn.Sequential(torch.nn.Linear(i, width), PREPROCESSING_DRESSED_ACTICATION_FN) \n",
    "    self.circuit = Circuit(width, depth, width, amplitude_embedding=False)\n",
    "    self.post_processing = torch.nn.Linear(width, o)\n",
    "  \n",
    "  def train(self, mode): \n",
    "    if mode == 'classical': setgrad(True, self.pre_processing, self.post_processing); setgrad(False, self.circuit)\n",
    "    if mode == 'quantum': setgrad(True, self.circuit); setgrad(False, self.pre_processing, self.post_processing)\n",
    "    if mode == 'hybrid': setgrad(True, self.pre_processing, self.circuit, self.post_processing)\n",
    "\n",
    "  def forward(self, input): return self.post_processing(self.circuit(self.pre_processing(input.float())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEQUENT(torch.nn.Module):\n",
    "  \"\"\" Sequential Quantum Enhanced Training (SEQUENT) \"\"\"\n",
    "  def __init__(self, width, depth, i=input_dimension, o=num_classes):\n",
    "    \"\"\" :params i,o: Input, Output dimension, :params width, depth: Internal net width (i.e. n_qubits) and depth (number of variational layers)\"\"\"\n",
    "    super().__init__()\n",
    "    self.compression  = torch.nn.Sequential(torch.nn.Linear(i, width),PREPROCESSING_SEQUENT_ACTICATION_FN) \n",
    "    self.surrogate = torch.nn.Sequential(torch.nn.Linear(width, o))\n",
    "    self.circuit = Circuit(width, depth, o, amplitude_embedding=False)\n",
    "\n",
    "  def train(self, mode): \n",
    "    if mode == 'classical': self.classification = self.surrogate; setgrad(False, self.circuit); setgrad(True, self.compression, self.surrogate)\n",
    "    if mode == 'quantum': self.classification = self.circuit; setgrad(True, self.circuit); setgrad(False, self.compression, self.surrogate)\n",
    "    if mode == 'hybrid': self.classification = self.circuit; setgrad(True, self.compression, self.circuit); setgrad(False, self.surrogate)\n",
    "\n",
    "  def forward(self, input): return self.classification(self.compression(input.float()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder(model, dataset_test, batch_size):\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for original_images_val, _ in dataloader_test:\n",
    "            recon_images_val = model(original_images_val)\n",
    "            loss = criterion(recon_images_val, original_images_val)\n",
    "            test_loss += loss.item() * original_images_val.shape[0] \n",
    "\n",
    "    # Compute average test loss for the epoch\n",
    "    test_loss /= len(dataloader_test.dataset)\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataset_test, batch_size):\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "    model.eval()\n",
    "    results_list = []\n",
    "    test_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in dataloader_test:\n",
    "            test_predictions = model(batch_inputs)\n",
    "            y_probs = torch.softmax(test_predictions, dim=1)\n",
    "            y_preds = torch.argmax(y_probs, dim=1)\n",
    "            y_trues = torch.argmax(batch_labels, dim=1)\n",
    "            \n",
    "            for i in range(len(batch_inputs)):\n",
    "                sample_result = (y_trues[i].item(), y_preds[i].item(), y_probs[i].tolist())\n",
    "                results_list.append(sample_result)\n",
    "\n",
    "            # Compute the test loss\n",
    "            loss = criterion(test_predictions, y_trues)\n",
    "            test_loss += loss.item() * batch_inputs.shape[0]\n",
    "\n",
    "            # Compute the test accuracy\n",
    "            total_accuracy += (y_preds == y_trues).sum().item()\n",
    "\n",
    "    # Calculate average test loss and test accuracy\n",
    "    avg_test_loss = test_loss / len(dataset_test)\n",
    "    avg_test_accuracy = total_accuracy / len(dataset_test)\n",
    "\n",
    "\n",
    "    return results_list, avg_test_loss, avg_test_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_autoencoder(model, dataset_train, dataset_validation, batch_size, num_epochs, learning_rate):\n",
    "    # Define the dataloader for efficient batch training\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_values = []\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for original_images, _ in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            recon_image = model(original_images)\n",
    "            loss = criterion(recon_image, original_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * original_images.size(0) # loss.item() * batch_size\n",
    "\n",
    "        # Compute average training loss for the epoch\n",
    "        train_loss /= len(dataloader_train.dataset)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for original_images_val, _ in dataloader_validation:\n",
    "                recon_images_val = model(original_images_val)\n",
    "                loss = criterion(recon_images_val, original_images_val)\n",
    "                val_loss += loss.item() * original_images_val.size(0) \n",
    "\n",
    "        # Compute average validation loss for the epoch\n",
    "        val_loss /= len(dataloader_validation.dataset)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        loss_values.append((epoch+1, train_loss, val_loss, epoch_time))\n",
    "        \n",
    "        # print out\n",
    "        print(f\"Epoch: [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_parameters(model):\n",
    "    for p in model.parameters():\n",
    "        print(p)\n",
    "        print(f\"p.shape: {p.shape}\")\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) \n",
    "    #numel() in order to calculate the total number of elements in a PyTorch tensor or parameter.\n",
    "\n",
    "\n",
    "def train_and_validate_model(model, dataset_train, dataset_validation, batch_size, num_epochs, learning_rate):    \n",
    "    # Define the dataloader for efficient batch training\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    result_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize the total loss and accuracy for this epoch\n",
    "        total_loss = 0.0\n",
    "        total_accuracy = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "\n",
    "        # Loop over the batches\n",
    "        for batch_inputs, batch_labels in dataloader_train:\n",
    "            # Reset the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the predictions\n",
    "            train_predictions = model(batch_inputs)\n",
    "            # Compute the loss\n",
    "            loss = criterion(train_predictions, batch_labels.argmax(dim=1))\n",
    "            # Accumulate the loss and accuracy\n",
    "            total_loss += loss.item() * batch_inputs.shape[0]\n",
    "            total_accuracy += (train_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute the average loss and accuracy for this epoch\n",
    "        avg_train_loss = total_loss / len(dataset_train)\n",
    "        avg_train_accuracy = total_accuracy / len(dataset_train)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        total_validation_loss = 0.0\n",
    "        total_validation_accuracy = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_labels in dataloader_validation:\n",
    "                val_predictions = model(batch_inputs)\n",
    "                val_loss = criterion(val_predictions, batch_labels.argmax(dim=1))\n",
    "                total_validation_loss += val_loss.item() * batch_inputs.shape[0]\n",
    "                total_validation_accuracy += (val_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "        \n",
    "        # Compute the average validation loss and accuracy for this epoch\n",
    "        avg_val_loss = total_validation_loss / len(dataset_validation)\n",
    "        avg_val_accuracy = total_validation_accuracy / len(dataset_validation)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        # Print the progress\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}, Train loss = {avg_train_loss:.4f}, Validation loss = {avg_val_loss:.4f}, Train accuracy = {avg_train_accuracy:.4f},  Validation accuracy = {avg_val_accuracy:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "        \n",
    "        # Add values to list\n",
    "        result_list.append((epoch+1, avg_train_loss, avg_val_loss, avg_train_accuracy, avg_val_accuracy, epoch_time))\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_SEQUENT_DRESSED(model, dataset_train, dataset_validation, dataset_test, stages, num_epochs, batch_size, learning_rate):\n",
    "    print('-' * 50)\n",
    "    print('-' * 50)\n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f\"epochs: {num_epochs}\")\n",
    "    print(f\"batch size: {batch_size}\")\n",
    "    print(f\"learning rate: {learning_rate}\")\n",
    "    print('-' * 50)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    for stage in stages:\n",
    "        print(f\"Training mode: {stage}\")\n",
    "        result_list_stage = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train(stage) # defines which part should be trained\n",
    "            total_loss = 0.0\n",
    "            total_accuracy = 0.0\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Loop over the batches\n",
    "            for batch_inputs, batch_labels in dataloader_train:\n",
    "                # Reset the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Compute the predictions\n",
    "                train_predictions = model(batch_inputs)\n",
    "                # Compute the loss\n",
    "                loss = criterion(train_predictions, batch_labels.argmax(dim=1))\n",
    "                # Accumulate the loss and accuracy\n",
    "                total_loss += loss.item() * batch_inputs.shape[0]\n",
    "                total_accuracy += (train_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "                # Compute the gradients\n",
    "                loss.backward()\n",
    "                # Update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "            # Compute the average loss and accuracy for this epoch\n",
    "            avg_train_loss = total_loss / len(dataset_train)\n",
    "            avg_train_accuracy = total_accuracy / len(dataset_train)\n",
    " \n",
    "\n",
    "            # Evaluate the model on the validation set\n",
    "            model.eval()\n",
    "            total_validation_loss = 0.0\n",
    "            total_validation_accuracy = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_inputs, batch_labels in dataloader_validation:\n",
    "                    val_predictions = model(batch_inputs)\n",
    "                    val_loss = criterion(val_predictions, batch_labels.argmax(dim=1))\n",
    "                    total_validation_loss += val_loss.item() * batch_inputs.shape[0]\n",
    "                    total_validation_accuracy += (val_predictions.argmax(axis=1) == batch_labels.argmax(axis=1)).float().sum().item()\n",
    "            \n",
    "            # Compute the average validation loss and accuracy for this epoch\n",
    "            avg_val_loss = total_validation_loss / len(dataset_validation)\n",
    "            avg_val_accuracy = total_validation_accuracy / len(dataset_validation)\n",
    "\n",
    "            end_time = time.time()\n",
    "            epoch_time = end_time - start_time\n",
    "\n",
    "            # Print the progress\n",
    "            print(f\"Model: {model.__class__.__name__}, Stage: {stage} --- Epoch: {epoch + 1}/{num_epochs}, Train loss = {avg_train_loss:.4f}, Validation loss = {avg_val_loss:.4f}, Train accuracy = {avg_train_accuracy:.4f},  Validation accuracy = {avg_val_accuracy:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "            # Add values to list\n",
    "            result_list_stage.append((epoch+1, avg_train_loss, avg_val_loss, avg_train_accuracy, avg_val_accuracy, epoch_time))\n",
    "\n",
    "        # Add testing and validation values to list\n",
    "        result_list.append((stage, result_list_stage))\n",
    "\n",
    "        # Testing\n",
    "        test_list_stage, avg_test_loss, avg_test_accuracy = test_model(model, dataset_test, batch_size)\n",
    "        test_result_list.append((stage, test_list_stage, avg_test_loss, avg_test_accuracy))\n",
    "\n",
    "\n",
    "    return result_list, test_result_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder model \n",
    "autoencoder = Autoencoder(input_size=input_dimension, hidden_size=VQC_width, encoder_last_layer_activation=ENCODER_ACTIVATION_FN, decoder_last_layer_activation=DECODER_ACTIVATION_FN)\n",
    "\n",
    "print(\"\\nAutoencoder results\")\n",
    "# Train and validate the autoencoder model\n",
    "AE_loss_values = train_and_validate_autoencoder(model = autoencoder, dataset_train=breast_cancer_train, dataset_validation=breast_cancer_validation, batch_size=BATCH_SIZE_AE, num_epochs=EPOCHS_AE, learning_rate=LEARNING_RATE_AE)\n",
    "\n",
    "# Testing\n",
    "AE_test_loss = test_autoencoder(autoencoder, dataset_test=breast_cancer_test, batch_size=BATCH_SIZE_AE)\n",
    "print(f\"AE test loss: {AE_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24])\n",
      "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 24, 24, 24, 24])\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "AE_testing_list, AE_testing_loss, AE_testing_accuracy = test_model(autoencoder, dataset_test=breast_cancer_test, batch_size=BATCH_SIZE_AE)\n",
    "print(AE_testing_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the encoded input for training, validation, and testing\n",
    "encoded_input_train = autoencoder.encoder(breast_cancer_train.X)\n",
    "encoded_input_train = encoded_input_train.detach()\n",
    "\n",
    "encoded_input_validation = autoencoder.encoder(breast_cancer_validation.X)\n",
    "encoded_input_valiation = encoded_input_validation.detach()\n",
    "\n",
    "encoded_input_test = autoencoder.encoder(breast_cancer_test.X)\n",
    "encoded_input_test = encoded_input_test.detach()\n",
    "\n",
    "\n",
    "# Visualize compressed input\n",
    "print(\"\\n\")\n",
    "print(f\"encoded_input_train.shape = {encoded_input_train.shape}\")\n",
    "print(f\"y_train.shape = {breast_cancer_train.y.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Minimum of X_train: {torch.min(breast_cancer_train.X)}\")\n",
    "print(f\"Maximum of X_train: {torch.max(breast_cancer_train.X)}\")\n",
    "print(f\"Minimum of encoded_input_train: {torch.min(encoded_input_train)}\")\n",
    "print(f\"Maximum of encoded_input_train: {torch.max(encoded_input_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(f\"encoded_input_train.shape[1] = {encoded_input_train.shape[1]}\")\n",
    "print(f\"Number of qubits = {VQC_width}\")\n",
    "print(f\"Number of layers = {LAYERS_ANGLE_EMBEDDING}\")\n",
    "print(f\"Number of output classes = {num_classes}\")\n",
    "\n",
    "# Create a TensorDataset for the encoded/compressed input\n",
    "compressed_dataset_train = torch.utils.data.TensorDataset(encoded_input_train, breast_cancer_train.y)\n",
    "compressed_dataset_validation = torch.utils.data.TensorDataset(encoded_input_validation, breast_cancer_validation.y)\n",
    "compressed_dataset_test = torch.utils.data.TensorDataset(encoded_input_test, breast_cancer_test.y)\n",
    "\n",
    "# Initialize the quantum circuit module\n",
    "circuit = Circuit(VQC_width, LAYERS_ANGLE_EMBEDDING, num_classes,  amplitude_embedding=False)\n",
    "\n",
    "# Train and validate the VQC\n",
    "EPOCHS_VQC = 2\n",
    "VQC_angle_list = []\n",
    "print(\"\\nVariational Quantum Circuit (with compressed input) results\")\n",
    "VQC_angle_list = train_and_validate_model(circuit, compressed_dataset_train, compressed_dataset_validation, BATCH_SIZE_VQC, EPOCHS_VQC, LEARNING_RATE_VQC)    \n",
    "\n",
    "\n",
    "# Testing\n",
    "VQC_angle_testing_list, VQC_angle_testing_loss, VQC_angle_testing_accuracy = test_model(circuit, dataset_test=compressed_dataset_test, batch_size=BATCH_SIZE_VQC)\n",
    "print(f\"VQC (Angle Embedding) | test loss: {VQC_angle_testing_loss}, test accuracy: {VQC_angle_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder + Classical feedforward Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_VQC_params = count_trainable_parameters(circuit)\n",
    "input_size = VQC_width\n",
    "output_size = num_classes\n",
    "\n",
    "# The formula for the total number N of parameters of a network with one hidden layer is:\n",
    "# N = (input_size * hidden_size) + hidden_size + (hidden_size * output_size) + output_size\n",
    "# Rearranging leads to:\n",
    "# N = hidden_size * (input_size + output_size + 1) + output_size\n",
    "# This leads to:\n",
    "# hidden_size = (N - output) / (input_size + output_size + 1)\n",
    "\n",
    "# Since I don't want to make the number of trainable parameters less than the total number in the VQC for fairness reasons, I round up.\n",
    "hidden_neurons = max(1, math.ceil((num_VQC_params - output_size) / (input_size + output_size + 1)))\n",
    "\n",
    "\n",
    "neural_network = ClassicalNeuralNetwork(input_size, hidden_neurons, output_size)\n",
    "\n",
    "\n",
    "num_network_parameters = count_trainable_parameters(neural_network)\n",
    "\n",
    "print(f\"\\nTrainable parameters in the VQC: {num_VQC_params}\")\n",
    "print(f\"NN input size: {input_size}\")\n",
    "print(f\"NN hidden neurons: {hidden_neurons}\")\n",
    "print(f\"NN output size: {output_size}\")\n",
    "print(f\"Trainable parameters in the NN: {num_network_parameters}\")\n",
    "\n",
    "assert num_network_parameters >= num_VQC_params, \"Number of trainable parameters in the network is less than number_VQC_params.\"\n",
    "    \n",
    "\n",
    "# Train and validate the NN on the compressed input\n",
    "NN_with_compressed_input_list = []\n",
    "print(\"\\nFeedforward NN (with compressed input) results\")\n",
    "NN_with_compressed_input_list =  train_and_validate_model(neural_network, compressed_dataset_train, compressed_dataset_validation, BATCH_SIZE_AE_NN, EPOCHS_AE_NN, LEARNING_RATE_AE_NN)   \n",
    "\n",
    "# Testing\n",
    "NN_with_compressed_input_testing_list, NN_with_compressed_input_testing_loss, NN_with_compressed_input_testing_accuracy = test_model(neural_network, dataset_test=compressed_dataset_test, batch_size=BATCH_SIZE_AE_NN)\n",
    "print(f\"NN (with compressed input) | test loss: {NN_with_compressed_input_testing_loss}, test accuracy: {NN_with_compressed_input_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical feedforward Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AE_params = count_trainable_parameters(autoencoder)\n",
    "num_VQC_params = count_trainable_parameters(circuit)\n",
    "num_trainable_params_combined = num_AE_params + num_VQC_params\n",
    "input_size_just_NN = breast_cancer_train.input_dimension\n",
    "output_size_just_NN = breast_cancer_train.num_classes\n",
    "# For the formula for the hidden neurons, see above:\n",
    "hidden_neurons_just_NN = max(1, math.ceil((num_trainable_params_combined - output_size_just_NN) / (input_size_just_NN + output_size_just_NN + 1)))\n",
    "\n",
    "neural_network_just_NN = ClassicalNeuralNetwork(input_size_just_NN, hidden_neurons_just_NN, output_size_just_NN)\n",
    "\n",
    "num_just_NN_parameters = count_trainable_parameters(neural_network_just_NN)\n",
    "\n",
    "print(f\"\\nTrainable parameters in the AE+VQC combined: {num_trainable_params_combined}\")\n",
    "print(f\"NN input size: {input_size_just_NN}\")\n",
    "print(f\"NN hidden neurons: {hidden_neurons_just_NN}\")\n",
    "print(f\"NN output size: {output_size_just_NN}\")\n",
    "print(f\"Trainable parameters in the NN: {num_just_NN_parameters}\")\n",
    "\n",
    "assert num_just_NN_parameters >= num_trainable_params_combined, \"Number of trainable parameters in the network is less than the number in AE + VQC combined.\"\n",
    "\n",
    "# Train and validate the NN on the original input\n",
    "NN_with_original_input_list = []\n",
    "print(\"\\nFeedforward NN (with original input) results\")\n",
    "NN_with_original_input_list =  train_and_validate_model(neural_network_just_NN, breast_cancer_train, breast_cancer_validation, BATCH_SIZE_ONLY_NN, EPOCHS_ONLY_NN, LEARNING_RATE_ONLY_NN)    \n",
    "\n",
    "\n",
    "# Testing\n",
    "NN_with_original_input_testing_list, NN_with_original_input_testing_loss, NN_with_original_input_testing_accuracy = test_model(neural_network_just_NN, dataset_test=breast_cancer_test, batch_size=BATCH_SIZE_ONLY_NN)\n",
    "print(f\"NN (with original input) | test loss: {NN_with_original_input_testing_loss}, test accuracy: {NN_with_original_input_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQC with Amplitude Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the quantum circuit module\n",
    "circuit_amplitude = Circuit(wires_amplitude, LAYERS_AMPLITUDE_EMBEDDING, num_classes, amplitude_embedding=True)\n",
    "\n",
    "# Train and validate the VQC (amplitude embedding)\n",
    "VQC_amplitude_list = []\n",
    "print(\"\\nVariational Quantum Circuit (with original input, but with amplitude embedding) results\")\n",
    "VQC_amplitude_list = train_and_validate_model(circuit_amplitude, breast_cancer_train, breast_cancer_validation, BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING, EPOCHS_VQC_AMPLITUDE_EMBEDDING, LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING) \n",
    "\n",
    "\n",
    "# Testing\n",
    "VQC_amplitude_testing_list, VQC_amplitude_testing_loss, VQC_amplitude_testing_accuracy = test_model(circuit_amplitude, dataset_test=breast_cancer_test, batch_size=EPOCHS_VQC_AMPLITUDE_EMBEDDING)\n",
    "print(f\"VQC (Amplitude Embedding) | test loss: {VQC_amplitude_testing_loss}, test accuracy: {VQC_amplitude_testing_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequent and Dressed Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists for the results\n",
    "sequent_classical_list = []\n",
    "sequent_quantum_list = []\n",
    "dressed_classical_list = []\n",
    "dressed_quantum_list = []\n",
    "\n",
    "sequent_classical_testing_list = []\n",
    "sequent_quantum_testing_list = []\n",
    "dressed_classical_testing_list = []\n",
    "dressed_quantum_testing_list = []\n",
    "sequent_classical_testing_loss = 0\n",
    "sequent_classical_testing_accuracy = 0\n",
    "sequent_quantum_testing_loss = 0\n",
    "sequent_quantum_testing_accuracy = 0\n",
    "dressed_classical_testing_loss = 0\n",
    "dressed_classical_testing_accuracy = 0\n",
    "dressed_quantum_testing_loss = 0\n",
    "dressed_quantum_testing_accuracy = 0\n",
    "\n",
    "\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    ('SEQUENT', SEQUENT(width=VQC_width, depth=LAYERS_SEQUENT), breast_cancer_train, breast_cancer_validation, breast_cancer_test, ['classical', 'quantum'], EPOCHS_SEQUENT, LEARNING_RATE_SEQUENT),\n",
    "    ('DQC', DressedQuantumCircuit(width=VQC_width, depth=LAYERS_DRESSED), breast_cancer_train, breast_cancer_validation, breast_cancer_test, ['classical', 'quantum'], EPOCHS_DRESSED, LEARNING_RATE_DRESSED)\n",
    "]\n",
    "\n",
    "print(\"\\nSequent and Dressed results\")\n",
    "\n",
    "# Train and test each model\n",
    "for name, model, train_dataset, validation_dataset, test_dataset, stages, epochs, lr in models:\n",
    "    batch_size = BATCH_SIZE_SEQUENT if name == 'SEQUENT' else BATCH_SIZE_DRESSED\n",
    "\n",
    "    # Training\n",
    "    model_results_list, model_test_results_list = train_and_validate_SEQUENT_DRESSED(\n",
    "        model, train_dataset, validation_dataset, test_dataset, stages, num_epochs=epochs, batch_size=batch_size, learning_rate=lr\n",
    "    )\n",
    "\n",
    "    for i in range(len(model_results_list)):\n",
    "        current_stage = model_results_list[i][0]\n",
    "        if name == 'SEQUENT' and current_stage == 'classical':\n",
    "            sequent_classical_list = model_results_list[i][1]\n",
    "        elif name == 'SEQUENT' and current_stage == 'quantum':\n",
    "            sequent_quantum_list = model_results_list[i][1]\n",
    "        elif name == 'DQC' and current_stage == 'classical':\n",
    "            dressed_classical_list = model_results_list[i][1]\n",
    "        elif name == 'DQC' and current_stage == 'quantum':\n",
    "            dressed_quantum_list = model_results_list[i][1]\n",
    "    \n",
    "    # Testing\n",
    "    for i in range(len(model_test_results_list)):\n",
    "        current_stage = model_test_results_list[i][0]\n",
    "        if name == 'SEQUENT' and current_stage == 'classical':\n",
    "            sequent_classical_testing_list = model_test_results_list[i][1]\n",
    "            sequent_classical_testing_loss = model_test_results_list[i][2]\n",
    "            sequent_classical_testing_accuracy = model_test_results_list[i][3]\n",
    "        elif name == 'SEQUENT' and current_stage == 'quantum':\n",
    "            sequent_quantum_testing_list = model_test_results_list[i][1]\n",
    "            sequent_quantum_testing_loss = model_test_results_list[i][2]\n",
    "            sequent_quantum_testing_accuracy = model_test_results_list[i][3]\n",
    "        elif name == 'DQC' and current_stage == 'classical':\n",
    "            dressed_classical_testing_list = model_test_results_list[i][1]\n",
    "            dressed_classical_testing_loss = model_test_results_list[i][2]\n",
    "            dressed_classical_testing_accuracy = model_test_results_list[i][3]\n",
    "        elif name == 'DQC' and current_stage == 'quantum':\n",
    "            dressed_quantum_testing_list = model_test_results_list[i][1]\n",
    "            dressed_quantum_testing_loss = model_test_results_list[i][2]\n",
    "            dressed_quantum_testing_accuracy = model_test_results_list[i][3]\n",
    "\n",
    "print(\"\\nResults for Sequent and Dressed\")\n",
    "print(\"\\nTesting\")\n",
    "print(f\"Sequent (Classical) | test loss: {sequent_classical_testing_loss}, test accuracy: {sequent_classical_testing_accuracy}\")\n",
    "print(f\"Sequent (Quantum) | test loss: {sequent_quantum_testing_loss}, test accuracy: {sequent_quantum_testing_accuracy}\")\n",
    "print(f\"DQC (Classical) | test loss: {dressed_classical_testing_loss}, test accuracy: {dressed_classical_testing_accuracy}\")\n",
    "print(f\"DQC (Quantum) | test loss: {dressed_quantum_testing_loss}, test accuracy: {dressed_quantum_testing_accuracy}\")\n",
    "\n",
    "\n",
    "print(f\"sequent_classical_testing_list: {sequent_classical_list}\")\n",
    "print(f\"sequent_quantum_testing_list: {sequent_quantum_testing_list}\")\n",
    "print(f\"dressed_classical_testing_list: {dressed_classical_testing_list}\")\n",
    "print(f\"dressed_quantum_testing_list: {dressed_quantum_testing_list}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "HYPERPARAMETERS = {\n",
    "    \"AE\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"AE_LEARNING_RATE\": LEARNING_RATE_AE,\n",
    "        \"AE_BATCH_SIZE\": BATCH_SIZE_AE,\n",
    "        \"AE_EPOCHS\": EPOCHS_AE,\n",
    "        \"AE_ENCODER_ACTIVATION_FN\": str(ENCODER_ACTIVATION_FN),\n",
    "        \"AE_DECODER_ACTIVATION_FN\": str(DECODER_ACTIVATION_FN),\n",
    "    },\n",
    "    \"VQC_angle\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_VQC,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_VQC,\n",
    "        \"EPOCHS\": EPOCHS_VQC,\n",
    "        \"LAYERS\": LAYERS_ANGLE_EMBEDDING,\n",
    "    },\n",
    "    \"VQC_amplitude\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_VQC_AMPLITUDE_EMBEDDING,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_VQC_AMPLITUDE_EMBEDDING,\n",
    "        \"EPOCHS\": EPOCHS_VQC_AMPLITUDE_EMBEDDING,\n",
    "        \"LAYERS\": LAYERS_AMPLITUDE_EMBEDDING,\n",
    "    },\n",
    "    \"NN_compressedInput\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_AE_NN,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_AE_NN,\n",
    "        \"EPOCHS\": EPOCHS_AE_NN,\n",
    "    },\n",
    "    \"NN_originalInput\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_ONLY_NN,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_ONLY_NN,\n",
    "        \"EPOCHS\": EPOCHS_ONLY_NN,\n",
    "    },\n",
    "    \"SEQUENT\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"PREPROCESSING_ACTIVATION_FN\": str(PREPROCESSING_SEQUENT_ACTICATION_FN),\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_SEQUENT,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_SEQUENT,\n",
    "        \"EPOCHS\": EPOCHS_SEQUENT,\n",
    "        \"LAYERS\": LAYERS_SEQUENT\n",
    "    },\n",
    "    \"DRESSED\": {\n",
    "        \"SEED\": SEED,\n",
    "        \"PREPROCESSING_ACTIVATION_FN\": str(PREPROCESSING_DRESSED_ACTICATION_FN),\n",
    "        \"LEARNING_RATE\": LEARNING_RATE_DRESSED,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE_DRESSED,\n",
    "        \"EPOCHS\": EPOCHS_DRESSED,\n",
    "        \"LAYERS\": LAYERS_DRESSED\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def save_list_to_csv(data_list, hyperparameters, list_name, autoencoder, testing, test_loss=None, test_accuracy=None):\n",
    "    dataset_name = \"Breast_Cancer_Wisconsin\"\n",
    "    header_list = []\n",
    "    result_list = []\n",
    "    header_list.append(\"Dataset\")\n",
    "    header_list.append(\"List Name\")\n",
    "    result_list.append(dataset_name)\n",
    "    result_list.append(list_name)\n",
    "\n",
    "\n",
    "    hyperparam_str = \"_\".join([f\"{param}-{value}\" for param, value in hyperparameters.items()])\n",
    "\n",
    "    # Add the hyperparameters for the AE to all csv files\n",
    "    AE_hyperparameters = HYPERPARAMETERS[\"AE\"]\n",
    "    for param, value in AE_hyperparameters.items():\n",
    "        header_list.append(param)\n",
    "        result_list.append(value)\n",
    "\n",
    "    # Add specific hyperparameters \n",
    "    if(not autoencoder):\n",
    "        for param, value in hyperparameters.items():\n",
    "            header_list.append(param)\n",
    "            result_list.append(value)\n",
    "\n",
    "    # Create the file name by combining the list name, hyperparameters, and the \".csv\" extension\n",
    "    file_name = f\"{dataset_name}--{list_name}_results_{hyperparam_str}.csv\"\n",
    "\n",
    "    # Save the list to the CSV file\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the column headers based on the type of result\n",
    "        if autoencoder:\n",
    "            header_list = header_list + [\"Epoch\", \"Train_Loss\", \"Validation_Loss\", \"Time\", \"Test_Loss\"]\n",
    "            writer.writerow(header_list)\n",
    "        elif testing:\n",
    "            header_list = header_list + [\"y_true\", \"y_pred\", \"y_probs\", \"Test_Loss\", \"Test_Accuracy\"]\n",
    "            writer.writerow(header_list)\n",
    "        else:\n",
    "            header_list = header_list + [\"Epoch\", \"Train_Loss\", \"Validation_Loss\", \"Train_Accuracy\", \"Validation_Accuracy\", \"Time\", \"Test_Loss\", \"Test_Accuracy\"]\n",
    "            writer.writerow(header_list)\n",
    "        \n",
    "        result_list = [list(result_list) + list(data) for data in data_list]\n",
    "\n",
    "        # if AE -> add the test loss\n",
    "        if(autoencoder):\n",
    "            result_list = [[*entry, test_loss] for entry in result_list]\n",
    "        else: # add test loss and test accuracy\n",
    "            result_list = [[*entry, test_loss, test_accuracy] for entry in result_list]\n",
    "\n",
    "        # Write the data rows\n",
    "        writer.writerows(result_list)\n",
    " \n",
    "\n",
    "# Training & Validation lists to csv\n",
    "save_list_to_csv(AE_loss_values, HYPERPARAMETERS[\"AE\"], \"AE_loss_values\", autoencoder=True, testing=False, test_loss=AE_test_loss)\n",
    "\n",
    "save_list_to_csv(VQC_angle_list, HYPERPARAMETERS[\"VQC_angle\"], \"VQC_angle_list\", autoencoder=False, testing=False, test_loss=VQC_angle_testing_loss, test_accuracy=VQC_angle_testing_accuracy)\n",
    "save_list_to_csv(NN_with_compressed_input_list, HYPERPARAMETERS[\"NN_compressedInput\"], \"NN_with_compressed_input_list\", autoencoder=False, testing=False, test_loss=NN_with_compressed_input_testing_loss, test_accuracy=NN_with_compressed_input_testing_accuracy)\n",
    "save_list_to_csv(NN_with_original_input_list, HYPERPARAMETERS[\"NN_originalInput\"], \"NN_with_original_input_list\", autoencoder=False, testing=False, test_loss=NN_with_original_input_testing_loss, test_accuracy=NN_with_original_input_testing_accuracy)\n",
    "save_list_to_csv(VQC_amplitude_list, HYPERPARAMETERS[\"VQC_amplitude\"], \"VQC_amplitude_list\", autoencoder=False, testing=False, test_loss=VQC_amplitude_testing_loss, test_accuracy=VQC_amplitude_testing_accuracy)\n",
    "save_list_to_csv(sequent_classical_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_classical_list\", autoencoder=False, testing=False, test_loss=sequent_classical_testing_loss, test_accuracy=sequent_classical_testing_accuracy)\n",
    "save_list_to_csv(sequent_quantum_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_quantum_list\", autoencoder=False, testing=False, test_loss=sequent_quantum_testing_loss, test_accuracy=sequent_quantum_testing_accuracy)\n",
    "save_list_to_csv(dressed_classical_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_classical_list\", autoencoder=False, testing=False, test_loss=dressed_classical_testing_loss, test_accuracy=dressed_classical_testing_accuracy)\n",
    "save_list_to_csv(dressed_quantum_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_quantum_list\", autoencoder=False, testing=False, test_loss=dressed_quantum_testing_loss, test_accuracy=dressed_quantum_testing_accuracy)\n",
    "\n",
    "# Testing lists to csv\n",
    "save_list_to_csv(VQC_angle_testing_list, HYPERPARAMETERS[\"VQC_angle\"], \"VQC_angle_testing_list\", autoencoder=False, testing=True, test_loss=VQC_angle_testing_loss, test_accuracy=VQC_angle_testing_accuracy)\n",
    "save_list_to_csv(NN_with_compressed_input_testing_list, HYPERPARAMETERS[\"NN_compressedInput\"], \"NN_with_compressed_input_testing_list\", autoencoder=False, testing=True, test_loss=NN_with_compressed_input_testing_loss, test_accuracy=NN_with_compressed_input_testing_accuracy)\n",
    "save_list_to_csv(NN_with_original_input_testing_list, HYPERPARAMETERS[\"NN_originalInput\"], \"NN_with_original_input_testing_list\", autoencoder=False, testing=True, test_loss=NN_with_original_input_testing_loss, test_accuracy=NN_with_original_input_testing_accuracy)\n",
    "save_list_to_csv(VQC_amplitude_testing_list, HYPERPARAMETERS[\"VQC_amplitude\"], \"VQC_amplitude_testing_list\", autoencoder=False, testing=True, test_loss=VQC_amplitude_testing_loss, test_accuracy=VQC_amplitude_testing_accuracy)\n",
    "save_list_to_csv(sequent_classical_testing_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_classical_testing_list\", autoencoder=False, testing=True, test_loss=sequent_classical_testing_loss, test_accuracy=sequent_classical_testing_accuracy)\n",
    "save_list_to_csv(sequent_quantum_testing_list, HYPERPARAMETERS[\"SEQUENT\"], \"sequent_quantum_testing_list\", autoencoder=False, testing=True, test_loss=sequent_quantum_testing_loss, test_accuracy=sequent_quantum_testing_accuracy)\n",
    "save_list_to_csv(dressed_classical_testing_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_classical_testing_list\", autoencoder=False, testing=True, test_loss=dressed_classical_testing_loss, test_accuracy=dressed_classical_testing_accuracy)\n",
    "save_list_to_csv(dressed_quantum_testing_list, HYPERPARAMETERS[\"DRESSED\"], \"dressed_quantum_testing_list\", autoencoder=False, testing=True, test_loss=dressed_quantum_testing_loss, test_accuracy=dressed_quantum_testing_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"+\"*50)\n",
    "print(\"+\"*50)\n",
    "print(\"-\"*50)\n",
    "print(\"Results\")\n",
    "print(\"-\"*50)\n",
    "print(\"Training & Validation Results\")\n",
    "print(f\"AE_loss_values: {AE_loss_values}\")\n",
    "print(f\"VQC_angle_list: {VQC_angle_list}\")\n",
    "print(f\"NN_with_compressed_input_list: {NN_with_compressed_input_list}\")\n",
    "print(f\"NN_with_original_input_list: {NN_with_original_input_list}\")\n",
    "print(f\"VQC_amplitude_list: {VQC_amplitude_list}\")\n",
    "print(f\"sequent_classical_list: {sequent_classical_list}\")\n",
    "print(f\"sequent_quantum_list: {sequent_quantum_list}\")\n",
    "print(f\"dressed_classical_list: {dressed_classical_list}\")\n",
    "print(f\"dressed_quantum_list: {dressed_quantum_list}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Results\")\n",
    "print(f\"VQC_angle_testing_list: {VQC_angle_testing_list}\")\n",
    "print(f\"NN_with_compressed_input_testing_list: {NN_with_compressed_input_testing_list}\")\n",
    "print(f\"NN_with_original_input_testing_list: {NN_with_original_input_testing_list}\")\n",
    "print(f\"VQC_amplitude_testing_list: {VQC_amplitude_testing_list}\")\n",
    "print(f\"sequent_classical_testing_list: {sequent_classical_testing_list}\")\n",
    "print(f\"sequent_quantum_testing_list: {sequent_quantum_testing_list}\")\n",
    "print(f\"dressed_classical_testing_list: {dressed_classical_testing_list}\")\n",
    "print(f\"dressed_quantum_testing_list: {dressed_quantum_testing_list}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Test Loss and Accuracy\")\n",
    "print(f\"VQC with Angle Embedding | Test Loss: {VQC_angle_testing_loss}, Test Accuracy: {VQC_angle_testing_accuracy}\")\n",
    "print(f\"NN with compressed Input | Test Loss: {NN_with_compressed_input_testing_loss}, Test Accuracy: {NN_with_compressed_input_testing_accuracy}\")\n",
    "print(f\"NN with original Input | Test Loss: {NN_with_original_input_testing_loss}, Test Accuracy: {NN_with_original_input_testing_accuracy}\")\n",
    "print(f\"VQC with Amplitude Embedding | Test Loss: {VQC_amplitude_testing_loss}, Test Accuracy: {VQC_amplitude_testing_accuracy}\")\n",
    "print(f\"Sequent Classical Mode | Test Loss: {sequent_classical_testing_loss}, Test Accuracy: {sequent_classical_testing_accuracy}\")\n",
    "print(f\"Sequent Quantum Mode | Test Loss: {sequent_quantum_testing_loss}, Test Accuracy: {sequent_quantum_testing_accuracy}\")\n",
    "print(f\"Dressed Classical Mode| Test Loss: {dressed_classical_testing_loss}, Test Accuracy: {dressed_classical_testing_accuracy}\")\n",
    "print(f\"Dressed Quantum Mode | Test Loss: {dressed_quantum_testing_loss}, Test Accuracy: {dressed_quantum_testing_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
