{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all files are in the folder\n",
    "folder_path_BanknoteAuthentication= os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Banknote\")\n",
    "folder_path_BreastCancer = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Breast_Cancer\")\n",
    "folder_path_MNIST = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"MNIST\")\n",
    "folder_path_Audio = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Audio_MNIST\")\n",
    "\n",
    "folder_paths = [folder_path_BanknoteAuthentication, folder_path_BreastCancer, folder_path_MNIST, folder_path_Audio]\n",
    "\n",
    "for paths in folder_paths:\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(paths)\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "    # There should be (8 train_val files * 3 lr * 5 seeds) + (8 test_files * 3 lr * 5 seeds) + 5 AE_files = 245 files\n",
    "    print(f\"Number of files in {paths} is {len(csv_files)}\")\n",
    "    # assert len(csv_files) == 245, \"There are not 245 files in the folder\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specific_combination(folder_path, specific_lr, model):\n",
    "    '''\n",
    "    Plots the validation loss per seed & average for a combination of hyperparameters\n",
    "    \n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                specific_lr (float): learning rate\n",
    "    '''\n",
    "\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    val_accuracy_list_with_best_combinations = []\n",
    "    val_loss_list_with_best_combinations = []\n",
    "\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path)\n",
    "        # check if file is the model we are looking for\n",
    "        model_list_name = data[\"List Name\"][0]\n",
    "        if model_list_name == model:\n",
    "            model_learning_rate = data[\"LEARNING_RATE\"][0]            \n",
    "            model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "            model_dataset_name = data[\"Dataset\"][0]\n",
    "            model_seed = data[\"SEED\"][0]\n",
    "            model_validation_accuracy = data[\"Validation_Accuracy\"].values\n",
    "            model_validation_loss = data[\"Validation_Loss\"].values\n",
    "            \n",
    "            # model_validation_accuracy = model_validation_accuracy[:50]\n",
    "            # model_validation_loss = model_validation_loss[:50]\n",
    "\n",
    "            if model_learning_rate == specific_lr:\n",
    "                val_accuracy_list_with_best_combinations.append((model_seed, model_validation_accuracy))\n",
    "                val_loss_list_with_best_combinations.append((model_seed, model_validation_loss))\n",
    "\n",
    "    val_accuracy_list_with_best_combinations = sorted(val_accuracy_list_with_best_combinations, key=lambda x:x[0])\n",
    "\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Iterate through the seed-test_loss pairs\n",
    "    for seed, val_acc in val_accuracy_list_with_best_combinations:\n",
    "        # Plot the validation accuracy values for the current seed\n",
    "        ax.plot(val_acc, label=f\"Seed {seed}, Validation Accuracy\")\n",
    "    \n",
    "    # Average over all seeds\n",
    "    # Extract the array from the tuple\n",
    "    array_data_accuracy = [arr for _, arr in val_accuracy_list_with_best_combinations]\n",
    "    # Calculate the average for each corresponding element in the arrays\n",
    "    acc_averages = np.mean(array_data_accuracy, axis=0)\n",
    "    ax.plot(acc_averages, label=f\"Average Accuracy\")\n",
    "\n",
    "    array_data_loss = [arr for _, arr in val_loss_list_with_best_combinations]\n",
    "    # Calculate the average for each corresponding element in the arrays\n",
    "    loss_averages = np.mean(array_data_loss, axis=0)\n",
    "    # ax.plot(loss_averages, label=f\"Average Loss\")\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss and Accuracy')\n",
    "    ax.set_title(f'{model_dataset_name} - {model}: {specific_lr}')\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_combination(folder_path, model, round_numbers):\n",
    "    '''\n",
    "    Returns the best combination of hyperparameters\n",
    "\n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                model (string): Name of the model\n",
    "                round_numbers (bool): Round the numbers to 4 decimal places\n",
    "        Returns:\n",
    "                best_learning_rate (float): Best learning rate\n",
    "                best_mean_test_acc (float): Best mean test accuracy  \n",
    "    '''\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    # Define the combinations of learning_rate and batch_size\n",
    "    learning_rates = [0.1, 0.01, 0.001]\n",
    "\n",
    "    # Store results as tuples in list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through the combinations (group by learning_rate and batch_size)\n",
    "    for lr in learning_rates:\n",
    "        # initialize an empty list to store test losses for each combination\n",
    "        test_accs = []\n",
    "        seeds = []\n",
    "\n",
    "        # Iterate through the CSV files\n",
    "        for file in csv_files:\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # check if file is the model we are looking for\n",
    "            model_list_name = data[\"List Name\"][0]\n",
    "            if model_list_name == model:\n",
    "                model_learning_rate = data[\"LEARNING_RATE\"][0]            \n",
    "                model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "                model_dataset_name = data[\"Dataset\"][0]\n",
    "                model_seed = data[\"SEED\"][0]\n",
    "\n",
    "                if model_learning_rate == lr:\n",
    "                    test_accs.append(model_test_accuracy)\n",
    "                    # print(f\"model_test_accuracy = {model_test_accuracy} for seed {model_seed}\")\n",
    "                    seeds.append(model_seed)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Create boxplot for the current learning rate\n",
    "        plt.boxplot(test_accs, showmeans=True)\n",
    "        plt.title(f\"Boxplot for Learning Rate {lr}\")\n",
    "        # plt.xlabel(\"Seed\")\n",
    "        plt.ylabel(\"Test Accuracy\")\n",
    "        # plt.xticks(range(1, len(seeds) + 1), seeds)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        # Calculate the mean test loss\n",
    "        if(len(test_accs) != 0):\n",
    "            assert len(set(seeds)) == 5, \"Number of unique seeds is not equal to 5 -> ERROR.\"\n",
    "            assert len(test_accs) == 5, \"Number of test losses is not equal to 5 -> ERROR.\"\n",
    "            mean_test_acc = np.mean(test_accs, axis=0)\n",
    "            se_test_acc = stats.sem(test_accs)\n",
    "            # Calculate the 95% confidence interval for test accuracy\n",
    "            confidence_interval_acc = stats.t.interval(0.95, len(test_accs) - 1, loc=mean_test_acc, scale=se_test_acc)\n",
    "            conf_interval_half_acc = abs(confidence_interval_acc[1] - confidence_interval_acc[0]) / 2\n",
    "\n",
    "            assert mean_test_acc == (sum(test_accs)/len(test_accs)), \"Mean test acc is not equal to sum of test accs divided by number of test losses -> ERROR.\"\n",
    "            print(f\"Learning Rate: {lr} || Mean Test Acc: {mean_test_acc}\")\n",
    "            results.append((lr, mean_test_acc, conf_interval_half_acc, confidence_interval_acc))\n",
    "\n",
    "    # sort results by mean test loss\n",
    "    sorted_results = sorted(results, key=lambda x:x[1])\n",
    "    sorted_results_length = len(sorted_results)\n",
    "    print(f\"len(sorted_results) = {sorted_results_length}\")\n",
    "    print(f\"len(csv_files) = {len(csv_files)}\")\n",
    "    print(\"Sorted List:\")\n",
    "    print(sorted_results)\n",
    "    print(f\"Best Combination for {model}[{model_dataset_name}]:\")\n",
    "    best_learning_rate = sorted_results[sorted_results_length-1][0]\n",
    "    best_mean_test_acc = sorted_results[sorted_results_length-1][1]\n",
    "    best_CI_half = sorted_results[sorted_results_length-1][2]\n",
    "\n",
    "    if round_numbers:\n",
    "        # round to 4 decimal places\n",
    "        best_mean_test_acc = round(best_mean_test_acc, 4)\n",
    "        best_CI_half = round(best_CI_half, 4)\n",
    "    print(f\"Learning Rate: {best_learning_rate}, Mean Test Acc: {best_mean_test_acc}, 95% Confidence Interval Half: {best_CI_half}\")\n",
    "    print(100*\"*\")\n",
    "\n",
    "    return best_learning_rate, best_mean_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_BanknoteAuthentication= os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Banknote\")\n",
    "folder_path_BreastCancer = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Breast_Cancer\")\n",
    "folder_path_MNIST = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"MNIST\")\n",
    "folder_path_Audio = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Audio_MNIST\")\n",
    "\n",
    "\n",
    "# Banknote Authentication\n",
    "best_VQC_angle_lr_BanknoteAuthentication, best_VQC_angle_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"VQC_angle_list\", True)\n",
    "best_VQC_amplitude_lr_BanknoteAuthentication, best_VQC_amplitude_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"VQC_amplitude_list\", True)\n",
    "best_NN_compressed_lr_BanknoteAuthentication, best_NN_compressed_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"NN_with_compressed_input_list\", True)\n",
    "best_NN_original_lr_BanknoteAuthentication, best_NN_original_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"NN_with_original_input_list\", True)\n",
    "best_Sequent_classical_lr_BanknoteAuthentication, best_Sequent_classical_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"sequent_classical_list\", True)\n",
    "best_Sequent_quantum_lr_BanknoteAuthentication, best_Sequent_quantum_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"sequent_quantum_list\", True)\n",
    "best_Dressed_classical_lr_BanknoteAuthentication, best_Dressed_classical_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"dressed_classical_list\", True)\n",
    "best_Dressed_quantum_lr_BanknoteAuthentication, best_Dressed_quantum_mean_test_acc_BanknoteAuthentication = best_combination(folder_path_BanknoteAuthentication, \"dressed_quantum_list\", True)\n",
    "\n",
    "\n",
    "# Breast Cancer\n",
    "best_VQC_angle_lr_BreastCancer, best_VQC_angle_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"VQC_angle_list\", True)\n",
    "best_VQC_amplitude_lr_BreastCancer, best_VQC_amplitude_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"VQC_amplitude_list\", True)\n",
    "best_NN_compressed_lr_BreastCancer, best_NN_compressed_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"NN_with_compressed_input_list\",True)\n",
    "best_NN_original_lr_BreastCancer, best_NN_original_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"NN_with_original_input_list\",True)\n",
    "best_Sequent_classical_lr_BreastCancer, best_Sequent_classical_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"sequent_classical_list\",True)\n",
    "best_Sequent_quantum_lr_BreastCancer, best_Sequent_quantum_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"sequent_quantum_list\",True)\n",
    "best_Dressed_classical_lr_BreastCancer, best_Dressed_classical_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"dressed_classical_list\",True)\n",
    "best_Dressed_quantum_lr_BreastCancer, best_Dressed_quantum_mean_test_acc_BreastCancer = best_combination(folder_path_BreastCancer, \"dressed_quantum_list\",True)\n",
    "\n",
    "\n",
    "# MNIST\n",
    "best_VQC_angle_lr_MNIST, best_VQC_angle_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"VQC_angle_list\",True)\n",
    "best_VQC_amplitude_lr_MNIST, best_VQC_amplitude_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"VQC_amplitude_list\",True)\n",
    "best_NN_compressed_lr_MNIST, best_NN_compressed_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"NN_with_compressed_input_list\",True)\n",
    "best_NN_original_lr_MNIST, best_NN_original_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"NN_with_original_input_list\",True)\n",
    "best_Sequent_classical_lr_MNIST, best_Sequent_classical_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"sequent_classical_list\",True)\n",
    "best_Sequent_quantum_lr_MNIST, best_Sequent_quantum_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"sequent_quantum_list\",True)\n",
    "best_Dressed_classical_lr_MNIST, best_Dressed_classical_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"dressed_classical_list\",True)\n",
    "best_Dressed_quantum_lr_MNIST, best_Dressed_quantum_mean_test_acc_MNIST = best_combination(folder_path_MNIST, \"dressed_quantum_list\",True)\n",
    "\n",
    "\n",
    "# Audio MNIST\n",
    "best_VQC_angle_lr_AudioMNIST, best_VQC_angle_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"VQC_angle_list\",True)\n",
    "best_VQC_amplitude_lr_AudioMNIST, best_VQC_amplitude_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"VQC_amplitude_list\",True)\n",
    "best_NN_compressed_lr_AudioMNIST, best_NN_compressed_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"NN_with_compressed_input_list\",True)\n",
    "best_NN_original_lr_AudioMNIST, best_NN_original_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"NN_with_original_input_list\",True)\n",
    "best_Sequent_classical_lr_AudioMNIST, best_Sequent_classical_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"sequent_classical_list\",True)\n",
    "best_Sequent_quantum_lr_AudioMNIST, best_Sequent_quantum_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"sequent_quantum_list\",True)\n",
    "best_Dressed_classical_lr_AudioMNIST, best_Dressed_classical_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"dressed_classical_list\",True)\n",
    "best_Dressed_quantum_lr_AudioMNIST, best_Dressed_quantum_mean_test_acc_AudioMNIST = best_combination(folder_path_Audio, \"dressed_quantum_list\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_combination_and_store(folder_path, models, round_numbers=True, layers=6):\n",
    "    '''\n",
    "    Returns the best combination of hyperparameters for multiple models. Stores the results in a CSV file.\n",
    "\n",
    "        Parameters:\n",
    "                folder_path (string): Path to the folder containing the CSV files\n",
    "                models (list): List of model names to find the best combination for\n",
    "                round_numbers (bool): Whether to round the results to 4 decimal places (default=True)\n",
    "                layers (int): Number of layers in the model (default=3)\n",
    "        Returns:\n",
    "                best_combinations (list): List of dictionaries containing the best combination for each model\n",
    "    '''\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter out the CSV files\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "    # Define the combinations of learning_rate and batch_size\n",
    "    learning_rates = [0.1, 0.01, 0.001]\n",
    "\n",
    "    # Create a list to store the results for each model\n",
    "    best_combinations = []\n",
    "\n",
    "    for model in models:\n",
    "        model_combinations = []\n",
    "        model_dataset_name = \"\"  # Initialize the model_dataset_name for each model\n",
    "\n",
    "        # Iterate through the combinations (group by learning_rate and batch_size)\n",
    "        for lr in learning_rates:\n",
    "            # initialize an empty list to store test losses for each combination\n",
    "            test_accs = []\n",
    "            seeds = []\n",
    "\n",
    "            # Iterate through the CSV files\n",
    "            for file in csv_files:\n",
    "                # Read the CSV file\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                data = pd.read_csv(file_path)\n",
    "\n",
    "                # check if file is the model we are looking for\n",
    "                model_list_name = data[\"List Name\"][0]\n",
    "                if model_list_name == model:\n",
    "                    model_learning_rate = data[\"LEARNING_RATE\"][0]            \n",
    "                    model_test_accuracy = data[\"Test_Accuracy\"][0]\n",
    "                    model_seed = data[\"SEED\"][0]\n",
    "                    epochs = data[\"EPOCHS\"][0]\n",
    "                    batch_size = data[\"BATCH_SIZE\"][0]\n",
    "\n",
    "                    if model_learning_rate == lr:\n",
    "                        test_accs.append(model_test_accuracy)\n",
    "                        seeds.append(model_seed)\n",
    "\n",
    "                    # Extract the dataset name (assuming it is consistent across all files for the same model)\n",
    "                    model_dataset_name = data[\"Dataset\"][0]\n",
    "\n",
    "            # Calculate the mean test loss\n",
    "            if len(test_accs) != 0:\n",
    "                assert len(set(seeds)) == 5, \"Number of unique seeds is not equal to 5 -> ERROR.\"\n",
    "                assert len(test_accs) == 5, \"Number of test losses is not equal to 5 -> ERROR.\"\n",
    "                mean_test_acc = np.mean(test_accs, axis=0)\n",
    "                se_test_acc = stats.sem(test_accs)\n",
    "                # Calculate the 95% confidence interval for test accuracy\n",
    "                confidence_interval_acc = stats.t.interval(0.95, len(test_accs) - 1, loc=mean_test_acc, scale=se_test_acc)\n",
    "                conf_interval_half_acc = abs(confidence_interval_acc[1] - confidence_interval_acc[0]) / 2\n",
    "\n",
    "                assert mean_test_acc == (sum(test_accs) / len(test_accs)), \"Mean test acc is not equal to sum of test accs divided by number of test losses -> ERROR.\"\n",
    "                print(f\"Model: {model} || Learning Rate: {lr} || Mean Test Acc: {mean_test_acc}\")\n",
    "                model_combinations.append((lr, mean_test_acc, conf_interval_half_acc, confidence_interval_acc))\n",
    "\n",
    "        if model_combinations:  # Check if any valid combinations were found\n",
    "            # Sort model_combinations by mean test loss\n",
    "            sorted_combinations = sorted(model_combinations, key=lambda x: x[1])\n",
    "            best_combination = sorted_combinations[-1]  # Get the best combination for this model\n",
    "\n",
    "            if round_numbers:\n",
    "                # Round to 4 decimal places\n",
    "                best_mean_test_acc = round(best_combination[1], 4)\n",
    "                best_CI_half = round(best_combination[2], 4)\n",
    "                best_CI = [round(conf, 4) for conf in best_combination[3]]\n",
    "            else:\n",
    "                best_mean_test_acc = best_combination[1]\n",
    "                best_CI_half = best_combination[2]\n",
    "                best_CI = best_combination[3]\n",
    "\n",
    "            best_combinations.append({\n",
    "                \"Dataset\": model_dataset_name,\n",
    "                \"Model\": model,\n",
    "                \"Epochs\": epochs,\n",
    "                \"Batch size\": batch_size,\n",
    "                \"Layers\": layers,\n",
    "                \"Learning rate\": best_combination[0],\n",
    "                \"Test acc\": best_mean_test_acc,\n",
    "                \"Confidence Interval Half\": best_CI_half,\n",
    "                \"Confidence Interval\": best_CI,\n",
    "            })\n",
    "\n",
    "            print(f\"Best Combination for {model}:\")\n",
    "            print(f\"Learning Rate: {best_combination[0]}, Mean Test Acc: {best_mean_test_acc}, 95% Confidence Interval Half: {best_CI_half}, 95% Confidence Interval: {best_CI}\")\n",
    "            print(100 * \"*\")\n",
    "\n",
    "    # Store the best combinations in a CSV file\n",
    "    output_csv = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", f\"{model_dataset_name}_best_combinations.csv\")\n",
    "    results_df = pd.DataFrame(best_combinations)\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    return best_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths for different datasets\n",
    "folder_path_BanknoteAuthentication = os.path.join(os.getcwd(), \"..\", \"Model_Optimization\", \"Banknote\")\n",
    "folder_path_BreastCancer = os.path.join(os.getcwd(),  \"..\", \"Model_Optimization\", \"Breast_Cancer\")\n",
    "folder_path_MNIST = os.path.join(os.getcwd(),  \"..\", \"Model_Optimization\", \"MNIST\")\n",
    "folder_path_Audio = os.path.join(os.getcwd(),  \"..\", \"Model_Optimization\", \"Audio_MNIST\")\n",
    "\n",
    "# Define the list of models to check\n",
    "models_to_check = [\n",
    "    \"VQC_angle_list\",\n",
    "    \"VQC_amplitude_list\",\n",
    "    \"dressed_quantum_list\",\n",
    "    \"sequent_quantum_list\",\n",
    "    \"NN_with_compressed_input_list\",\n",
    "    \"NN_with_original_input_list\",\n",
    "]\n",
    "\n",
    "# Call the function for Banknote Authentication dataset\n",
    "best_combinations_banknote = best_combination_and_store(folder_path_BanknoteAuthentication, models_to_check, round_numbers=True)\n",
    "best_combinations_breastcancer = best_combination_and_store(folder_path_BreastCancer, models_to_check, round_numbers=True)\n",
    "best_combinations_mnist = best_combination_and_store(folder_path_MNIST, models_to_check, round_numbers=True)\n",
    "best_combinations_audiomnist = best_combination_and_store(folder_path_Audio, models_to_check, round_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "print(\"Plot for best combination for Banknote Authentication\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_VQC_angle_lr_BanknoteAuthentication, \"VQC_angle_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_VQC_amplitude_lr_BanknoteAuthentication, \"VQC_amplitude_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_NN_compressed_lr_BanknoteAuthentication, \"NN_with_compressed_input_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_NN_original_lr_BanknoteAuthentication, \"NN_with_original_input_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_Sequent_classical_lr_BanknoteAuthentication, \"sequent_classical_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_Sequent_quantum_lr_BanknoteAuthentication, \"sequent_quantum_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_Dressed_classical_lr_BanknoteAuthentication, \"dressed_classical_list\")\n",
    "plot_specific_combination(folder_path_BanknoteAuthentication, best_Dressed_quantum_lr_BanknoteAuthentication, \"dressed_quantum_list\")\n",
    "\n",
    "\n",
    "print(\"Plot for best combination for Breast Cancer Detection\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_VQC_angle_lr_BreastCancer, \"VQC_angle_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_VQC_amplitude_lr_BreastCancer, \"VQC_amplitude_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_NN_compressed_lr_BreastCancer, \"NN_with_compressed_input_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_NN_original_lr_BreastCancer, \"NN_with_original_input_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_Sequent_classical_lr_BreastCancer, \"sequent_classical_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_Sequent_quantum_lr_BreastCancer, \"sequent_quantum_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_Dressed_classical_lr_BreastCancer, \"dressed_classical_list\")\n",
    "plot_specific_combination(folder_path_BreastCancer, best_Dressed_quantum_lr_BreastCancer, \"dressed_quantum_list\")\n",
    "\n",
    "\n",
    "print(\"Plot for best combination for MNIST\")\n",
    "plot_specific_combination(folder_path_MNIST, best_VQC_angle_lr_MNIST, \"VQC_angle_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_VQC_amplitude_lr_MNIST, \"VQC_amplitude_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_NN_compressed_lr_MNIST, \"NN_with_compressed_input_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_NN_original_lr_MNIST, \"NN_with_original_input_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_Sequent_classical_lr_MNIST, \"sequent_classical_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_Sequent_quantum_lr_MNIST, \"sequent_quantum_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_Dressed_classical_lr_MNIST, \"dressed_classical_list\")\n",
    "plot_specific_combination(folder_path_MNIST, best_Dressed_quantum_lr_MNIST, \"dressed_quantum_list\")\n",
    "\n",
    "\n",
    "print(\"Plot for best combination for Audio MNIST\")\n",
    "plot_specific_combination(folder_path_Audio, 0.001, \"VQC_angle_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.1, \"VQC_amplitude_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.01, \"NN_with_compressed_input_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.1, \"NN_with_original_input_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.1, \"sequent_classical_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.1, \"sequent_quantum_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.1, \"dressed_classical_list\")\n",
    "plot_specific_combination(folder_path_Audio, 0.1, \"dressed_quantum_list\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
